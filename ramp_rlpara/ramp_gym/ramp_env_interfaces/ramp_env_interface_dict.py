'''
This is not the environment itself but the interface of environment.
Observation is ramp_msgs/RampObservation excluding header and robot_state_vector.
type(observation) is collections.OrderedDict.
'''

import time
import gym
from gym import spaces
from gym.utils import seeding
import numpy as np
import rospy
from collections import deque
from collections import OrderedDict
from std_msgs.msg import Float64
from std_msgs.msg import Empty
from ramp_msgs.msg import RampObservationOneRunning

class RampEnv(gym.Env):

	def exeTimeCallback(self, data):
		assert data.data > 0
		assert len(self.exe_time_vector) < self.nb_runs_one_step
		self.exe_time_vector = np.append(self.exe_time_vector, data.data)

	def obOneRunCallback(self, data)
		assert data.nb_best_trajectory_switches == len(data.best_trajectory_vector)
		assert len(self.ob_one_run_vector) < self.nb_runs_one_step
		self.ob_one_run_vector = np.append(self.ob_one_run_vector, data)

	def setEnvRdyTrueCallback(self, data):
		self.env_ready = True

	def __init__(self):
		self.action_space = spaces.Box(np.array([-0.003, -3.0, -3.0]), np.array([0.003, 3.0, 3.0]))

		## build sub-spaces of ramp observation space
		self.exe_time_space = spaces.Box(np.array([0.001]), np.array([3600])) # seconds
		self.nb_best_traj_sw_space = spaces.Discrete(3600)
		n = rospy.get_param("/max_nb_best_traj", 50)
		m = rospy.get_param("/max_nb_motion_state", 10)
		k = rospy.get_param("/dof_motion_state", 10)
		self.best_traj_vector_space = spaces.Box(low=0, high=1, shape = (n, m, k)) # normalized to [0, 1]
		self.coefficient_space = spaces.Box(np.array([0.0, 0.0, 0.0]), np.array([0.05, 50.0, 50.0]))
		## build ramp observation space
		self.observation_space = spaces.Dict({"execution_time": exe_time_space,
		                                      "nb_best_traj_switch": nb_best_traj_sw_space,
											  "best_traj_vector": best_traj_vector_space,
											  "coefficient": coefficient_space})

		self.last_calcu_exe_time = -1.0 # init a invalid value
		self.nb_runs_one_step = 3
		self.exe_time_vector = np.array([])
		self.ob_one_run_vector = np.array([])
		self.len_observation_buffer = 15 # TODO: buffer length can be parameterized
		self.observation_buffer = deque(maxlen = self.len_observation_buffer)
		self.env_ready = False
		
		self.exe_time_sub = rospy.Subscriber("execution_time", Float64, self.exeTimeCallback)
		self.ob_one_run_sub = rospy.Subscriber("ramp_collection_ramp_ob_one_run", RampObservationOneRunning, self.obOneRunCallback)
		self.set_env_rdy_true_sub = rospy.Subscriber("set_env_ready_true", Empty, self.setEnvRdyTrueCallback)

		self._seed()

	def _seed(self, seed=None):
		self.np_random, seed = seeding.np_random(seed)
		return [seed]
		
	def _reset(self):
		## Set coefficient randomly
		#  just coefficient can be sampled, other components of observation
		#  should be generated by RAMP with this random coefficient
		coefficient = self.coefficient_space.sample()
		rospy.set_param("/ramp/eval_weight_A", coefficient[0].item())
		rospy.set_param("/ramp/eval_weight_D", coefficient[1].item())
		rospy.set_param("/ramp/eval_weight_Qk", coefficient[2].item())

		## the robot start go and it will make many runnings (one running one execution time)
		# rospy.set_param("/start_one_step", True)
		
		## wait for the robot to complete all runnings and return a observation_one_running vector
		print("wait for the robot to complete all runnings......")
		while len(self.ob_one_run_vector) != self.nb_runs_one_step:
			print("wait the actual environment to get ready......")
			while not self.env_ready:
				time.sleep(0.5) # 0.5s
			print("set start_planner True for the ready environment to start one running!")
			rospy.set_param("/ramp/start_planner", True)
			self.env_ready = False
		print("initial running has been completed!")
		# print("execution times of initial running: " + str(self.exe_time_vector) + " seconds")

		## prevent the robot start go
		# rospy.set_param("/start_one_step", False)

		## process execution time vector (try to make RAMP success more)
		#  TODO: maybe need improvement
		sorted_etv = np.sort(self.exe_time_vector)
		self.exe_time_vector = np.array([]) # clear self.exe_time_vector after it is used
		assert len(sorted_etv) == self.nb_runs_one_step # one running one execution time
		assert len(sorted_etv) >= 1 # at least one running
		centre_id = int(len(sorted_etv) / 2)
		use_this_ob = self.ob_one_run_vector[centre_id] # use_this_ob is ramp_msgs/RampObservationOneRunning
		self.last_calcu_exe_time = use_this_ob.execution_time
		assert self.last_calcu_exe_time > 0
		
		## Build observation
		et = np.array([use_this_ob.execution_time]) # np.array
		nb_sw = use_this_ob.nb_best_trajectory_switches # int
		? = ? # ?
		? = ? # ?

		return observation # its dtype must be np.array

	def _step(self, action):
		assert self.action_space.contains(action)
		assert rospy.has_param("/ramp/eval_weight_A")
		assert rospy.has_param("/ramp/eval_weight_D")
		assert rospy.has_param("/ramp/eval_weight_Qk")
	
		## read the parameters of RAMP
		wA = rospy.get_param("/ramp/eval_weight_A")
		wD = rospy.get_param("/ramp/eval_weight_D")
		wQk = rospy.get_param("/ramp/eval_weight_Qk")
		wA += action[0].item()
		wD += action[1].item()
		wQk += action[2].item()
		
		## limit the parameters (observation vector) into the observation space
		low = self.coefficient_space.low
		high = self.coefficient_space.high
		wA_min = low[0].item()
		wA_max = high[0].item()
		wD_min = low[1].item()
		wD_max = high[1].item()
		wQk_min = low[2].item()
		wQk_max = high[2].item()
		if wA < wA_min:
			wA = wA_min
		if wA > wA_max:
			wA = wA_max
		if wD < wD_min:
			wD = wD_min
		if wD > wD_max:
			wD = wD_max
		if wQk < wQk_min:
			wQk = wQk_min
		if wQk > wQk_max:
			wQk = wQk_max
		
		## change the parameters of RAMP
		rospy.set_param("/ramp/eval_weight_A", wA)
		rospy.set_param("/ramp/eval_weight_D", wD)
		rospy.set_param("/ramp/eval_weight_Qk", wQk)
		
		## build a observation used for returning
		observation = np.array([wA, wD, wQk])
		assert self.observation_space.contains(observation)
		
		## buffer observation
		self.observation_buffer.append(observation) # remove the oldest observation autonomously
		
		## start a new step
		#  the robot start go and it will make many runnings (one running one execution time)
		# rospy.set_param("/start_one_step", True)
		
		## wait for the robot to complete all runnings and return a execution time vector
		print("wait for the robot to complete all runnings......")
		while len(self.exe_time_vector) != self.nb_runs_one_step: # TODO: enable key interrupt
			print("wait the actual environment to get ready......")
			while not self.env_ready:
				time.sleep(0.5) # 0.5s
			print("set start_planner True for the ready environment to start one running!")
			rospy.set_param("/ramp/start_planner", True)
			self.env_ready = False
		print("one step has been completed!")
		# print("execution times of this step: " + str(self.exe_time_vector) + " seconds")
		
		## prevent the robot go before starting a new step
		# rospy.set_param("/start_one_step", False)

		## process execution time vector (try to make RAMP success more)
		#  TODO: maybe need improvement
		exe_time_vector = self.exe_time_vector # returning info needs this line
		self.exe_time_vector = np.array([]) # clear self.exe_time_vector after it is used
		etv = exe_time_vector
		assert len(etv) == self.nb_runs_one_step
		assert len(etv) >= 1
		if len(etv) >= 3:
			etv = np.delete(etv, [etv.argmin(), etv.argmax()]) # delete the min and the max in the vector
		calcu_exe_time = etv.mean() # the execution time used for calculating reward
		assert calcu_exe_time > 0

		## calculate reward
		delta_calcu_exe_time = calcu_exe_time - self.last_calcu_exe_time
		self.last_calcu_exe_time = calcu_exe_time
		reward = -delta_calcu_exe_time

		## TODO: done or not. TODO: maybe need improvement
		if len(self.observation_buffer) == self.observation_buffer.maxlen:
			# when there is enough observations
			# done = True or done = False
			done = False # just used for returning
		else:
			done = False

		## Observation's dtype must be np.array
		#  TODO: For Keras-rl, value in info can not be a array.
		#        Maybe we should revise the code in Keras-rl (in its core.py, use try and exception)
		return observation, reward, done, {"execution_time_vector": exe_time_vector, "calculated_execution_time": calcu_exe_time}