######################################### STEP 0 #########################################
< action >
[-0.00194937 -0.00025643]
< returned_observation >
[ 0.2200438   0.87047588]
< reward >
4.800000000000001
< running_reward >
1.4400000000000002
< done >
False
######################################### STEP 1 #########################################
< action >
[-0.00079515  0.0016021 ]
< returned_observation >
[ 0.21924865  0.87207797]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2 #########################################
< action >
[-0.00230546  0.00224497]
< returned_observation >
[ 0.21694318  0.87432295]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 3 #########################################
< action >
[-0.00328264  0.00138506]
< returned_observation >
[ 0.21366055  0.875708  ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 4 #########################################
< action >
[-0.00414942  0.00096095]
< returned_observation >
[ 0.20951113  0.87666895]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 5 #########################################
< action >
[-0.00314641  0.00167249]
< returned_observation >
[ 0.20636472  0.87834144]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 6 #########################################
< action >
[-0.0030824   0.00130709]
< returned_observation >
[ 0.20328232  0.87964853]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 7 #########################################
< action >
[-0.00307435  0.00119969]
< returned_observation >
[ 0.20020796  0.88084822]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 8 #########################################
< action >
[-0.00227656  0.00056683]
< returned_observation >
[ 0.1979314   0.88141505]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 9 #########################################
< action >
[-0.00227937  0.00046556]
< returned_observation >
[ 0.19565204  0.88188061]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 10 #########################################
< action >
[-0.00232829  0.00071474]
< returned_observation >
[ 0.19332375  0.88259535]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 11 #########################################
< action >
[-0.00212715  0.00204912]
< returned_observation >
[ 0.1911966   0.88464447]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 12 #########################################
< action >
[-0.00221089  0.00360793]
< returned_observation >
[ 0.18898571  0.8882524 ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 13 #########################################
< action >
[-0.00251347  0.00312482]
< returned_observation >
[ 0.18647224  0.89137722]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 14 #########################################
< action >
[-0.00240895  0.0034757 ]
< returned_observation >
[ 0.18406329  0.89485293]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 15 #########################################
< action >
[-0.00213572  0.00476251]
< returned_observation >
[ 0.18192757  0.89961543]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 16 #########################################
< action >
[-0.00099323  0.00524961]
< returned_observation >
[ 0.18093434  0.90486504]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 17 #########################################
< action >
[-0.00132836  0.00514082]
< returned_observation >
[ 0.17960598  0.91000586]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 18 #########################################
< action >
[  8.68082047e-05   5.35409451e-03]
< returned_observation >
[ 0.17969279  0.91535996]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 19 #########################################
< action >
[-0.0012246   0.00465618]
< returned_observation >
[ 0.17846819  0.92001614]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 20 #########################################
< action >
[-0.00180051  0.00580122]
< returned_observation >
[ 0.17666768  0.92581736]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 21 #########################################
< action >
[-0.0019051   0.00805222]
< returned_observation >
[ 0.17476258  0.93386958]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 22 #########################################
< action >
[-0.00124572  0.0081641 ]
< returned_observation >
[ 0.17351686  0.94203368]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 23 #########################################
< action >
[-0.00167979  0.00912315]
< returned_observation >
[ 0.17183707  0.95115683]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 24 #########################################
< action >
[-0.00191813  0.00828427]
< returned_observation >
[ 0.16991894  0.9594411 ]
< reward >
-1.1999999999999993
< running_reward >
-0.35999999999999976
< done >
False
######################################### STEP 25 #########################################
< action >
[-0.00134722  0.0082837 ]
< returned_observation >
[ 0.16857172  0.9677248 ]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 26 #########################################
< action >
[-0.00015635  0.00819678]
< returned_observation >
[ 0.16841536  0.97592158]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 27 #########################################
< action >
[-0.00301626  0.00897297]
< returned_observation >
[ 0.1653991   0.98489455]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 28 #########################################
< action >
[-0.00488936  0.01049722]
< returned_observation >
[ 0.16050974  0.99539177]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 29 #########################################
< action >
[-0.00306017  0.0100531 ]
< returned_observation >
[ 0.15744958  1.        ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 30 #########################################
< action >
[-0.00422015  0.00863969]
< returned_observation >
[ 0.15322943  1.        ]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 31 #########################################
< action >
[-0.0033408   0.00842364]
< returned_observation >
[ 0.14988863  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 32 #########################################
< action >
[-0.00393397  0.00816665]
< returned_observation >
[ 0.14595466  1.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 33 #########################################
< action >
[-0.00183925  0.00850044]
< returned_observation >
[ 0.14411541  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 34 #########################################
< action >
[-0.00109088  0.00926365]
< returned_observation >
[ 0.14302454  1.        ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 35 #########################################
< action >
[ -7.10874796e-05   1.03100121e-02]
< returned_observation >
[ 0.14295345  1.        ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 36 #########################################
< action >
[-0.00078192  0.01007805]
< returned_observation >
[ 0.14217153  1.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 37 #########################################
< action >
[-0.00154183  0.00935051]
< returned_observation >
[ 0.1406297  1.       ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 38 #########################################
< action >
[-0.00039819  0.00883361]
< returned_observation >
[ 0.14023151  1.        ]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 39 #########################################
< action >
[-0.00047714  0.00812653]
< returned_observation >
[ 0.13975437  1.        ]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 40 #########################################
< action >
[-0.00107022  0.0089017 ]
< returned_observation >
[ 0.13868415  1.        ]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 41 #########################################
< action >
[-0.00151431  0.0084052 ]
< returned_observation >
[ 0.13716984  1.        ]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 42 #########################################
< action >
[-0.00101867  0.00889215]
< returned_observation >
[ 0.13615117  1.        ]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 43 #########################################
< action >
[-0.000225    0.00904856]
< returned_observation >
[ 0.13592617  1.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 44 #########################################
< action >
[-0.00197884  0.00966423]
< returned_observation >
[ 0.13394734  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 45 #########################################
< action >
[-0.00147763  0.01066669]
< returned_observation >
[ 0.13246971  1.        ]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 46 #########################################
< action >
[-0.00232207  0.01317012]
< returned_observation >
[ 0.13014764  1.        ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 47 #########################################
< action >
[-0.00355099  0.01387544]
< returned_observation >
[ 0.12659665  1.        ]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 48 #########################################
< action >
[-0.00349948  0.01336547]
< returned_observation >
[ 0.12309716  1.        ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 49 #########################################
< action >
[-0.00267788  0.01306207]
< returned_observation >
[ 0.12041928  1.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 50 #########################################
< action >
[-0.00500944  0.01187334]
< returned_observation >
[ 0.11540984  1.        ]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 51 #########################################
< action >
[-0.00454375  0.01409188]
< returned_observation >
[ 0.11086609  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 52 #########################################
< action >
[-0.00601777  0.01405173]
< returned_observation >
[ 0.10484832  1.        ]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 53 #########################################
< action >
[-0.00455729  0.01463547]
< returned_observation >
[ 0.10029104  1.        ]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 54 #########################################
< action >
[-0.00492564  0.01318942]
< returned_observation >
[ 0.09536539  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 55 #########################################
< action >
[-0.00669891  0.01241984]
< returned_observation >
[ 0.08866649  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 56 #########################################
< action >
[-0.00705641  0.01015037]
< returned_observation >
[ 0.08161008  1.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 57 #########################################
< action >
[-0.00873857  0.01043751]
< returned_observation >
[ 0.0728715  1.       ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 58 #########################################
< action >
[-0.00913319  0.00966569]
< returned_observation >
[ 0.06373831  1.        ]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 59 #########################################
< action >
[-0.00952567  0.00883739]
< returned_observation >
[ 0.05421264  1.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 60 #########################################
< action >
[-0.00858245  0.01046308]
< returned_observation >
[ 0.04563019  1.        ]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 61 #########################################
< action >
[-0.00649472  0.01115584]
< returned_observation >
[ 0.03913547  1.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 62 #########################################
< action >
[-0.00573701  0.01260073]
< returned_observation >
[ 0.03339846  1.        ]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 63 #########################################
< action >
[-0.00398929  0.01404526]
< returned_observation >
[ 0.02940916  1.        ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 64 #########################################
< action >
[-0.00277071  0.01338749]
< returned_observation >
[ 0.02663845  1.        ]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 65 #########################################
< action >
[-0.00436619  0.01424264]
< returned_observation >
[ 0.02227226  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 66 #########################################
< action >
[-0.00445308  0.01416351]
< returned_observation >
[ 0.01781919  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 67 #########################################
< action >
[-0.00533541  0.01283923]
< returned_observation >
[ 0.01248377  1.        ]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 68 #########################################
< action >
[-0.00392466  0.01328326]
< returned_observation >
[ 0.00855911  1.        ]
< reward >
-1.8999999999999986
< running_reward >
-0.5699999999999995
< done >
False
######################################### STEP 69 #########################################
< action >
[-0.00498351  0.01365185]
< returned_observation >
[ 0.0035756  1.       ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 70 #########################################
< action >
[-0.00466992  0.01415125]
< returned_observation >
[ 0.  1.]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
True
##################### episode 0 infomation #####################
{'max_reward': 4.800000000000001, 'nb_episode_steps': 71, 'min_reward': -12.3, 'episode_reward': 71.0, 'nb_steps': 71, 'ave_reward': 1.0}
######################################### STEP 71 #########################################
< action >
[-0.00156421  0.00048029]
< returned_observation >
[ 0.20515495  0.9190912 ]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 72 #########################################
< action >
[-0.00220839  0.0010288 ]
< returned_observation >
[ 0.20294656  0.92012   ]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 73 #########################################
< action >
[-0.00199458  0.0013743 ]
< returned_observation >
[ 0.20095198  0.92149431]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 74 #########################################
< action >
[-0.00255872  0.0017864 ]
< returned_observation >
[ 0.19839326  0.92328071]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 75 #########################################
< action >
[-0.00306511  0.00230138]
< returned_observation >
[ 0.19532815  0.92558209]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 76 #########################################
< action >
[-0.00336139  0.00117981]
< returned_observation >
[ 0.19196676  0.9267619 ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 77 #########################################
< action >
[-0.00285763  0.00047247]
< returned_observation >
[ 0.18910912  0.92723437]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 78 #########################################
< action >
[-0.00140938  0.00091538]
< returned_observation >
[ 0.18769975  0.92814975]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 79 #########################################
< action >
[-0.00093976  0.00101592]
< returned_observation >
[ 0.18675998  0.92916567]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 80 #########################################
< action >
[-0.000998   -0.00137175]
< returned_observation >
[ 0.18576198  0.92779392]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 81 #########################################
< action >
[ 0.00022538 -0.00218258]
< returned_observation >
[ 0.18598737  0.92561134]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 82 #########################################
< action >
[ 0.00118078 -0.00281662]
< returned_observation >
[ 0.18716815  0.92279472]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 83 #########################################
< action >
[ 0.00103516 -0.00303527]
< returned_observation >
[ 0.18820331  0.91975945]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 84 #########################################
< action >
[ -5.57899475e-06  -3.20106447e-03]
< returned_observation >
[ 0.18819773  0.91655839]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 85 #########################################
< action >
[ 0.00047029 -0.00360905]
< returned_observation >
[ 0.18866802  0.91294934]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 86 #########################################
< action >
[-0.00079507 -0.00417537]
< returned_observation >
[ 0.18787295  0.90877397]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 87 #########################################
< action >
[-0.00054439 -0.00302032]
< returned_observation >
[ 0.18732856  0.90575366]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 88 #########################################
< action >
[ 0.000292   -0.00272702]
< returned_observation >
[ 0.18762056  0.90302663]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 89 #########################################
< action >
[-0.00070458 -0.00181474]
< returned_observation >
[ 0.18691598  0.90121189]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 90 #########################################
< action >
[-0.00067965 -0.00205089]
< returned_observation >
[ 0.18623632  0.899161  ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 91 #########################################
< action >
[ 0.00023113 -0.0014288 ]
< returned_observation >
[ 0.18646745  0.8977322 ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 92 #########################################
< action >
[ 0.00072987 -0.00257716]
< returned_observation >
[ 0.18719732  0.89515504]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 93 #########################################
< action >
[ 0.00011763 -0.00427591]
< returned_observation >
[ 0.18731495  0.89087913]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 94 #########################################
< action >
[ 0.00031138 -0.00423965]
< returned_observation >
[ 0.18762633  0.88663948]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 95 #########################################
< action >
[ 0.00124293 -0.00401964]
< returned_observation >
[ 0.18886926  0.88261984]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 96 #########################################
< action >
[ 0.00087239 -0.00190057]
< returned_observation >
[ 0.18974165  0.88071928]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 97 #########################################
< action >
[-0.00015915 -0.00323286]
< returned_observation >
[ 0.1895825   0.87748642]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 98 #########################################
< action >
[-0.00076993 -0.00270192]
< returned_observation >
[ 0.18881256  0.8747845 ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 99 #########################################
< action >
[-0.00111842 -0.00313731]
< returned_observation >
[ 0.18769415  0.87164719]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 100 #########################################
< action >
[-0.00223829 -0.00165837]
< returned_observation >
[ 0.18545586  0.86998882]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 101 #########################################
< action >
[-0.00285834 -0.0027355 ]
< returned_observation >
[ 0.18259752  0.86725332]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 102 #########################################
< action >
[-0.00295149 -0.00351285]
< returned_observation >
[ 0.17964603  0.86374047]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 103 #########################################
< action >
[-0.00315463 -0.00215289]
< returned_observation >
[ 0.1764914   0.86158758]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 104 #########################################
< action >
[-0.0035734  -0.00218564]
< returned_observation >
[ 0.17291801  0.85940193]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 105 #########################################
< action >
[-0.00391135 -0.00235611]
< returned_observation >
[ 0.16900666  0.85704582]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 106 #########################################
< action >
[-0.00306066 -0.00180024]
< returned_observation >
[ 0.165946    0.85524559]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 107 #########################################
< action >
[-0.00337698 -0.00270891]
< returned_observation >
[ 0.16256901  0.85253667]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 108 #########################################
< action >
[-0.00349211 -0.00185099]
< returned_observation >
[ 0.1590769   0.85068568]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 109 #########################################
< action >
[-0.00349786 -0.00195337]
< returned_observation >
[ 0.15557904  0.84873231]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 110 #########################################
< action >
[-0.00529972 -0.00093267]
< returned_observation >
[ 0.15027932  0.84779964]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 111 #########################################
< action >
[-0.00678311 -0.00218917]
< returned_observation >
[ 0.14349621  0.84561046]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 112 #########################################
< action >
[-0.00715096 -0.00212606]
< returned_observation >
[ 0.13634525  0.8434844 ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 113 #########################################
< action >
[-0.00710014 -0.00286077]
< returned_observation >
[ 0.12924511  0.84062363]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 114 #########################################
< action >
[-0.00741137 -0.00343676]
< returned_observation >
[ 0.12183374  0.83718687]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 115 #########################################
< action >
[-0.00922036 -0.00365987]
< returned_observation >
[ 0.11261338  0.833527  ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 116 #########################################
< action >
[-0.00991243 -0.00320733]
< returned_observation >
[ 0.10270095  0.83031967]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 117 #########################################
< action >
[-0.01005639 -0.00221076]
< returned_observation >
[ 0.09264456  0.82810891]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 118 #########################################
< action >
[-0.00936083 -0.00127958]
< returned_observation >
[ 0.08328373  0.82682933]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 119 #########################################
< action >
[-0.00815591 -0.00055595]
< returned_observation >
[ 0.07512782  0.82627338]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 120 #########################################
< action >
[-0.00832894  0.00082675]
< returned_observation >
[ 0.06679888  0.82710012]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 121 #########################################
< action >
[-0.00926524  0.00081884]
< returned_observation >
[ 0.05753363  0.82791897]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 122 #########################################
< action >
[-0.00841168  0.00055857]
< returned_observation >
[ 0.04912196  0.82847753]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 123 #########################################
< action >
[-0.00770487 -0.00021693]
< returned_observation >
[ 0.04141709  0.82826061]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 124 #########################################
< action >
[-0.00825483  0.00035844]
< returned_observation >
[ 0.03316226  0.82861905]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 125 #########################################
< action >
[-0.00755132  0.00158339]
< returned_observation >
[ 0.02561094  0.83020244]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 126 #########################################
< action >
[-0.00763083  0.00190716]
< returned_observation >
[ 0.01798011  0.8321096 ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 127 #########################################
< action >
[-0.0070149  0.0023999]
< returned_observation >
[ 0.01096521  0.83450949]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 128 #########################################
< action >
[-0.00833005  0.00185475]
< returned_observation >
[ 0.00263516  0.83636424]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 129 #########################################
< action >
[-0.00689769  0.00063666]
< returned_observation >
[ 0.         0.8370009]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 130 #########################################
< action >
[-0.00628171  0.00023887]
< returned_observation >
[ 0.          0.83723976]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 131 #########################################
< action >
[-0.00529318 -0.00051056]
< returned_observation >
[ 0.         0.8367292]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 132 #########################################
< action >
[-0.00526073 -0.00250697]
< returned_observation >
[ 0.          0.83422223]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 133 #########################################
< action >
[-0.00531949 -0.00139898]
< returned_observation >
[ 0.          0.83282325]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 134 #########################################
< action >
[-0.00683763 -0.00018146]
< returned_observation >
[ 0.          0.83264179]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 135 #########################################
< action >
[-0.00756773 -0.00020291]
< returned_observation >
[ 0.          0.83243888]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 136 #########################################
< action >
[-0.01035667  0.00090594]
< returned_observation >
[ 0.          0.83334482]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 137 #########################################
< action >
[-0.01124222  0.00039609]
< returned_observation >
[ 0.          0.83374092]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 138 #########################################
< action >
[-0.01252941 -0.00056713]
< returned_observation >
[ 0.          0.83317378]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 139 #########################################
< action >
[-0.01139259 -0.00104532]
< returned_observation >
[ 0.          0.83212846]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 140 #########################################
< action >
[-0.01050667 -0.00118944]
< returned_observation >
[ 0.          0.83093903]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 141 #########################################
< action >
[-0.01017088 -0.00166362]
< returned_observation >
[ 0.          0.82927541]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 142 #########################################
< action >
[-0.00975483  0.00095798]
< returned_observation >
[ 0.          0.83023338]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 143 #########################################
< action >
[-0.00911399  0.00149236]
< returned_observation >
[ 0.          0.83172574]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 144 #########################################
< action >
[-0.00960334  0.00253112]
< returned_observation >
[ 0.          0.83425686]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 145 #########################################
< action >
[-0.00825641  0.0008548 ]
< returned_observation >
[ 0.          0.83511167]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 146 #########################################
< action >
[-0.00965159  0.00298533]
< returned_observation >
[ 0.        0.838097]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 147 #########################################
< action >
[-0.00923792  0.00313951]
< returned_observation >
[ 0.          0.84123651]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 148 #########################################
< action >
[-0.00868847  0.00426129]
< returned_observation >
[ 0.         0.8454978]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 149 #########################################
< action >
[-0.00790275  0.00406166]
< returned_observation >
[ 0.          0.84955946]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 150 #########################################
< action >
[-0.00585605  0.00409837]
< returned_observation >
[ 0.          0.85365783]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 151 #########################################
< action >
[-0.00675171  0.00356566]
< returned_observation >
[ 0.          0.85722349]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 152 #########################################
< action >
[-0.00690356  0.00321169]
< returned_observation >
[ 0.          0.86043519]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 153 #########################################
< action >
[-0.00711128  0.00355349]
< returned_observation >
[ 0.          0.86398868]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 154 #########################################
< action >
[-0.01041481  0.00280046]
< returned_observation >
[ 0.          0.86678913]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 155 #########################################
< action >
[-0.00947874  0.00339054]
< returned_observation >
[ 0.          0.87017968]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 156 #########################################
< action >
[-0.01017546  0.00279225]
< returned_observation >
[ 0.          0.87297193]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 157 #########################################
< action >
[-0.00905003  0.00257185]
< returned_observation >
[ 0.          0.87554378]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 158 #########################################
< action >
[-0.00959735  0.00445535]
< returned_observation >
[ 0.          0.87999913]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 159 #########################################
< action >
[-0.00998352  0.00516424]
< returned_observation >
[ 0.          0.88516336]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 160 #########################################
< action >
[-0.01004515  0.00523874]
< returned_observation >
[ 0.         0.8904021]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 161 #########################################
< action >
[-0.01100829  0.00443537]
< returned_observation >
[ 0.          0.89483746]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 162 #########################################
< action >
[-0.00976426  0.00332124]
< returned_observation >
[ 0.          0.89815871]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 163 #########################################
< action >
[-0.00950308  0.00215346]
< returned_observation >
[ 0.          0.90031217]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 164 #########################################
< action >
[-0.00976011  0.0021449 ]
< returned_observation >
[ 0.          0.90245707]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 165 #########################################
< action >
[-0.01140592  0.00330839]
< returned_observation >
[ 0.          0.90576546]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 166 #########################################
< action >
[-0.01160294  0.00454972]
< returned_observation >
[ 0.          0.91031518]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 167 #########################################
< action >
[-0.01254997  0.00548598]
< returned_observation >
[ 0.          0.91580116]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 168 #########################################
< action >
[-0.01022681  0.00572528]
< returned_observation >
[ 0.          0.92152644]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 169 #########################################
< action >
[-0.0108888   0.00622628]
< returned_observation >
[ 0.          0.92775272]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 170 #########################################
< action >
[-0.01076161  0.00603763]
< returned_observation >
[ 0.          0.93379035]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
True
##################### episode 1 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 100, 'min_reward': -12.399999999999999, 'episode_reward': 31.800000000000022, 'nb_steps': 171, 'ave_reward': 0.3180000000000002}
######################################### STEP 171 #########################################
< action >
[-0.00123551  0.00193591]
< returned_observation >
[ 0.48717568  0.61367977]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 172 #########################################
< action >
[-0.0021215   0.00277933]
< returned_observation >
[ 0.48505418  0.6164591 ]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 173 #########################################
< action >
[-0.00231473  0.00545124]
< returned_observation >
[ 0.48273945  0.62191034]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 174 #########################################
< action >
[-0.0025911   0.00475589]
< returned_observation >
[ 0.48014834  0.62666623]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 175 #########################################
< action >
[-0.00316637  0.0051497 ]
< returned_observation >
[ 0.47698197  0.63181593]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 176 #########################################
< action >
[-0.00388818  0.00390828]
< returned_observation >
[ 0.4730938   0.63572421]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 177 #########################################
< action >
[-0.00227203  0.00269211]
< returned_observation >
[ 0.47082176  0.63841632]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 178 #########################################
< action >
[-0.00078383  0.002859  ]
< returned_observation >
[ 0.47003793  0.64127532]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 179 #########################################
< action >
[-0.00187354  0.00455073]
< returned_observation >
[ 0.46816439  0.64582605]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 180 #########################################
< action >
[-0.00210222  0.00356531]
< returned_observation >
[ 0.46606217  0.64939135]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 181 #########################################
< action >
[-0.00206155  0.0048755 ]
< returned_observation >
[ 0.46400062  0.65426686]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 182 #########################################
< action >
[-0.00140251  0.00572329]
< returned_observation >
[ 0.46259811  0.65999015]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 183 #########################################
< action >
[ 0.0003264   0.00595768]
< returned_observation >
[ 0.4629245   0.66594783]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 184 #########################################
< action >
[ 0.0006741   0.00575099]
< returned_observation >
[ 0.46359861  0.67169882]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 185 #########################################
< action >
[-0.00080891  0.00562592]
< returned_observation >
[ 0.4627897   0.67732474]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 186 #########################################
< action >
[ 0.00078261  0.00391436]
< returned_observation >
[ 0.46357231  0.68123909]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 187 #########################################
< action >
[ 0.00209852  0.00419832]
< returned_observation >
[ 0.46567083  0.68543741]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 188 #########################################
< action >
[ 0.00115808  0.0042855 ]
< returned_observation >
[ 0.4668289   0.68972291]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 189 #########################################
< action >
[ 0.00290626  0.00373384]
< returned_observation >
[ 0.46973517  0.69345675]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 190 #########################################
< action >
[ 0.00366601  0.00488766]
< returned_observation >
[ 0.47340118  0.69834441]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 191 #########################################
< action >
[ 0.00273694  0.00554066]
< returned_observation >
[ 0.47613812  0.70388507]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 192 #########################################
< action >
[ 0.00324163  0.00508581]
< returned_observation >
[ 0.47937975  0.70897088]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 193 #########################################
< action >
[ 0.00389546  0.00474457]
< returned_observation >
[ 0.48327521  0.71371545]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 194 #########################################
< action >
[ 0.00328583  0.00353039]
< returned_observation >
[ 0.48656103  0.71724584]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 195 #########################################
< action >
[ 0.00364023  0.00312379]
< returned_observation >
[ 0.49020127  0.72036963]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 196 #########################################
< action >
[ 0.00304977  0.00199803]
< returned_observation >
[ 0.49325104  0.72236766]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 197 #########################################
< action >
[ 0.00165408  0.00123399]
< returned_observation >
[ 0.49490512  0.72360166]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 198 #########################################
< action >
[ 0.00235597  0.00044659]
< returned_observation >
[ 0.49726109  0.72404825]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 199 #########################################
< action >
[ 0.00377162  0.00088269]
< returned_observation >
[ 0.50103271  0.72493094]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 200 #########################################
< action >
[ 0.00389808 -0.00029339]
< returned_observation >
[ 0.50493079  0.72463755]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 201 #########################################
< action >
[ 0.00581974 -0.00170483]
< returned_observation >
[ 0.51075054  0.72293272]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 202 #########################################
< action >
[  6.31857514e-03   2.12252140e-05]
< returned_observation >
[ 0.51706911  0.72295395]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 203 #########################################
< action >
[ 0.00608358 -0.00063357]
< returned_observation >
[ 0.52315269  0.72232037]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 204 #########################################
< action >
[ 0.00602903  0.00031191]
< returned_observation >
[ 0.52918172  0.72263228]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 205 #########################################
< action >
[ 0.00735241  0.00094459]
< returned_observation >
[ 0.53653413  0.72357688]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 206 #########################################
< action >
[ 0.00624539  0.00029761]
< returned_observation >
[ 0.54277951  0.72387448]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 207 #########################################
< action >
[ 0.00641308 -0.00095027]
< returned_observation >
[ 0.54919259  0.72292421]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 208 #########################################
< action >
[ 0.00613666  0.00132122]
< returned_observation >
[ 0.55532925  0.72424543]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 209 #########################################
< action >
[ 0.00504379  0.00250831]
< returned_observation >
[ 0.56037305  0.72675373]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 210 #########################################
< action >
[ 0.00407726  0.00219212]
< returned_observation >
[ 0.56445031  0.72894586]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 211 #########################################
< action >
[ 0.00397544  0.0007116 ]
< returned_observation >
[ 0.56842575  0.72965745]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 212 #########################################
< action >
[ 0.00383872  0.00203602]
< returned_observation >
[ 0.57226447  0.73169347]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 213 #########################################
< action >
[ 0.00452443  0.00275928]
< returned_observation >
[ 0.57678891  0.73445275]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 214 #########################################
< action >
[ 0.00368737  0.00263842]
< returned_observation >
[ 0.58047628  0.73709117]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 215 #########################################
< action >
[ 0.00385842  0.00334162]
< returned_observation >
[ 0.58433469  0.74043279]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 216 #########################################
< action >
[ 0.00516926  0.00236574]
< returned_observation >
[ 0.58950395  0.74279854]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 217 #########################################
< action >
[ 0.00683473  0.00210476]
< returned_observation >
[ 0.59633868  0.74490329]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 218 #########################################
< action >
[ 0.00654605  0.00092205]
< returned_observation >
[ 0.60288473  0.74582535]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 219 #########################################
< action >
[ 0.00644154  0.00072178]
< returned_observation >
[ 0.60932627  0.74654713]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 220 #########################################
< action >
[ 0.00517058  0.00045861]
< returned_observation >
[ 0.61449685  0.74700574]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 221 #########################################
< action >
[  5.25764227e-03   7.58707523e-05]
< returned_observation >
[ 0.61975449  0.74708161]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 222 #########################################
< action >
[ 0.00600231 -0.00091935]
< returned_observation >
[ 0.6257568   0.74616226]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 223 #########################################
< action >
[ 0.00685628 -0.0010741 ]
< returned_observation >
[ 0.63261308  0.74508816]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 224 #########################################
< action >
[ 0.00719113 -0.00288767]
< returned_observation >
[ 0.63980421  0.74220049]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 225 #########################################
< action >
[ 0.00728229 -0.00291483]
< returned_observation >
[ 0.6470865   0.73928566]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 226 #########################################
< action >
[ 0.00817993 -0.00405994]
< returned_observation >
[ 0.65526643  0.73522571]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 227 #########################################
< action >
[ 0.00950448 -0.00510588]
< returned_observation >
[ 0.66477091  0.73011983]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 228 #########################################
< action >
[ 0.01077917 -0.00448897]
< returned_observation >
[ 0.67555008  0.72563086]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 229 #########################################
< action >
[ 0.00998053 -0.00228155]
< returned_observation >
[ 0.68553061  0.72334931]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 230 #########################################
< action >
[ 0.00874203 -0.00241953]
< returned_observation >
[ 0.69427264  0.72092979]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 231 #########################################
< action >
[ 0.00890797 -0.00186328]
< returned_observation >
[ 0.70318061  0.7190665 ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 232 #########################################
< action >
[ 0.00909289 -0.00103055]
< returned_observation >
[ 0.71227351  0.71803595]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 233 #########################################
< action >
[ 0.00951022 -0.00096555]
< returned_observation >
[ 0.72178373  0.71707041]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 234 #########################################
< action >
[ 0.00853801 -0.00127833]
< returned_observation >
[ 0.73032174  0.71579207]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 235 #########################################
< action >
[ 0.00939946 -0.00241194]
< returned_observation >
[ 0.7397212   0.71338013]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 236 #########################################
< action >
[ 0.009468   -0.00442554]
< returned_observation >
[ 0.7491892   0.70895459]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 237 #########################################
< action >
[ 0.00872985 -0.00601041]
< returned_observation >
[ 0.75791904  0.70294418]
< reward >
-0.8999999999999986
< running_reward >
-0.2699999999999996
< done >
False
######################################### STEP 238 #########################################
< action >
[ 0.00993305 -0.00779211]
< returned_observation >
[ 0.7678521   0.69515208]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 239 #########################################
< action >
[ 0.00965    -0.00701956]
< returned_observation >
[ 0.7775021   0.68813252]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 240 #########################################
< action >
[ 0.01021564 -0.00620335]
< returned_observation >
[ 0.78771774  0.68192917]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 241 #########################################
< action >
[ 0.0112338  -0.00568818]
< returned_observation >
[ 0.79895154  0.67624099]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 242 #########################################
< action >
[ 0.01202261 -0.00570157]
< returned_observation >
[ 0.81097415  0.67053942]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 243 #########################################
< action >
[ 0.01194983 -0.00742117]
< returned_observation >
[ 0.82292399  0.66311824]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 244 #########################################
< action >
[ 0.0120715  -0.00611013]
< returned_observation >
[ 0.83499548  0.65700811]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 245 #########################################
< action >
[ 0.0112762  -0.00723826]
< returned_observation >
[ 0.84627168  0.64976984]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 246 #########################################
< action >
[ 0.01132147 -0.00606029]
< returned_observation >
[ 0.85759315  0.64370956]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 247 #########################################
< action >
[ 0.0124819  -0.00751911]
< returned_observation >
[ 0.87007505  0.63619045]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 248 #########################################
< action >
[ 0.01288378 -0.00813118]
< returned_observation >
[ 0.88295883  0.62805927]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 249 #########################################
< action >
[ 0.01311226 -0.01034349]
< returned_observation >
[ 0.89607109  0.61771578]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 250 #########################################
< action >
[ 0.01398467 -0.0106899 ]
< returned_observation >
[ 0.91005577  0.60702588]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 251 #########################################
< action >
[ 0.01413883 -0.01081973]
< returned_observation >
[ 0.9241946   0.59620615]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 252 #########################################
< action >
[ 0.01305358 -0.01024401]
< returned_observation >
[ 0.93724818  0.58596214]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 253 #########################################
< action >
[ 0.01252233 -0.01088315]
< returned_observation >
[ 0.94977051  0.57507899]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 254 #########################################
< action >
[ 0.01313272 -0.01091625]
< returned_observation >
[ 0.96290323  0.56416274]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 255 #########################################
< action >
[ 0.01238326 -0.00992625]
< returned_observation >
[ 0.97528649  0.55423648]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 256 #########################################
< action >
[ 0.01174398 -0.00990846]
< returned_observation >
[ 0.98703047  0.54432803]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 257 #########################################
< action >
[ 0.01243019 -0.00891537]
< returned_observation >
[ 0.99946067  0.53541265]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 258 #########################################
< action >
[ 0.0135811  -0.00721088]
< returned_observation >
[ 1.          0.52820177]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 259 #########################################
< action >
[ 0.01357479 -0.00796406]
< returned_observation >
[ 1.          0.52023771]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 260 #########################################
< action >
[ 0.01517137 -0.006526  ]
< returned_observation >
[ 1.          0.51371171]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 261 #########################################
< action >
[ 0.01481766 -0.00578061]
< returned_observation >
[ 1.         0.5079311]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 262 #########################################
< action >
[ 0.01438621 -0.00729484]
< returned_observation >
[ 1.          0.50063626]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 263 #########################################
< action >
[ 0.01537117 -0.00690299]
< returned_observation >
[ 1.          0.49373327]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 264 #########################################
< action >
[ 0.01543821 -0.00516753]
< returned_observation >
[ 1.          0.48856574]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 265 #########################################
< action >
[ 0.0168152  -0.00576636]
< returned_observation >
[ 1.          0.48279937]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 266 #########################################
< action >
[ 0.01564836 -0.00761703]
< returned_observation >
[ 1.          0.47518234]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 267 #########################################
< action >
[ 0.01559791 -0.00795568]
< returned_observation >
[ 1.          0.46722666]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 268 #########################################
< action >
[ 0.0159045  -0.00789471]
< returned_observation >
[ 1.          0.45933195]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 269 #########################################
< action >
[ 0.01519104 -0.00825091]
< returned_observation >
[ 1.          0.45108104]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 270 #########################################
< action >
[ 0.01357681 -0.00697351]
< returned_observation >
[ 1.          0.44410754]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
True
##################### episode 2 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 100, 'min_reward': -13.7, 'episode_reward': -222.9000000000001, 'nb_steps': 271, 'ave_reward': -2.229000000000001}
######################################### STEP 271 #########################################
< action >
[-0.00456173  0.0048715 ]
< returned_observation >
[ 0.76134613  0.52328949]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 272 #########################################
< action >
[-0.00395555  0.00462544]
< returned_observation >
[ 0.75739058  0.52791493]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 273 #########################################
< action >
[-0.00479594  0.00697906]
< returned_observation >
[ 0.75259464  0.53489399]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 274 #########################################
< action >
[-0.00501851  0.007572  ]
< returned_observation >
[ 0.74757613  0.54246599]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 275 #########################################
< action >
[-0.00512348  0.00682272]
< returned_observation >
[ 0.74245265  0.54928871]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 276 #########################################
< action >
[-0.00383332  0.00723937]
< returned_observation >
[ 0.73861933  0.55652808]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 277 #########################################
< action >
[-0.00351901  0.00498881]
< returned_observation >
[ 0.73510032  0.5615169 ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 278 #########################################
< action >
[-0.00325946  0.00585767]
< returned_observation >
[ 0.73184085  0.56737457]
< reward >
-0.8000000000000007
< running_reward >
-0.2400000000000002
< done >
False
######################################### STEP 279 #########################################
< action >
[-0.00300475  0.00573727]
< returned_observation >
[ 0.72883611  0.57311184]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 280 #########################################
< action >
[-0.00184087  0.00601188]
< returned_observation >
[ 0.72699524  0.57912372]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 281 #########################################
< action >
[-0.0012915   0.00707693]
< returned_observation >
[ 0.72570373  0.58620064]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 282 #########################################
< action >
[-0.00032314  0.00578951]
< returned_observation >
[ 0.72538059  0.59199015]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 283 #########################################
< action >
[ -2.12669373e-05   5.05718589e-03]
< returned_observation >
[ 0.72535932  0.59704734]
< reward >
-14.5
< running_reward >
-4.35
< done >
False
######################################### STEP 284 #########################################
< action >
[-0.00206445  0.00537352]
< returned_observation >
[ 0.72329487  0.60242086]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 285 #########################################
< action >
[-0.00383469  0.00493775]
< returned_observation >
[ 0.71946019  0.60735861]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 286 #########################################
< action >
[-0.00637358  0.00394854]
< returned_observation >
[ 0.71308661  0.61130715]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 287 #########################################
< action >
[-0.00686915  0.00397457]
< returned_observation >
[ 0.70621746  0.61528172]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 288 #########################################
< action >
[-0.00743436  0.00308428]
< returned_observation >
[ 0.6987831  0.618366 ]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 289 #########################################
< action >
[-0.00836013  0.00465242]
< returned_observation >
[ 0.69042297  0.62301842]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 290 #########################################
< action >
[-0.00885448  0.00458818]
< returned_observation >
[ 0.68156849  0.6276066 ]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 291 #########################################
< action >
[-0.00699363  0.0028797 ]
< returned_observation >
[ 0.67457485  0.63048631]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 292 #########################################
< action >
[-0.00908925  0.00189477]
< returned_observation >
[ 0.6654856   0.63238108]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 293 #########################################
< action >
[-0.00950827  0.00078642]
< returned_observation >
[ 0.65597733  0.6331675 ]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 294 #########################################
< action >
[-0.00957443  0.00073854]
< returned_observation >
[ 0.64640291  0.63390604]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 295 #########################################
< action >
[-0.0111488   0.00094088]
< returned_observation >
[ 0.63525411  0.63484692]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 296 #########################################
< action >
[-0.01260609  0.00168037]
< returned_observation >
[ 0.62264802  0.63652729]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 297 #########################################
< action >
[-0.01240486  0.00390748]
< returned_observation >
[ 0.61024317  0.64043478]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 298 #########################################
< action >
[-0.01160255  0.00373356]
< returned_observation >
[ 0.59864061  0.64416833]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 299 #########################################
< action >
[-0.01128524  0.00391059]
< returned_observation >
[ 0.58735538  0.64807892]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 300 #########################################
< action >
[-0.01205337  0.0024872 ]
< returned_observation >
[ 0.57530201  0.65056612]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 301 #########################################
< action >
[-0.01098152  0.00403892]
< returned_observation >
[ 0.5643205   0.65460504]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 302 #########################################
< action >
[-0.01147416  0.00381107]
< returned_observation >
[ 0.55284633  0.65841611]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 303 #########################################
< action >
[-0.01198714  0.0048532 ]
< returned_observation >
[ 0.54085919  0.66326931]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 304 #########################################
< action >
[-0.01080412  0.00401138]
< returned_observation >
[ 0.53005507  0.6672807 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 305 #########################################
< action >
[-0.01117372  0.00350724]
< returned_observation >
[ 0.51888136  0.67078794]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 306 #########################################
< action >
[-0.01098841  0.00430915]
< returned_observation >
[ 0.50789295  0.67509709]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 307 #########################################
< action >
[-0.00994736  0.00406555]
< returned_observation >
[ 0.49794558  0.67916264]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 308 #########################################
< action >
[-0.01096271  0.00463847]
< returned_observation >
[ 0.48698287  0.68380111]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 309 #########################################
< action >
[-0.01039748  0.00432187]
< returned_observation >
[ 0.47658539  0.68812297]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 310 #########################################
< action >
[-0.0102585   0.00471562]
< returned_observation >
[ 0.46632689  0.69283859]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 311 #########################################
< action >
[-0.00940711  0.00482274]
< returned_observation >
[ 0.45691978  0.69766133]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 312 #########################################
< action >
[-0.00895053  0.00503814]
< returned_observation >
[ 0.44796925  0.70269947]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 313 #########################################
< action >
[-0.00994769  0.00577909]
< returned_observation >
[ 0.43802156  0.70847856]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 314 #########################################
< action >
[-0.00987705  0.00686978]
< returned_observation >
[ 0.42814451  0.71534834]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 315 #########################################
< action >
[-0.01109232  0.00620288]
< returned_observation >
[ 0.41705219  0.72155122]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 316 #########################################
< action >
[-0.01079291  0.00452362]
< returned_observation >
[ 0.40625928  0.72607484]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 317 #########################################
< action >
[-0.0109541   0.00411595]
< returned_observation >
[ 0.39530518  0.73019079]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 318 #########################################
< action >
[-0.01139667  0.00390494]
< returned_observation >
[ 0.38390851  0.73409574]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 319 #########################################
< action >
[-0.01365308  0.00398846]
< returned_observation >
[ 0.37025543  0.7380842 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 320 #########################################
< action >
[-0.01360242  0.00508007]
< returned_observation >
[ 0.356653    0.74316427]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 321 #########################################
< action >
[-0.01218262  0.00547535]
< returned_observation >
[ 0.34447038  0.74863962]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 322 #########################################
< action >
[-0.01128409  0.0031216 ]
< returned_observation >
[ 0.33318629  0.75176122]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 323 #########################################
< action >
[-0.01076571  0.00427116]
< returned_observation >
[ 0.32242058  0.75603238]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 324 #########################################
< action >
[-0.00992553  0.00455102]
< returned_observation >
[ 0.31249505  0.76058339]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 325 #########################################
< action >
[-0.01031303  0.00422865]
< returned_observation >
[ 0.30218202  0.76481204]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 326 #########################################
< action >
[-0.01032116  0.00470062]
< returned_observation >
[ 0.29186086  0.76951266]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 327 #########################################
< action >
[-0.00978124  0.00464856]
< returned_observation >
[ 0.28207962  0.77416122]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 328 #########################################
< action >
[-0.0110707  0.0065145]
< returned_observation >
[ 0.27100892  0.78067572]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 329 #########################################
< action >
[-0.0119673   0.00387592]
< returned_observation >
[ 0.25904162  0.78455164]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 330 #########################################
< action >
[-0.0105713   0.00493359]
< returned_observation >
[ 0.24847032  0.78948523]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 331 #########################################
< action >
[-0.01041539  0.00594942]
< returned_observation >
[ 0.23805493  0.79543465]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 332 #########################################
< action >
[-0.01000386  0.00515811]
< returned_observation >
[ 0.22805108  0.80059277]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 333 #########################################
< action >
[-0.00992193  0.0039652 ]
< returned_observation >
[ 0.21812915  0.80455797]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 334 #########################################
< action >
[-0.01060659  0.0031436 ]
< returned_observation >
[ 0.20752256  0.80770157]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 335 #########################################
< action >
[-0.01048447  0.00425375]
< returned_observation >
[ 0.19703809  0.81195532]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 336 #########################################
< action >
[-0.01116458  0.00475916]
< returned_observation >
[ 0.18587351  0.81671448]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 337 #########################################
< action >
[-0.0133304   0.00373145]
< returned_observation >
[ 0.17254311  0.82044593]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 338 #########################################
< action >
[-0.01282553  0.00473565]
< returned_observation >
[ 0.15971758  0.82518158]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 339 #########################################
< action >
[-0.01191385  0.00584986]
< returned_observation >
[ 0.14780372  0.83103144]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 340 #########################################
< action >
[-0.01358605  0.00537229]
< returned_observation >
[ 0.13421767  0.83640373]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 341 #########################################
< action >
[-0.01619685  0.00526047]
< returned_observation >
[ 0.11802082  0.8416642 ]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 342 #########################################
< action >
[-0.01598885  0.00496541]
< returned_observation >
[ 0.10203198  0.84662961]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 343 #########################################
< action >
[-0.01694327  0.00544001]
< returned_observation >
[ 0.08508871  0.85206962]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 344 #########################################
< action >
[-0.01643788  0.00561816]
< returned_observation >
[ 0.06865083  0.85768777]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 345 #########################################
< action >
[-0.01706865  0.00570563]
< returned_observation >
[ 0.05158218  0.86339341]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 346 #########################################
< action >
[-0.01700999  0.0060173 ]
< returned_observation >
[ 0.03457219  0.8694107 ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 347 #########################################
< action >
[-0.01641494  0.00603448]
< returned_observation >
[ 0.01815726  0.87544518]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 348 #########################################
< action >
[-0.01788864  0.00580465]
< returned_observation >
[  2.68619911e-04   8.81249825e-01]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 349 #########################################
< action >
[-0.01754373  0.00540983]
< returned_observation >
[ 0.          0.88665966]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 350 #########################################
< action >
[-0.01735265  0.00477058]
< returned_observation >
[ 0.          0.89143023]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 351 #########################################
< action >
[-0.01603731  0.00522128]
< returned_observation >
[ 0.          0.89665151]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 352 #########################################
< action >
[-0.01592764  0.00602447]
< returned_observation >
[ 0.          0.90267598]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 353 #########################################
< action >
[-0.01519491  0.00615964]
< returned_observation >
[ 0.          0.90883562]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 354 #########################################
< action >
[-0.01422622  0.00685995]
< returned_observation >
[ 0.          0.91569556]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 355 #########################################
< action >
[-0.01404624  0.00690668]
< returned_observation >
[ 0.          0.92260225]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 356 #########################################
< action >
[-0.01518943  0.00714377]
< returned_observation >
[ 0.          0.92974602]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 357 #########################################
< action >
[-0.01504531  0.00635393]
< returned_observation >
[ 0.          0.93609994]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 358 #########################################
< action >
[-0.01371763  0.00639482]
< returned_observation >
[ 0.          0.94249477]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 359 #########################################
< action >
[-0.01482624  0.00602225]
< returned_observation >
[ 0.          0.94851702]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 360 #########################################
< action >
[-0.01490318  0.00603277]
< returned_observation >
[ 0.          0.95454979]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 361 #########################################
< action >
[-0.01571837  0.0061141 ]
< returned_observation >
[ 0.          0.96066388]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 362 #########################################
< action >
[-0.01720923  0.0057305 ]
< returned_observation >
[ 0.          0.96639439]
< reward >
-0.6999999999999993
< running_reward >
-0.20999999999999977
< done >
False
######################################### STEP 363 #########################################
< action >
[-0.01680591  0.00510387]
< returned_observation >
[ 0.          0.97149825]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 364 #########################################
< action >
[-0.0161917   0.00595273]
< returned_observation >
[ 0.          0.97745098]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 365 #########################################
< action >
[-0.01682043  0.00360014]
< returned_observation >
[ 0.          0.98105113]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 366 #########################################
< action >
[-0.01597264  0.00499837]
< returned_observation >
[ 0.          0.98604949]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 367 #########################################
< action >
[-0.0175979   0.00525689]
< returned_observation >
[ 0.          0.99130638]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 368 #########################################
< action >
[-0.01730335  0.00369016]
< returned_observation >
[ 0.          0.99499654]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 369 #########################################
< action >
[-0.01787127  0.00499827]
< returned_observation >
[ 0.          0.99999481]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 370 #########################################
< action >
[-0.01767215  0.00507683]
< returned_observation >
[ 0.  1.]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
True
##################### episode 3 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 100, 'min_reward': -14.5, 'episode_reward': -286.5000000000001, 'nb_steps': 371, 'ave_reward': -2.865000000000001}
######################################### STEP 371 #########################################
< action >
[-0.00953291  0.00994524]
< returned_observation >
[ 0.28726759  0.19766647]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 372 #########################################
< action >
[-0.01034138  0.01000383]
< returned_observation >
[ 0.27692621  0.2076703 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 373 #########################################
< action >
[-0.00920011  0.01035118]
< returned_observation >
[ 0.2677261   0.21802148]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 374 #########################################
< action >
[-0.00905109  0.00981496]
< returned_observation >
[ 0.25867501  0.22783644]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 375 #########################################
< action >
[-0.00848608  0.01208799]
< returned_observation >
[ 0.25018893  0.23992443]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 376 #########################################
< action >
[-0.00907592  0.01104682]
< returned_observation >
[ 0.24111301  0.25097125]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 377 #########################################
< action >
[-0.00878191  0.01039467]
< returned_observation >
[ 0.2323311   0.26136592]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 378 #########################################
< action >
[-0.0086637   0.01049917]
< returned_observation >
[ 0.22366741  0.27186509]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 379 #########################################
< action >
[-0.00817376  0.01078064]
< returned_observation >
[ 0.21549365  0.28264573]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 380 #########################################
< action >
[-0.00786414  0.01213629]
< returned_observation >
[ 0.20762951  0.29478202]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 381 #########################################
< action >
[-0.00883589  0.01226724]
< returned_observation >
[ 0.19879362  0.30704926]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 382 #########################################
< action >
[-0.00851361  0.0111334 ]
< returned_observation >
[ 0.19028001  0.31818266]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 383 #########################################
< action >
[-0.00945879  0.01088592]
< returned_observation >
[ 0.18082122  0.32906858]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 384 #########################################
< action >
[-0.00999173  0.01209063]
< returned_observation >
[ 0.1708295   0.34115921]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 385 #########################################
< action >
[-0.00985549  0.01510624]
< returned_observation >
[ 0.16097401  0.35626545]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 386 #########################################
< action >
[-0.01022632  0.01487431]
< returned_observation >
[ 0.15074769  0.37113976]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 387 #########################################
< action >
[-0.00796512  0.01439534]
< returned_observation >
[ 0.14278256  0.3855351 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 388 #########################################
< action >
[-0.00576711  0.01136365]
< returned_observation >
[ 0.13701546  0.39689875]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 389 #########################################
< action >
[-0.00643049  0.01285392]
< returned_observation >
[ 0.13058497  0.40975267]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 390 #########################################
< action >
[-0.00483536  0.01340017]
< returned_observation >
[ 0.12574961  0.42315284]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 391 #########################################
< action >
[-0.00548456  0.01335009]
< returned_observation >
[ 0.12026504  0.43650293]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 392 #########################################
< action >
[-0.00470261  0.01375787]
< returned_observation >
[ 0.11556243  0.45026079]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 393 #########################################
< action >
[-0.00374745  0.01312902]
< returned_observation >
[ 0.11181499  0.46338981]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 394 #########################################
< action >
[-0.00291036  0.01450993]
< returned_observation >
[ 0.10890463  0.47789975]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 395 #########################################
< action >
[ 0.00018372  0.01533185]
< returned_observation >
[ 0.10908835  0.49323159]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 396 #########################################
< action >
[ 0.00088977  0.01458597]
< returned_observation >
[ 0.10997812  0.50781757]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 397 #########################################
< action >
[-0.00045168  0.01239538]
< returned_observation >
[ 0.10952644  0.52021295]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 398 #########################################
< action >
[  1.34229660e-05   1.45260870e-02]
< returned_observation >
[ 0.10953986  0.53473904]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 399 #########################################
< action >
[ -8.41259956e-05   1.21391118e-02]
< returned_observation >
[ 0.10945574  0.54687815]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 400 #########################################
< action >
[ 0.00010962  0.0120377 ]
< returned_observation >
[ 0.10956536  0.55891585]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 401 #########################################
< action >
[-0.00026398  0.01390563]
< returned_observation >
[ 0.10930138  0.57282147]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 402 #########################################
< action >
[ 0.00097865  0.01550892]
< returned_observation >
[ 0.11028004  0.58833039]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 403 #########################################
< action >
[ 0.00018946  0.01597912]
< returned_observation >
[ 0.1104695   0.60430951]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 404 #########################################
< action >
[-0.00090441  0.01723267]
< returned_observation >
[ 0.10956508  0.62154218]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 405 #########################################
< action >
[-0.00201611  0.01860163]
< returned_observation >
[ 0.10754898  0.64014381]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 406 #########################################
< action >
[-0.00175426  0.01893809]
< returned_observation >
[ 0.10579472  0.6590819 ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 407 #########################################
< action >
[-0.00318542  0.01975242]
< returned_observation >
[ 0.1026093   0.67883432]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 408 #########################################
< action >
[-0.00499965  0.01860719]
< returned_observation >
[ 0.09760965  0.69744151]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 409 #########################################
< action >
[-0.00592553  0.020782  ]
< returned_observation >
[ 0.09168412  0.71822351]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 410 #########################################
< action >
[-0.00580555  0.02019754]
< returned_observation >
[ 0.08587857  0.73842105]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 411 #########################################
< action >
[-0.00527002  0.02267679]
< returned_observation >
[ 0.08060855  0.76109784]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 412 #########################################
< action >
[-0.00541945  0.02171142]
< returned_observation >
[ 0.0751891   0.78280926]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 413 #########################################
< action >
[-0.00652817  0.02174981]
< returned_observation >
[ 0.06866093  0.80455907]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 414 #########################################
< action >
[-0.00484093  0.02170128]
< returned_observation >
[ 0.06382     0.82626035]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 415 #########################################
< action >
[-0.00507892  0.02079942]
< returned_observation >
[ 0.05874108  0.84705977]
< reward >
-0.8000000000000007
< running_reward >
-0.2400000000000002
< done >
False
######################################### STEP 416 #########################################
< action >
[-0.00622185  0.02193655]
< returned_observation >
[ 0.05251922  0.86899632]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 417 #########################################
< action >
[-0.00587365  0.0224404 ]
< returned_observation >
[ 0.04664557  0.89143672]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 418 #########################################
< action >
[-0.00725378  0.0230885 ]
< returned_observation >
[ 0.0393918   0.91452522]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 419 #########################################
< action >
[-0.00693001  0.02469379]
< returned_observation >
[ 0.03246178  0.939219  ]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 420 #########################################
< action >
[-0.00586864  0.02453598]
< returned_observation >
[ 0.02659314  0.96375498]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 421 #########################################
< action >
[-0.00554325  0.0249347 ]
< returned_observation >
[ 0.02104989  0.98868968]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 422 #########################################
< action >
[-0.00565119  0.02413452]
< returned_observation >
[ 0.0153987  1.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 423 #########################################
< action >
[-0.00476064  0.02647495]
< returned_observation >
[ 0.01063806  1.        ]
< reward >
-0.6000000000000014
< running_reward >
-0.1800000000000004
< done >
False
######################################### STEP 424 #########################################
< action >
[-0.00486969  0.0281935 ]
< returned_observation >
[ 0.00576837  1.        ]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 425 #########################################
< action >
[-0.00520939  0.02791762]
< returned_observation >
[  5.58985701e-04   1.00000000e+00]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 426 #########################################
< action >
[-0.00525174  0.0276858 ]
< returned_observation >
[ 0.  1.]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
True
##################### episode 4 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 56, 'min_reward': -12.100000000000001, 'episode_reward': -295.1999999999999, 'nb_steps': 427, 'ave_reward': -5.27142857142857}
######################################### STEP 427 #########################################
< action >
[-0.01330588  0.01181782]
< returned_observation >
[ 0.06743539  0.75025812]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 428 #########################################
< action >
[-0.01291125  0.01366494]
< returned_observation >
[ 0.05452414  0.76392306]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 429 #########################################
< action >
[-0.01381067  0.01388774]
< returned_observation >
[ 0.04071347  0.7778108 ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 430 #########################################
< action >
[-0.01258915  0.01487846]
< returned_observation >
[ 0.02812432  0.79268926]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 431 #########################################
< action >
[-0.01105305  0.01418523]
< returned_observation >
[ 0.01707127  0.80687449]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 432 #########################################
< action >
[-0.01173213  0.01486961]
< returned_observation >
[ 0.00533914  0.8217441 ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 433 #########################################
< action >
[-0.01311144  0.01540817]
< returned_observation >
[ 0.          0.83715227]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 434 #########################################
< action >
[-0.0121744   0.01584277]
< returned_observation >
[ 0.          0.85299504]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 435 #########################################
< action >
[-0.01353115  0.015351  ]
< returned_observation >
[ 0.          0.86834603]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 436 #########################################
< action >
[-0.01385279  0.01585474]
< returned_observation >
[ 0.          0.88420077]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 437 #########################################
< action >
[-0.01361146  0.01549965]
< returned_observation >
[ 0.          0.89970042]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 438 #########################################
< action >
[-0.01531038  0.0137418 ]
< returned_observation >
[ 0.          0.91344222]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 439 #########################################
< action >
[-0.01633966  0.01276994]
< returned_observation >
[ 0.          0.92621216]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 440 #########################################
< action >
[-0.01699892  0.01175054]
< returned_observation >
[ 0.         0.9379627]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 441 #########################################
< action >
[-0.01718216  0.01119502]
< returned_observation >
[ 0.          0.94915772]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 442 #########################################
< action >
[-0.01702227  0.01124138]
< returned_observation >
[ 0.         0.9603991]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 443 #########################################
< action >
[-0.01646886  0.01032344]
< returned_observation >
[ 0.          0.97072254]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 444 #########################################
< action >
[-0.01740306  0.0092564 ]
< returned_observation >
[ 0.          0.97997894]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 445 #########################################
< action >
[-0.01735505  0.0100364 ]
< returned_observation >
[ 0.          0.99001534]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 446 #########################################
< action >
[-0.01624168  0.01025187]
< returned_observation >
[ 0.  1.]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
True
##################### episode 5 infomation #####################
{'max_reward': 3.0, 'nb_episode_steps': 20, 'min_reward': -12.600000000000001, 'episode_reward': 8.79999999999999, 'nb_steps': 447, 'ave_reward': 0.4399999999999995}
######################################### STEP 447 #########################################
< action >
[-0.01202161  0.01084796]
< returned_observation >
[ 0.42928761  0.16915782]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 448 #########################################
< action >
[-0.011329    0.01047291]
< returned_observation >
[ 0.41795861  0.17963074]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 449 #########################################
< action >
[-0.01286299  0.01033232]
< returned_observation >
[ 0.40509563  0.18996306]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 450 #########################################
< action >
[-0.0137432   0.01033764]
< returned_observation >
[ 0.39135243  0.2003007 ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 451 #########################################
< action >
[-0.01451399  0.01005665]
< returned_observation >
[ 0.37683843  0.21035735]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 452 #########################################
< action >
[-0.01517161  0.00997837]
< returned_observation >
[ 0.36166682  0.22033572]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 453 #########################################
< action >
[-0.01464521  0.01026589]
< returned_observation >
[ 0.34702161  0.23060161]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 454 #########################################
< action >
[-0.01469553  0.01133182]
< returned_observation >
[ 0.33232608  0.24193343]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 455 #########################################
< action >
[-0.01610657  0.01153997]
< returned_observation >
[ 0.3162195   0.25347339]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 456 #########################################
< action >
[-0.01498364  0.01214069]
< returned_observation >
[ 0.30123586  0.26561408]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 457 #########################################
< action >
[-0.01390755  0.01125453]
< returned_observation >
[ 0.28732831  0.2768686 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 458 #########################################
< action >
[-0.01281199  0.01059495]
< returned_observation >
[ 0.27451632  0.28746355]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 459 #########################################
< action >
[-0.01173412  0.01089188]
< returned_observation >
[ 0.2627822   0.29835543]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 460 #########################################
< action >
[-0.01092848  0.01015325]
< returned_observation >
[ 0.25185373  0.30850868]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 461 #########################################
< action >
[-0.01119908  0.00835782]
< returned_observation >
[ 0.24065464  0.31686651]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 462 #########################################
< action >
[-0.01088919  0.0091536 ]
< returned_observation >
[ 0.22976545  0.32602011]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 463 #########################################
< action >
[-0.01055977  0.01034853]
< returned_observation >
[ 0.21920568  0.33636864]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 464 #########################################
< action >
[-0.00998013  0.01055683]
< returned_observation >
[ 0.20922555  0.34692547]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 465 #########################################
< action >
[-0.00944429  0.01009648]
< returned_observation >
[ 0.19978126  0.35702195]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 466 #########################################
< action >
[-0.00853366  0.01046147]
< returned_observation >
[ 0.1912476   0.36748343]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 467 #########################################
< action >
[-0.00821075  0.0104175 ]
< returned_observation >
[ 0.18303685  0.37790093]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 468 #########################################
< action >
[-0.00879777  0.00956447]
< returned_observation >
[ 0.17423908  0.3874654 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 469 #########################################
< action >
[-0.00907967  0.01037923]
< returned_observation >
[ 0.1651594   0.39784463]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 470 #########################################
< action >
[-0.01084615  0.01060196]
< returned_observation >
[ 0.15431326  0.40844659]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 471 #########################################
< action >
[-0.00729012  0.01093984]
< returned_observation >
[ 0.14702313  0.41938643]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 472 #########################################
< action >
[-0.00741779  0.01146535]
< returned_observation >
[ 0.13960535  0.43085178]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 473 #########################################
< action >
[-0.00751454  0.0117198 ]
< returned_observation >
[ 0.13209081  0.44257158]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 474 #########################################
< action >
[-0.00730437  0.01089421]
< returned_observation >
[ 0.12478643  0.45346579]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 475 #########################################
< action >
[-0.00604736  0.01127673]
< returned_observation >
[ 0.11873908  0.46474252]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 476 #########################################
< action >
[-0.00487171  0.01161648]
< returned_observation >
[ 0.11386736  0.476359  ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 477 #########################################
< action >
[-0.00374401  0.01184881]
< returned_observation >
[ 0.11012335  0.48820781]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 478 #########################################
< action >
[-0.00064143  0.01317856]
< returned_observation >
[ 0.10948192  0.50138637]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 479 #########################################
< action >
[ 0.00075302  0.01330871]
< returned_observation >
[ 0.11023494  0.51469508]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 480 #########################################
< action >
[-0.00069988  0.01318886]
< returned_observation >
[ 0.10953507  0.52788394]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 481 #########################################
< action >
[-0.00010316  0.01352258]
< returned_observation >
[ 0.1094319   0.54140652]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 482 #########################################
< action >
[-0.00058392  0.0129736 ]
< returned_observation >
[ 0.10884798  0.55438012]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 483 #########################################
< action >
[-0.00172668  0.01270847]
< returned_observation >
[ 0.1071213   0.56708859]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 484 #########################################
< action >
[-0.00103068  0.0135462 ]
< returned_observation >
[ 0.10609062  0.5806348 ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 485 #########################################
< action >
[-0.00033117  0.0135282 ]
< returned_observation >
[ 0.10575945  0.594163  ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 486 #########################################
< action >
[ -8.89629126e-05   1.36766851e-02]
< returned_observation >
[ 0.10567049  0.60783969]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 487 #########################################
< action >
[ 0.00037869  0.0141141 ]
< returned_observation >
[ 0.10604918  0.62195379]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 488 #########################################
< action >
[ 0.00102247  0.01412819]
< returned_observation >
[ 0.10707165  0.63608198]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 489 #########################################
< action >
[ 0.00096948  0.01563931]
< returned_observation >
[ 0.10804113  0.65172128]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 490 #########################################
< action >
[ 0.0022559  0.0136662]
< returned_observation >
[ 0.11029704  0.66538748]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 491 #########################################
< action >
[ 0.00259539  0.01411381]
< returned_observation >
[ 0.11289243  0.6795013 ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 492 #########################################
< action >
[ 0.00340043  0.01208223]
< returned_observation >
[ 0.11629286  0.69158353]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 493 #########################################
< action >
[ 0.00168207  0.01171423]
< returned_observation >
[ 0.11797493  0.70329775]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 494 #########################################
< action >
[ 0.00171314  0.01062666]
< returned_observation >
[ 0.11968808  0.71392442]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 495 #########################################
< action >
[ 0.00273861  0.01166785]
< returned_observation >
[ 0.12242669  0.72559226]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 496 #########################################
< action >
[ 0.00328721  0.01251526]
< returned_observation >
[ 0.1257139   0.73810753]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 497 #########################################
< action >
[ 0.00204435  0.01238622]
< returned_observation >
[ 0.12775825  0.75049375]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 498 #########################################
< action >
[-0.00035855  0.01336343]
< returned_observation >
[ 0.1273997   0.76385718]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 499 #########################################
< action >
[ 0.00067211  0.01376608]
< returned_observation >
[ 0.12807182  0.77762326]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 500 #########################################
< action >
[-0.0004193   0.01381029]
< returned_observation >
[ 0.12765252  0.79143355]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 501 #########################################
< action >
[ 0.00042755  0.0126062 ]
< returned_observation >
[ 0.12808007  0.80403974]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 502 #########################################
< action >
[ 0.00054922  0.01332639]
< returned_observation >
[ 0.12862929  0.81736614]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 503 #########################################
< action >
[-0.00030217  0.01278992]
< returned_observation >
[ 0.12832712  0.83015606]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 504 #########################################
< action >
[ 0.00077769  0.01356125]
< returned_observation >
[ 0.12910481  0.84371731]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 505 #########################################
< action >
[ 0.00209008  0.01385326]
< returned_observation >
[ 0.1311949   0.85757057]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 506 #########################################
< action >
[ 0.00105185  0.01383535]
< returned_observation >
[ 0.13224674  0.87140593]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 507 #########################################
< action >
[ 0.000359    0.01361891]
< returned_observation >
[ 0.13260575  0.88502484]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 508 #########################################
< action >
[ 0.00076256  0.0151447 ]
< returned_observation >
[ 0.13336831  0.90016954]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 509 #########################################
< action >
[ 0.00085295  0.0170329 ]
< returned_observation >
[ 0.13422126  0.91720244]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 510 #########################################
< action >
[-0.0004982   0.01689693]
< returned_observation >
[ 0.13372306  0.93409937]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 511 #########################################
< action >
[-0.00051943  0.01486564]
< returned_observation >
[ 0.13320363  0.948965  ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 512 #########################################
< action >
[-0.00216384  0.01459667]
< returned_observation >
[ 0.13103979  0.96356167]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 513 #########################################
< action >
[-0.00209613  0.01508543]
< returned_observation >
[ 0.12894366  0.97864711]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 514 #########################################
< action >
[-0.00205881  0.01485035]
< returned_observation >
[ 0.12688485  0.99349746]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 515 #########################################
< action >
[-0.00344545  0.01495884]
< returned_observation >
[ 0.1234394  1.       ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 516 #########################################
< action >
[-0.00190128  0.01546125]
< returned_observation >
[ 0.12153812  1.        ]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 517 #########################################
< action >
[-0.00262082  0.01566177]
< returned_observation >
[ 0.1189173  1.       ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 518 #########################################
< action >
[-0.00223475  0.01696457]
< returned_observation >
[ 0.11668256  1.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 519 #########################################
< action >
[-0.00280659  0.01752381]
< returned_observation >
[ 0.11387596  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 520 #########################################
< action >
[-0.0022862   0.01729218]
< returned_observation >
[ 0.11158976  1.        ]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 521 #########################################
< action >
[-0.00241341  0.0169459 ]
< returned_observation >
[ 0.10917635  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 522 #########################################
< action >
[-0.00238026  0.01727417]
< returned_observation >
[ 0.10679608  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 523 #########################################
< action >
[-0.00360506  0.01720015]
< returned_observation >
[ 0.10319102  1.        ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 524 #########################################
< action >
[-0.00213217  0.017259  ]
< returned_observation >
[ 0.10105885  1.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 525 #########################################
< action >
[-0.00399942  0.01875836]
< returned_observation >
[ 0.09705943  1.        ]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 526 #########################################
< action >
[-0.00425209  0.01899318]
< returned_observation >
[ 0.09280734  1.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 527 #########################################
< action >
[-0.00375201  0.01866858]
< returned_observation >
[ 0.08905533  1.        ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 528 #########################################
< action >
[-0.00477948  0.01801751]
< returned_observation >
[ 0.08427585  1.        ]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 529 #########################################
< action >
[-0.00453808  0.01807587]
< returned_observation >
[ 0.07973777  1.        ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 530 #########################################
< action >
[-0.00484136  0.02025232]
< returned_observation >
[ 0.0748964  1.       ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 531 #########################################
< action >
[-0.00461453  0.02127032]
< returned_observation >
[ 0.07028188  1.        ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 532 #########################################
< action >
[-0.00254292  0.02147667]
< returned_observation >
[ 0.06773896  1.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 533 #########################################
< action >
[-0.00295295  0.02129808]
< returned_observation >
[ 0.06478601  1.        ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 534 #########################################
< action >
[-0.00284455  0.02314538]
< returned_observation >
[ 0.06194146  1.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 535 #########################################
< action >
[-0.00180214  0.02301927]
< returned_observation >
[ 0.06013931  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 536 #########################################
< action >
[-0.00236971  0.0238412 ]
< returned_observation >
[ 0.0577696  1.       ]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 537 #########################################
< action >
[-0.00058649  0.02334661]
< returned_observation >
[ 0.05718311  1.        ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 538 #########################################
< action >
[ 0.00098396  0.02375221]
< returned_observation >
[ 0.05816706  1.        ]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 539 #########################################
< action >
[ 0.00099791  0.02359982]
< returned_observation >
[ 0.05916497  1.        ]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 540 #########################################
< action >
[ 0.00033732  0.02323636]
< returned_observation >
[ 0.05950229  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 541 #########################################
< action >
[ 0.00156438  0.02194687]
< returned_observation >
[ 0.06106668  1.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 542 #########################################
< action >
[ 0.00113854  0.02199971]
< returned_observation >
[ 0.06220522  1.        ]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 543 #########################################
< action >
[  1.10924244e-05   2.16139674e-02]
< returned_observation >
[ 0.06221631  1.        ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 544 #########################################
< action >
[-0.00138595  0.02231773]
< returned_observation >
[ 0.06083037  1.        ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 545 #########################################
< action >
[-0.00075584  0.0210407 ]
< returned_observation >
[ 0.06007453  1.        ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 546 #########################################
< action >
[ 0.00062062  0.02012398]
< returned_observation >
[ 0.06069515  1.        ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
True
##################### episode 6 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 100, 'min_reward': -12.5, 'episode_reward': -377.2000000000003, 'nb_steps': 547, 'ave_reward': -3.772000000000003}
######################################### STEP 547 #########################################
< action >
[-0.01655373  0.01309331]
< returned_observation >
[ 0.8633833   0.28717977]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 548 #########################################
< action >
[-0.0166685   0.01338609]
< returned_observation >
[ 0.8467148   0.30056587]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 549 #########################################
< action >
[-0.0157196  0.0131097]
< returned_observation >
[ 0.8309952   0.31367557]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 550 #########################################
< action >
[-0.0145983   0.01275823]
< returned_observation >
[ 0.8163969  0.3264338]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 551 #########################################
< action >
[-0.01372581  0.01184381]
< returned_observation >
[ 0.8026711   0.33827761]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 552 #########################################
< action >
[-0.01346271  0.01158393]
< returned_observation >
[ 0.78920839  0.34986154]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 553 #########################################
< action >
[-0.01332003  0.01381915]
< returned_observation >
[ 0.77588836  0.36368068]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 554 #########################################
< action >
[-0.01335455  0.01391698]
< returned_observation >
[ 0.7625338   0.37759766]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 555 #########################################
< action >
[-0.01325672  0.01429656]
< returned_observation >
[ 0.74927708  0.39189421]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 556 #########################################
< action >
[-0.01546658  0.01507965]
< returned_observation >
[ 0.73381051  0.40697386]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 557 #########################################
< action >
[-0.01683595  0.01313535]
< returned_observation >
[ 0.71697455  0.42010921]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 558 #########################################
< action >
[-0.01676132  0.01195861]
< returned_observation >
[ 0.70021323  0.43206782]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 559 #########################################
< action >
[-0.01656125  0.01310035]
< returned_observation >
[ 0.68365198  0.44516817]
< reward >
-14.2
< running_reward >
-4.26
< done >
False
######################################### STEP 560 #########################################
< action >
[-0.01657469  0.01214855]
< returned_observation >
[ 0.66707729  0.45731672]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 561 #########################################
< action >
[-0.01650821  0.0142176 ]
< returned_observation >
[ 0.65056908  0.47153432]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 562 #########################################
< action >
[-0.01647725  0.01601468]
< returned_observation >
[ 0.63409184  0.48754901]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 563 #########################################
< action >
[-0.01505894  0.01487369]
< returned_observation >
[ 0.6190329   0.50242269]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 564 #########################################
< action >
[-0.01420427  0.01360076]
< returned_observation >
[ 0.60482863  0.51602346]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 565 #########################################
< action >
[-0.01368435  0.01420346]
< returned_observation >
[ 0.59114428  0.53022692]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 566 #########################################
< action >
[-0.01390584  0.01267639]
< returned_observation >
[ 0.57723844  0.54290331]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 567 #########################################
< action >
[-0.01431015  0.0123889 ]
< returned_observation >
[ 0.56292829  0.55529221]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 568 #########################################
< action >
[-0.01387955  0.01236188]
< returned_observation >
[ 0.54904874  0.5676541 ]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 569 #########################################
< action >
[-0.01341474  0.01208565]
< returned_observation >
[ 0.535634    0.57973975]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 570 #########################################
< action >
[-0.01506676  0.01208608]
< returned_observation >
[ 0.52056724  0.59182582]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 571 #########################################
< action >
[-0.01372083  0.01126543]
< returned_observation >
[ 0.50684642  0.60309126]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 572 #########################################
< action >
[-0.0147953   0.00937577]
< returned_observation >
[ 0.49205112  0.61246703]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 573 #########################################
< action >
[-0.01299598  0.00835547]
< returned_observation >
[ 0.47905514  0.6208225 ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 574 #########################################
< action >
[-0.01199059  0.00855323]
< returned_observation >
[ 0.46706455  0.62937573]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 575 #########################################
< action >
[-0.01217329  0.00866672]
< returned_observation >
[ 0.45489126  0.63804245]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 576 #########################################
< action >
[-0.01037061  0.01040683]
< returned_observation >
[ 0.44452065  0.64844928]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 577 #########################################
< action >
[-0.00991347  0.01001837]
< returned_observation >
[ 0.43460718  0.65846765]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 578 #########################################
< action >
[-0.00850998  0.01074987]
< returned_observation >
[ 0.4260972   0.66921753]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 579 #########################################
< action >
[-0.00845078  0.01130498]
< returned_observation >
[ 0.41764643  0.68052251]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 580 #########################################
< action >
[-0.00926075  0.01208206]
< returned_observation >
[ 0.40838568  0.69260457]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 581 #########################################
< action >
[-0.00958083  0.01189171]
< returned_observation >
[ 0.39880485  0.70449628]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 582 #########################################
< action >
[-0.01078363  0.01203377]
< returned_observation >
[ 0.38802122  0.71653005]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 583 #########################################
< action >
[-0.01040937  0.01060622]
< returned_observation >
[ 0.37761186  0.72713628]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 584 #########################################
< action >
[-0.01014275  0.01109058]
< returned_observation >
[ 0.36746911  0.73822686]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 585 #########################################
< action >
[-0.0088916   0.01226569]
< returned_observation >
[ 0.35857751  0.75049255]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 586 #########################################
< action >
[-0.00952901  0.01352775]
< returned_observation >
[ 0.3490485   0.76402029]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 587 #########################################
< action >
[-0.00906697  0.01335599]
< returned_observation >
[ 0.33998153  0.77737628]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 588 #########################################
< action >
[-0.00988251  0.01429087]
< returned_observation >
[ 0.33009902  0.79166715]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 589 #########################################
< action >
[-0.00910633  0.01387115]
< returned_observation >
[ 0.32099269  0.8055383 ]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 590 #########################################
< action >
[-0.00883286  0.01350403]
< returned_observation >
[ 0.31215983  0.81904234]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 591 #########################################
< action >
[-0.00965121  0.01263134]
< returned_observation >
[ 0.30250862  0.83167368]
< reward >
-0.8000000000000007
< running_reward >
-0.2400000000000002
< done >
False
######################################### STEP 592 #########################################
< action >
[-0.00907736  0.01298296]
< returned_observation >
[ 0.29343126  0.84465664]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 593 #########################################
< action >
[-0.00875346  0.01325553]
< returned_observation >
[ 0.2846778   0.85791218]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 594 #########################################
< action >
[-0.00874192  0.01421337]
< returned_observation >
[ 0.27593588  0.87212555]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 595 #########################################
< action >
[-0.0104158  0.0150537]
< returned_observation >
[ 0.26552009  0.88717925]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 596 #########################################
< action >
[-0.01159599  0.01488741]
< returned_observation >
[ 0.25392409  0.90206666]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 597 #########################################
< action >
[-0.01152955  0.01494216]
< returned_observation >
[ 0.24239455  0.91700882]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 598 #########################################
< action >
[-0.01113254  0.01409568]
< returned_observation >
[ 0.231262   0.9311045]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 599 #########################################
< action >
[-0.00952364  0.01520613]
< returned_observation >
[ 0.22173836  0.94631063]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 600 #########################################
< action >
[-0.00906096  0.01594705]
< returned_observation >
[ 0.2126774   0.96225768]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 601 #########################################
< action >
[-0.0095064   0.01424245]
< returned_observation >
[ 0.203171    0.97650013]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 602 #########################################
< action >
[-0.01108631  0.014743  ]
< returned_observation >
[ 0.19208469  0.99124313]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 603 #########################################
< action >
[-0.01373135  0.01630989]
< returned_observation >
[ 0.17835334  1.        ]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 604 #########################################
< action >
[-0.01335825  0.01539974]
< returned_observation >
[ 0.16499509  1.        ]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 605 #########################################
< action >
[-0.01395369  0.01384106]
< returned_observation >
[ 0.15104139  1.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 606 #########################################
< action >
[-0.0141243   0.01424285]
< returned_observation >
[ 0.1369171  1.       ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 607 #########################################
< action >
[-0.01298417  0.01299905]
< returned_observation >
[ 0.12393293  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 608 #########################################
< action >
[-0.01198302  0.01324542]
< returned_observation >
[ 0.11194991  1.        ]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 609 #########################################
< action >
[-0.01212631  0.01330216]
< returned_observation >
[ 0.09982361  1.        ]
< reward >
-1.0
< running_reward >
-0.3
< done >
False
######################################### STEP 610 #########################################
< action >
[-0.01182049  0.01514946]
< returned_observation >
[ 0.08800312  1.        ]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 611 #########################################
< action >
[-0.01040682  0.01598882]
< returned_observation >
[ 0.0775963  1.       ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 612 #########################################
< action >
[-0.01120097  0.01578634]
< returned_observation >
[ 0.06639533  1.        ]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 613 #########################################
< action >
[-0.01037154  0.01617805]
< returned_observation >
[ 0.05602378  1.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 614 #########################################
< action >
[-0.01121079  0.01801895]
< returned_observation >
[ 0.04481299  1.        ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 615 #########################################
< action >
[-0.00890667  0.01856852]
< returned_observation >
[ 0.03590632  1.        ]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 616 #########################################
< action >
[-0.00931267  0.01859826]
< returned_observation >
[ 0.02659366  1.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 617 #########################################
< action >
[-0.01037154  0.01745121]
< returned_observation >
[ 0.01622211  1.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 618 #########################################
< action >
[-0.01008847  0.01724659]
< returned_observation >
[ 0.00613364  1.        ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 619 #########################################
< action >
[-0.00922368  0.02015706]
< returned_observation >
[ 0.  1.]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
True
##################### episode 7 infomation #####################
{'max_reward': 3.3999999999999986, 'nb_episode_steps': 73, 'min_reward': -14.2, 'episode_reward': -342.0999999999999, 'nb_steps': 620, 'ave_reward': -4.6863013698630125}
######################################### STEP 620 #########################################
< action >
[-0.02014675  0.01758625]
< returned_observation >
[ 0.39408827  0.31366618]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 621 #########################################
< action >
[-0.0186999   0.01782728]
< returned_observation >
[ 0.37538837  0.33149346]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 622 #########################################
< action >
[-0.01785063  0.0168678 ]
< returned_observation >
[ 0.35753774  0.34836126]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 623 #########################################
< action >
[-0.01878007  0.01675122]
< returned_observation >
[ 0.33875767  0.36511248]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 624 #########################################
< action >
[-0.01785316  0.01592048]
< returned_observation >
[ 0.3209045   0.38103296]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 625 #########################################
< action >
[-0.01655826  0.01508984]
< returned_observation >
[ 0.30434624  0.3961228 ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 626 #########################################
< action >
[-0.01635767  0.01514153]
< returned_observation >
[ 0.28798857  0.41126433]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 627 #########################################
< action >
[-0.0147677   0.01429443]
< returned_observation >
[ 0.27322088  0.42555876]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 628 #########################################
< action >
[-0.01560474  0.01412094]
< returned_observation >
[ 0.25761614  0.43967971]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 629 #########################################
< action >
[-0.01485397  0.01490471]
< returned_observation >
[ 0.24276217  0.45458442]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 630 #########################################
< action >
[-0.01604553  0.01421514]
< returned_observation >
[ 0.22671665  0.46879955]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 631 #########################################
< action >
[-0.01728125  0.0160123 ]
< returned_observation >
[ 0.2094354   0.48481185]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 632 #########################################
< action >
[-0.0168289  0.0167484]
< returned_observation >
[ 0.1926065   0.50156026]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 633 #########################################
< action >
[-0.01893513  0.01706778]
< returned_observation >
[ 0.17367137  0.51862804]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 634 #########################################
< action >
[-0.01913775  0.01812169]
< returned_observation >
[ 0.15453362  0.53674973]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 635 #########################################
< action >
[-0.0207048   0.01962735]
< returned_observation >
[ 0.13382882  0.55637708]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 636 #########################################
< action >
[-0.0199692   0.02036428]
< returned_observation >
[ 0.11385962  0.57674135]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 637 #########################################
< action >
[-0.02108532  0.02246106]
< returned_observation >
[ 0.0927743   0.59920241]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 638 #########################################
< action >
[-0.02071849  0.02293475]
< returned_observation >
[ 0.07205581  0.62213716]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 639 #########################################
< action >
[-0.02056846  0.02281693]
< returned_observation >
[ 0.05148735  0.6449541 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 640 #########################################
< action >
[-0.02028061  0.02315844]
< returned_observation >
[ 0.03120674  0.66811253]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 641 #########################################
< action >
[-0.01906555  0.02387688]
< returned_observation >
[ 0.01214119  0.69198941]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 642 #########################################
< action >
[-0.01965232  0.02424645]
< returned_observation >
[ 0.          0.71623586]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 643 #########################################
< action >
[-0.0185563   0.02378581]
< returned_observation >
[ 0.          0.74002167]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 644 #########################################
< action >
[-0.01851786  0.02507891]
< returned_observation >
[ 0.          0.76510058]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 645 #########################################
< action >
[-0.01795416  0.02474861]
< returned_observation >
[ 0.          0.78984919]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 646 #########################################
< action >
[-0.01723695  0.0258755 ]
< returned_observation >
[ 0.          0.81572469]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 647 #########################################
< action >
[-0.01642157  0.0262289 ]
< returned_observation >
[ 0.          0.84195359]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 648 #########################################
< action >
[-0.01443     0.02502439]
< returned_observation >
[ 0.          0.86697798]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 649 #########################################
< action >
[-0.01398203  0.02582576]
< returned_observation >
[ 0.          0.89280373]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 650 #########################################
< action >
[-0.01477741  0.0252187 ]
< returned_observation >
[ 0.          0.91802243]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 651 #########################################
< action >
[-0.01538509  0.02549996]
< returned_observation >
[ 0.          0.94352239]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 652 #########################################
< action >
[-0.01539958  0.02615824]
< returned_observation >
[ 0.          0.96968063]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 653 #########################################
< action >
[-0.01408895  0.02567763]
< returned_observation >
[ 0.          0.99535826]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 654 #########################################
< action >
[-0.01391788  0.02620139]
< returned_observation >
[ 0.  1.]
< reward >
0.0
< running_reward >
0.0
< done >
True
##################### episode 8 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 35, 'min_reward': -12.399999999999999, 'episode_reward': -121.60000000000002, 'nb_steps': 655, 'ave_reward': -3.474285714285715}
######################################### STEP 655 #########################################
< action >
[-0.02342157  0.01695393]
< returned_observation >
[ 0.60536634  0.59679174]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 656 #########################################
< action >
[-0.024357    0.01808212]
< returned_observation >
[ 0.58100934  0.61487386]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 657 #########################################
< action >
[-0.02497361  0.01746321]
< returned_observation >
[ 0.55603573  0.63233707]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 658 #########################################
< action >
[-0.02425623  0.01734134]
< returned_observation >
[ 0.5317795   0.64967841]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 659 #########################################
< action >
[-0.02564748  0.01844896]
< returned_observation >
[ 0.50613203  0.66812738]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 660 #########################################
< action >
[-0.02470064  0.01813387]
< returned_observation >
[ 0.48143139  0.68626124]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 661 #########################################
< action >
[-0.02638103  0.01744135]
< returned_observation >
[ 0.45505036  0.70370259]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 662 #########################################
< action >
[-0.02734757  0.01902076]
< returned_observation >
[ 0.42770278  0.72272335]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 663 #########################################
< action >
[-0.02811291  0.01977314]
< returned_observation >
[ 0.39958987  0.7424965 ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 664 #########################################
< action >
[-0.02692788  0.02006329]
< returned_observation >
[ 0.37266199  0.76255979]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 665 #########################################
< action >
[-0.02665481  0.02132466]
< returned_observation >
[ 0.34600718  0.78388445]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 666 #########################################
< action >
[-0.02591168  0.01978167]
< returned_observation >
[ 0.3200955   0.80366611]
< reward >
-1.0
< running_reward >
-0.3
< done >
False
######################################### STEP 667 #########################################
< action >
[-0.02493457  0.01756901]
< returned_observation >
[ 0.29516093  0.82123512]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 668 #########################################
< action >
[-0.0256705   0.01834608]
< returned_observation >
[ 0.26949043  0.8395812 ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 669 #########################################
< action >
[-0.02758242  0.01935319]
< returned_observation >
[ 0.24190801  0.85893439]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 670 #########################################
< action >
[-0.02547104  0.0191098 ]
< returned_observation >
[ 0.21643697  0.87804419]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 671 #########################################
< action >
[-0.02736622  0.02070459]
< returned_observation >
[ 0.18907075  0.89874878]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 672 #########################################
< action >
[-0.02840857  0.01938523]
< returned_observation >
[ 0.16066218  0.91813401]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 673 #########################################
< action >
[-0.02964198  0.01876773]
< returned_observation >
[ 0.1310202   0.93690174]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 674 #########################################
< action >
[-0.03043342  0.02059323]
< returned_observation >
[ 0.10058677  0.95749496]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 675 #########################################
< action >
[-0.03149609  0.01880705]
< returned_observation >
[ 0.06909068  0.97630201]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 676 #########################################
< action >
[-0.03321643  0.01824751]
< returned_observation >
[ 0.03587425  0.99454952]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 677 #########################################
< action >
[-0.03168487  0.01674724]
< returned_observation >
[ 0.00418938  1.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 678 #########################################
< action >
[-0.03202966  0.01736342]
< returned_observation >
[ 0.  1.]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
True
##################### episode 9 infomation #####################
{'max_reward': 3.1999999999999993, 'nb_episode_steps': 24, 'min_reward': -12.8, 'episode_reward': -69.4, 'nb_steps': 679, 'ave_reward': -2.891666666666667}
######################################### STEP 679 #########################################
< action >
[-0.02323404  0.01821556]
< returned_observation >
[ 0.57669516  0.28403468]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 680 #########################################
< action >
[-0.02413436  0.01954816]
< returned_observation >
[ 0.5525608   0.30358284]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 681 #########################################
< action >
[-0.02606573  0.02038556]
< returned_observation >
[ 0.52649507  0.3239684 ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 682 #########################################
< action >
[-0.02514155  0.02032145]
< returned_observation >
[ 0.50135352  0.34428984]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 683 #########################################
< action >
[-0.02558974  0.02145838]
< returned_observation >
[ 0.47576378  0.36574822]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 684 #########################################
< action >
[-0.02668422  0.02113179]
< returned_observation >
[ 0.44907956  0.38688001]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 685 #########################################
< action >
[-0.0276873   0.02130691]
< returned_observation >
[ 0.42139226  0.40818692]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 686 #########################################
< action >
[-0.02872041  0.02057168]
< returned_observation >
[ 0.39267185  0.42875859]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 687 #########################################
< action >
[-0.02816678  0.02046174]
< returned_observation >
[ 0.36450507  0.44922033]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 688 #########################################
< action >
[-0.02803725  0.02198627]
< returned_observation >
[ 0.33646782  0.4712066 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 689 #########################################
< action >
[-0.03012212  0.02133768]
< returned_observation >
[ 0.3063457   0.49254428]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 690 #########################################
< action >
[-0.03020244  0.02267219]
< returned_observation >
[ 0.27614326  0.51521648]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 691 #########################################
< action >
[-0.03137593  0.02247977]
< returned_observation >
[ 0.24476733  0.53769625]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 692 #########################################
< action >
[-0.03093192  0.02133143]
< returned_observation >
[ 0.21383541  0.55902767]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 693 #########################################
< action >
[-0.0314705   0.02126827]
< returned_observation >
[ 0.18236491  0.58029595]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 694 #########################################
< action >
[-0.03208655  0.02178265]
< returned_observation >
[ 0.15027836  0.6020786 ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 695 #########################################
< action >
[-0.03127923  0.02131882]
< returned_observation >
[ 0.11899913  0.62339742]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 696 #########################################
< action >
[-0.0306915   0.02172128]
< returned_observation >
[ 0.08830763  0.6451187 ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 697 #########################################
< action >
[-0.03076298  0.02094209]
< returned_observation >
[ 0.05754465  0.66606079]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 698 #########################################
< action >
[-0.02921071  0.01980508]
< returned_observation >
[ 0.02833395  0.68586587]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 699 #########################################
< action >
[-0.02902766  0.0206091 ]
< returned_observation >
[ 0.          0.70647497]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 700 #########################################
< action >
[-0.03161694  0.01990564]
< returned_observation >
[ 0.          0.72638061]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 701 #########################################
< action >
[-0.033566    0.01966366]
< returned_observation >
[ 0.          0.74604428]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 702 #########################################
< action >
[-0.0329984   0.01892865]
< returned_observation >
[ 0.          0.76497293]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 703 #########################################
< action >
[-0.03299584  0.01960662]
< returned_observation >
[ 0.          0.78457955]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 704 #########################################
< action >
[-0.03378441  0.0192838 ]
< returned_observation >
[ 0.          0.80386335]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 705 #########################################
< action >
[-0.03488401  0.01976002]
< returned_observation >
[ 0.          0.82362337]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 706 #########################################
< action >
[-0.03520724  0.02118413]
< returned_observation >
[ 0.         0.8448075]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 707 #########################################
< action >
[-0.03402542  0.01983132]
< returned_observation >
[ 0.          0.86463883]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 708 #########################################
< action >
[-0.03387979  0.02002435]
< returned_observation >
[ 0.          0.88466317]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 709 #########################################
< action >
[-0.03375919  0.02037322]
< returned_observation >
[ 0.          0.90503639]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 710 #########################################
< action >
[-0.03401737  0.02131257]
< returned_observation >
[ 0.          0.92634896]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 711 #########################################
< action >
[-0.03339643  0.02170717]
< returned_observation >
[ 0.          0.94805613]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 712 #########################################
< action >
[-0.03398651  0.02283772]
< returned_observation >
[ 0.          0.97089386]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 713 #########################################
< action >
[-0.03541259  0.02383444]
< returned_observation >
[ 0.          0.99472829]
< reward >
-0.6999999999999993
< running_reward >
-0.20999999999999977
< done >
False
######################################### STEP 714 #########################################
< action >
[-0.03483031  0.02297888]
< returned_observation >
[ 0.  1.]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
True
##################### episode 10 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 36, 'min_reward': -12.2, 'episode_reward': -78.4, 'nb_steps': 715, 'ave_reward': -2.177777777777778}
######################################### STEP 715 #########################################
< action >
[-0.02395753  0.01765758]
< returned_observation >
[ 0.26072835  0.27124578]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 716 #########################################
< action >
[-0.02380603  0.01824922]
< returned_observation >
[ 0.23692232  0.289495  ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 717 #########################################
< action >
[-0.02207972  0.01806713]
< returned_observation >
[ 0.2148426   0.30756213]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 718 #########################################
< action >
[-0.02114468  0.01828007]
< returned_observation >
[ 0.19369792  0.3258422 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 719 #########################################
< action >
[-0.01995327  0.01870655]
< returned_observation >
[ 0.17374464  0.34454876]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 720 #########################################
< action >
[-0.02098186  0.0194507 ]
< returned_observation >
[ 0.15276279  0.36399946]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 721 #########################################
< action >
[-0.01988957  0.01926249]
< returned_observation >
[ 0.13287321  0.38326195]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 722 #########################################
< action >
[-0.02200536  0.01835161]
< returned_observation >
[ 0.11086785  0.40161356]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 723 #########################################
< action >
[-0.02200415  0.01905178]
< returned_observation >
[ 0.08886371  0.42066535]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 724 #########################################
< action >
[-0.02254716  0.0200597 ]
< returned_observation >
[ 0.06631654  0.44072505]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 725 #########################################
< action >
[-0.02309617  0.01869797]
< returned_observation >
[ 0.04322037  0.45942302]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 726 #########################################
< action >
[-0.02269213  0.01802369]
< returned_observation >
[ 0.02052823  0.47744671]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 727 #########################################
< action >
[-0.02141646  0.01911532]
< returned_observation >
[ 0.          0.49656203]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 728 #########################################
< action >
[-0.02185439  0.01849385]
< returned_observation >
[ 0.          0.51505588]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 729 #########################################
< action >
[-0.02167329  0.01962827]
< returned_observation >
[ 0.          0.53468415]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 730 #########################################
< action >
[-0.02157845  0.01949902]
< returned_observation >
[ 0.          0.55418317]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 731 #########################################
< action >
[-0.02054024  0.02016334]
< returned_observation >
[ 0.          0.57434651]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 732 #########################################
< action >
[-0.02124563  0.01950981]
< returned_observation >
[ 0.          0.59385632]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 733 #########################################
< action >
[-0.02346555  0.01926097]
< returned_observation >
[ 0.          0.61311729]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 734 #########################################
< action >
[-0.02388351  0.01972502]
< returned_observation >
[ 0.          0.63284231]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 735 #########################################
< action >
[-0.02460697  0.0192881 ]
< returned_observation >
[ 0.          0.65213041]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 736 #########################################
< action >
[-0.02504291  0.01874806]
< returned_observation >
[ 0.          0.67087847]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 737 #########################################
< action >
[-0.02539178  0.01814159]
< returned_observation >
[ 0.          0.68902006]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 738 #########################################
< action >
[-0.02427223  0.01796274]
< returned_observation >
[ 0.         0.7069828]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 739 #########################################
< action >
[-0.02394031  0.01829019]
< returned_observation >
[ 0.        0.725273]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 740 #########################################
< action >
[-0.02504303  0.01626222]
< returned_observation >
[ 0.          0.74153521]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 741 #########################################
< action >
[-0.02626197  0.01586499]
< returned_observation >
[ 0.         0.7574002]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 742 #########################################
< action >
[-0.02633915  0.01444656]
< returned_observation >
[ 0.          0.77184676]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 743 #########################################
< action >
[-0.02578991  0.01405579]
< returned_observation >
[ 0.          0.78590255]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 744 #########################################
< action >
[-0.0250704   0.01307243]
< returned_observation >
[ 0.          0.79897497]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 745 #########################################
< action >
[-0.02802234  0.0135544 ]
< returned_observation >
[ 0.          0.81252937]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 746 #########################################
< action >
[-0.02765796  0.01573759]
< returned_observation >
[ 0.          0.82826696]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 747 #########################################
< action >
[-0.02766462  0.01597892]
< returned_observation >
[ 0.          0.84424588]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 748 #########################################
< action >
[-0.02602873  0.0131573 ]
< returned_observation >
[ 0.          0.85740318]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 749 #########################################
< action >
[-0.02757539  0.01114493]
< returned_observation >
[ 0.          0.86854811]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 750 #########################################
< action >
[-0.027345    0.01081431]
< returned_observation >
[ 0.          0.87936242]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 751 #########################################
< action >
[-0.02693525  0.00914996]
< returned_observation >
[ 0.          0.88851239]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 752 #########################################
< action >
[-0.02780199  0.0090037 ]
< returned_observation >
[ 0.          0.89751609]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 753 #########################################
< action >
[-0.02814256  0.00858443]
< returned_observation >
[ 0.          0.90610052]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 754 #########################################
< action >
[-0.02726083  0.00772913]
< returned_observation >
[ 0.          0.91382965]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 755 #########################################
< action >
[-0.0279165  0.0070873]
< returned_observation >
[ 0.          0.92091694]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 756 #########################################
< action >
[-0.02747123  0.00591585]
< returned_observation >
[ 0.         0.9268328]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 757 #########################################
< action >
[-0.02869614  0.00479816]
< returned_observation >
[ 0.          0.93163095]
< reward >
-0.6999999999999993
< running_reward >
-0.20999999999999977
< done >
False
######################################### STEP 758 #########################################
< action >
[-0.03053354  0.00441884]
< returned_observation >
[ 0.          0.93604979]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 759 #########################################
< action >
[-0.03139213  0.00217982]
< returned_observation >
[ 0.          0.93822961]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 760 #########################################
< action >
[-0.0321645   0.00203971]
< returned_observation >
[ 0.          0.94026932]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 761 #########################################
< action >
[-0.03081782  0.00175123]
< returned_observation >
[ 0.          0.94202055]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 762 #########################################
< action >
[-0.02969299  0.00176138]
< returned_observation >
[ 0.          0.94378193]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 763 #########################################
< action >
[-0.02859446  0.00036864]
< returned_observation >
[ 0.          0.94415057]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 764 #########################################
< action >
[ -3.01870376e-02  -3.82512808e-05]
< returned_observation >
[ 0.          0.94411232]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 765 #########################################
< action >
[-0.03072527 -0.00018473]
< returned_observation >
[ 0.          0.94392759]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 766 #########################################
< action >
[-0.03049701 -0.00152479]
< returned_observation >
[ 0.          0.94240279]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 767 #########################################
< action >
[-0.03050235 -0.00225182]
< returned_observation >
[ 0.          0.94015097]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 768 #########################################
< action >
[-0.02875291 -0.00259962]
< returned_observation >
[ 0.          0.93755136]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 769 #########################################
< action >
[-0.02941516 -0.00098982]
< returned_observation >
[ 0.          0.93656153]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 770 #########################################
< action >
[-0.03119518  0.0005259 ]
< returned_observation >
[ 0.          0.93708743]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 771 #########################################
< action >
[ -3.10076818e-02  -2.92897224e-05]
< returned_observation >
[ 0.          0.93705815]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 772 #########################################
< action >
[-0.0315825  -0.00012322]
< returned_observation >
[ 0.          0.93693492]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 773 #########################################
< action >
[-0.03142554 -0.00097162]
< returned_observation >
[ 0.         0.9359633]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 774 #########################################
< action >
[-0.03121033 -0.00036363]
< returned_observation >
[ 0.          0.93559967]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 775 #########################################
< action >
[-0.03134853  0.00105245]
< returned_observation >
[ 0.          0.93665212]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 776 #########################################
< action >
[-0.03242452  0.00106325]
< returned_observation >
[ 0.          0.93771537]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 777 #########################################
< action >
[-0.0315895   0.00141854]
< returned_observation >
[ 0.          0.93913391]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 778 #########################################
< action >
[-0.03023699  0.00228378]
< returned_observation >
[ 0.          0.94141769]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 779 #########################################
< action >
[-0.03144529  0.00361951]
< returned_observation >
[ 0.         0.9450372]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 780 #########################################
< action >
[-0.03212742  0.00466994]
< returned_observation >
[ 0.          0.94970714]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 781 #########################################
< action >
[-0.03217514  0.00573114]
< returned_observation >
[ 0.          0.95543828]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 782 #########################################
< action >
[-0.03464405  0.00640028]
< returned_observation >
[ 0.          0.96183856]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 783 #########################################
< action >
[-0.03487364  0.00787862]
< returned_observation >
[ 0.          0.96971717]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 784 #########################################
< action >
[-0.03336529  0.00920978]
< returned_observation >
[ 0.          0.97892695]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 785 #########################################
< action >
[-0.03356166  0.0092333 ]
< returned_observation >
[ 0.          0.98816025]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 786 #########################################
< action >
[-0.03444953  0.00914184]
< returned_observation >
[ 0.          0.99730209]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 787 #########################################
< action >
[-0.03437649  0.00965528]
< returned_observation >
[ 0.  1.]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
True
##################### episode 11 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 73, 'min_reward': -11.899999999999999, 'episode_reward': -70.99999999999996, 'nb_steps': 788, 'ave_reward': -0.9726027397260268}
######################################### STEP 788 #########################################
< action >
[-0.02614743  0.01844597]
< returned_observation >
[ 0.30141652  0.16261027]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 789 #########################################
< action >
[-0.0263403   0.01673532]
< returned_observation >
[ 0.27507622  0.17934559]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 790 #########################################
< action >
[-0.02684151  0.01609613]
< returned_observation >
[ 0.24823471  0.19544172]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 791 #########################################
< action >
[-0.02804818  0.01624636]
< returned_observation >
[ 0.22018653  0.21168808]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 792 #########################################
< action >
[-0.02850574  0.01593171]
< returned_observation >
[ 0.1916808  0.2276198]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 793 #########################################
< action >
[-0.0284625   0.01577774]
< returned_observation >
[ 0.16321829  0.24339754]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 794 #########################################
< action >
[-0.02801613  0.01623222]
< returned_observation >
[ 0.13520217  0.25962976]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 795 #########################################
< action >
[-0.02787958  0.01656258]
< returned_observation >
[ 0.10732259  0.27619234]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 796 #########################################
< action >
[-0.02723446  0.0161422 ]
< returned_observation >
[ 0.08008813  0.29233454]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 797 #########################################
< action >
[-0.02628244  0.017382  ]
< returned_observation >
[ 0.05380568  0.30971654]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 798 #########################################
< action >
[-0.02649111  0.01865911]
< returned_observation >
[ 0.02731457  0.32837566]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 799 #########################################
< action >
[-0.02599335  0.01908104]
< returned_observation >
[ 0.00132122  0.34745669]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 800 #########################################
< action >
[-0.02428112  0.0177345 ]
< returned_observation >
[ 0.          0.36519119]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 801 #########################################
< action >
[-0.02351808  0.01701858]
< returned_observation >
[ 0.          0.38220977]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 802 #########################################
< action >
[-0.02339792  0.01478016]
< returned_observation >
[ 0.          0.39698994]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 803 #########################################
< action >
[-0.02265028  0.01588386]
< returned_observation >
[ 0.         0.4128738]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 804 #########################################
< action >
[-0.02376251  0.01736535]
< returned_observation >
[ 0.          0.43023915]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 805 #########################################
< action >
[-0.02445273  0.01710743]
< returned_observation >
[ 0.          0.44734658]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 806 #########################################
< action >
[-0.02569816  0.01740025]
< returned_observation >
[ 0.          0.46474683]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 807 #########################################
< action >
[-0.02624824  0.01702265]
< returned_observation >
[ 0.          0.48176948]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 808 #########################################
< action >
[-0.02637089  0.01573425]
< returned_observation >
[ 0.          0.49750373]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 809 #########################################
< action >
[-0.02608252  0.01521355]
< returned_observation >
[ 0.          0.51271728]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 810 #########################################
< action >
[-0.02498313  0.01490011]
< returned_observation >
[ 0.          0.52761739]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 811 #########################################
< action >
[-0.02474661  0.01506331]
< returned_observation >
[ 0.         0.5426807]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 812 #########################################
< action >
[-0.02380913  0.01621894]
< returned_observation >
[ 0.          0.55889964]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 813 #########################################
< action >
[-0.02402647  0.01496245]
< returned_observation >
[ 0.          0.57386209]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 814 #########################################
< action >
[-0.02435834  0.01427775]
< returned_observation >
[ 0.          0.58813984]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 815 #########################################
< action >
[-0.0240156   0.01368978]
< returned_observation >
[ 0.          0.60182962]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 816 #########################################
< action >
[-0.02398552  0.01359445]
< returned_observation >
[ 0.          0.61542407]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 817 #########################################
< action >
[-0.02402368  0.01234353]
< returned_observation >
[ 0.         0.6277676]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 818 #########################################
< action >
[-0.02324303  0.01156742]
< returned_observation >
[ 0.          0.63933502]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 819 #########################################
< action >
[-0.02515707  0.01050736]
< returned_observation >
[ 0.          0.64984238]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 820 #########################################
< action >
[-0.02581477  0.00979186]
< returned_observation >
[ 0.          0.65963425]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 821 #########################################
< action >
[-0.02573858  0.00894188]
< returned_observation >
[ 0.          0.66857612]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 822 #########################################
< action >
[-0.02581387  0.0095629 ]
< returned_observation >
[ 0.          0.67813903]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 823 #########################################
< action >
[-0.0269449   0.00865585]
< returned_observation >
[ 0.          0.68679487]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 824 #########################################
< action >
[-0.02575281  0.00888357]
< returned_observation >
[ 0.          0.69567844]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 825 #########################################
< action >
[-0.02509426  0.00852153]
< returned_observation >
[ 0.          0.70419997]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 826 #########################################
< action >
[-0.0253095   0.00820117]
< returned_observation >
[ 0.          0.71240114]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 827 #########################################
< action >
[-0.02628595  0.00910168]
< returned_observation >
[ 0.          0.72150282]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 828 #########################################
< action >
[-0.02761079  0.00825719]
< returned_observation >
[ 0.          0.72976001]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 829 #########################################
< action >
[-0.02893256  0.00988932]
< returned_observation >
[ 0.          0.73964933]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 830 #########################################
< action >
[-0.02998144  0.01085268]
< returned_observation >
[ 0.          0.75050201]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 831 #########################################
< action >
[-0.03147407  0.01267954]
< returned_observation >
[ 0.          0.76318154]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 832 #########################################
< action >
[-0.02915438  0.01246632]
< returned_observation >
[ 0.          0.77564787]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 833 #########################################
< action >
[-0.02780569  0.01103394]
< returned_observation >
[ 0.          0.78668181]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 834 #########################################
< action >
[-0.02838734  0.0121415 ]
< returned_observation >
[ 0.         0.7988233]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 835 #########################################
< action >
[-0.02843404  0.01151486]
< returned_observation >
[ 0.          0.81033816]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 836 #########################################
< action >
[-0.02849851  0.01080292]
< returned_observation >
[ 0.          0.82114109]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 837 #########################################
< action >
[-0.02931333  0.01157505]
< returned_observation >
[ 0.          0.83271614]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 838 #########################################
< action >
[-0.03133034  0.0108413 ]
< returned_observation >
[ 0.          0.84355744]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 839 #########################################
< action >
[-0.03146373  0.01158906]
< returned_observation >
[ 0.         0.8551465]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 840 #########################################
< action >
[-0.03143699  0.01100877]
< returned_observation >
[ 0.          0.86615527]
< reward >
-1.0
< running_reward >
-0.3
< done >
False
######################################### STEP 841 #########################################
< action >
[-0.03378869  0.01371837]
< returned_observation >
[ 0.          0.87987363]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 842 #########################################
< action >
[-0.03467846  0.01423848]
< returned_observation >
[ 0.          0.89411211]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 843 #########################################
< action >
[-0.03604944  0.01498527]
< returned_observation >
[ 0.          0.90909738]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 844 #########################################
< action >
[-0.03755882  0.01424582]
< returned_observation >
[ 0.         0.9233432]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 845 #########################################
< action >
[-0.03758911  0.01287397]
< returned_observation >
[ 0.          0.93621717]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 846 #########################################
< action >
[-0.03691464  0.01277738]
< returned_observation >
[ 0.          0.94899455]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 847 #########################################
< action >
[-0.0358784  0.0135172]
< returned_observation >
[ 0.          0.96251175]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 848 #########################################
< action >
[-0.03636128  0.01223373]
< returned_observation >
[ 0.          0.97474548]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 849 #########################################
< action >
[-0.03678616  0.01317736]
< returned_observation >
[ 0.          0.98792284]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 850 #########################################
< action >
[-0.03845765  0.01412509]
< returned_observation >
[ 0.  1.]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
True
##################### episode 12 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 63, 'min_reward': -12.7, 'episode_reward': -98.00000000000004, 'nb_steps': 851, 'ave_reward': -1.5555555555555562}
######################################### STEP 851 #########################################
< action >
[-0.02762755  0.01448054]
< returned_observation >
[ 0.13798531  0.97841107]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 852 #########################################
< action >
[-0.02913462  0.0143352 ]
< returned_observation >
[ 0.10885069  0.99274627]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 853 #########################################
< action >
[-0.02871457  0.01295497]
< returned_observation >
[ 0.08013612  1.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 854 #########################################
< action >
[-0.02836605  0.01309015]
< returned_observation >
[ 0.05177007  1.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 855 #########################################
< action >
[-0.0297086   0.01111496]
< returned_observation >
[ 0.02206147  1.        ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 856 #########################################
< action >
[-0.02981098  0.01065652]
< returned_observation >
[ 0.  1.]
< reward >
2.5
< running_reward >
0.75
< done >
True
##################### episode 13 infomation #####################
{'max_reward': 2.5, 'nb_episode_steps': 6, 'min_reward': 0.0, 'episode_reward': 7.799999999999997, 'nb_steps': 857, 'ave_reward': 1.2999999999999996}
######################################### STEP 857 #########################################
< action >
[-0.02615955  0.01562073]
< returned_observation >
[ 0.93406716  0.20403538]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 858 #########################################
< action >
[-0.02572615  0.01472184]
< returned_observation >
[ 0.90834102  0.21875722]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 859 #########################################
< action >
[-0.02582379  0.01571464]
< returned_observation >
[ 0.88251722  0.23447186]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 860 #########################################
< action >
[-0.02683661  0.01499662]
< returned_observation >
[ 0.85568061  0.24946848]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 861 #########################################
< action >
[-0.02730878  0.01436081]
< returned_observation >
[ 0.82837183  0.26382929]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 862 #########################################
< action >
[-0.02684033  0.01348495]
< returned_observation >
[ 0.8015315   0.27731424]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 863 #########################################
< action >
[-0.02676743  0.01364996]
< returned_observation >
[ 0.77476407  0.29096421]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 864 #########################################
< action >
[-0.0265703   0.01376201]
< returned_observation >
[ 0.74819377  0.30472622]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 865 #########################################
< action >
[-0.02804468  0.01235197]
< returned_observation >
[ 0.72014909  0.31707819]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 866 #########################################
< action >
[-0.02991924  0.01242588]
< returned_observation >
[ 0.69022985  0.32950407]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 867 #########################################
< action >
[-0.02942879  0.01281682]
< returned_observation >
[ 0.66080105  0.34232089]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 868 #########################################
< action >
[-0.02795879  0.01248031]
< returned_observation >
[ 0.63284226  0.35480119]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 869 #########################################
< action >
[-0.0269273   0.01257914]
< returned_observation >
[ 0.60591496  0.36738034]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 870 #########################################
< action >
[-0.0261153   0.01179106]
< returned_observation >
[ 0.57979966  0.3791714 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 871 #########################################
< action >
[-0.0262482   0.01089655]
< returned_observation >
[ 0.55355146  0.39006795]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 872 #########################################
< action >
[-0.02740198  0.00866926]
< returned_observation >
[ 0.52614948  0.39873721]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 873 #########################################
< action >
[-0.02645952  0.00896637]
< returned_observation >
[ 0.49968996  0.40770358]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 874 #########################################
< action >
[-0.02363336  0.0089797 ]
< returned_observation >
[ 0.4760566   0.41668328]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 875 #########################################
< action >
[-0.02327606  0.00790968]
< returned_observation >
[ 0.45278053  0.42459296]
< reward >
4.0
< running_reward >
1.2
< done >
False
######################################### STEP 876 #########################################
< action >
[-0.02219862  0.00722042]
< returned_observation >
[ 0.43058191  0.43181338]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 877 #########################################
< action >
[-0.02012083  0.0096204 ]
< returned_observation >
[ 0.41046109  0.44143377]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 878 #########################################
< action >
[-0.02208306  0.00887572]
< returned_observation >
[ 0.38837802  0.4503095 ]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 879 #########################################
< action >
[-0.0234166   0.00801812]
< returned_observation >
[ 0.36496142  0.45832762]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 880 #########################################
< action >
[-0.02470091  0.00835401]
< returned_observation >
[ 0.34026051  0.46668163]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 881 #########################################
< action >
[-0.02342166  0.00844043]
< returned_observation >
[ 0.31683884  0.47512207]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 882 #########################################
< action >
[-0.02203669  0.00890138]
< returned_observation >
[ 0.29480215  0.48402345]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 883 #########################################
< action >
[-0.02094879  0.01041366]
< returned_observation >
[ 0.27385336  0.49443711]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 884 #########################################
< action >
[-0.02178058  0.0120887 ]
< returned_observation >
[ 0.25207278  0.50652582]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 885 #########################################
< action >
[-0.02265735  0.01111268]
< returned_observation >
[ 0.22941542  0.5176385 ]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 886 #########################################
< action >
[-0.02181041  0.01018864]
< returned_observation >
[ 0.20760502  0.52782714]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 887 #########################################
< action >
[-0.02287894  0.01095601]
< returned_observation >
[ 0.18472608  0.53878315]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 888 #########################################
< action >
[-0.02316845  0.01033756]
< returned_observation >
[ 0.16155763  0.5491207 ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 889 #########################################
< action >
[-0.02395216  0.0093524 ]
< returned_observation >
[ 0.13760547  0.55847311]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 890 #########################################
< action >
[-0.02374979  0.00914216]
< returned_observation >
[ 0.11385568  0.56761527]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 891 #########################################
< action >
[-0.02441781  0.01120356]
< returned_observation >
[ 0.08943787  0.57881883]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 892 #########################################
< action >
[-0.02379157  0.00988153]
< returned_observation >
[ 0.0656463   0.58870036]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 893 #########################################
< action >
[-0.0235126   0.00913358]
< returned_observation >
[ 0.0421337   0.59783394]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 894 #########################################
< action >
[-0.0240698  0.0109912]
< returned_observation >
[ 0.01806389  0.60882514]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 895 #########################################
< action >
[-0.02279336  0.01123164]
< returned_observation >
[ 0.          0.62005678]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 896 #########################################
< action >
[-0.02170809  0.009715  ]
< returned_observation >
[ 0.          0.62977178]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 897 #########################################
< action >
[-0.02101779  0.0104588 ]
< returned_observation >
[ 0.          0.64023058]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 898 #########################################
< action >
[-0.02177301  0.00872173]
< returned_observation >
[ 0.          0.64895231]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 899 #########################################
< action >
[-0.02121367  0.00895246]
< returned_observation >
[ 0.          0.65790477]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 900 #########################################
< action >
[-0.02133934  0.00895931]
< returned_observation >
[ 0.          0.66686408]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 901 #########################################
< action >
[-0.02127601  0.00981351]
< returned_observation >
[ 0.          0.67667758]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 902 #########################################
< action >
[-0.01982978  0.00930021]
< returned_observation >
[ 0.         0.6859778]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 903 #########################################
< action >
[-0.01857284  0.00878254]
< returned_observation >
[ 0.          0.69476034]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 904 #########################################
< action >
[-0.01933891  0.00846002]
< returned_observation >
[ 0.          0.70322035]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 905 #########################################
< action >
[-0.01875005  0.00889142]
< returned_observation >
[ 0.          0.71211178]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 906 #########################################
< action >
[-0.01883601  0.00776948]
< returned_observation >
[ 0.          0.71988126]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 907 #########################################
< action >
[-0.01792322  0.00736617]
< returned_observation >
[ 0.          0.72724743]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 908 #########################################
< action >
[-0.018027    0.00646654]
< returned_observation >
[ 0.          0.73371397]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 909 #########################################
< action >
[-0.01633737  0.00596291]
< returned_observation >
[ 0.          0.73967688]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 910 #########################################
< action >
[-0.01777852  0.00668732]
< returned_observation >
[ 0.         0.7463642]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 911 #########################################
< action >
[-0.01788764  0.00745777]
< returned_observation >
[ 0.          0.75382197]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 912 #########################################
< action >
[-0.0171266   0.00561721]
< returned_observation >
[ 0.          0.75943919]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 913 #########################################
< action >
[-0.01746004  0.00786413]
< returned_observation >
[ 0.          0.76730332]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 914 #########################################
< action >
[-0.01702101  0.00829049]
< returned_observation >
[ 0.         0.7755938]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 915 #########################################
< action >
[-0.01606604  0.00946406]
< returned_observation >
[ 0.          0.78505787]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 916 #########################################
< action >
[-0.01608523  0.01028252]
< returned_observation >
[ 0.          0.79534038]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 917 #########################################
< action >
[-0.01536916  0.01045794]
< returned_observation >
[ 0.          0.80579833]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 918 #########################################
< action >
[-0.01542536  0.01115882]
< returned_observation >
[ 0.          0.81695714]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 919 #########################################
< action >
[-0.01510125  0.01015637]
< returned_observation >
[ 0.          0.82711351]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 920 #########################################
< action >
[-0.01645155  0.01004423]
< returned_observation >
[ 0.          0.83715774]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 921 #########################################
< action >
[-0.01658575  0.01139561]
< returned_observation >
[ 0.          0.84855335]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 922 #########################################
< action >
[-0.01665299  0.01128403]
< returned_observation >
[ 0.          0.85983738]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 923 #########################################
< action >
[-0.01711384  0.01140984]
< returned_observation >
[ 0.          0.87124722]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 924 #########################################
< action >
[-0.01677543  0.01242923]
< returned_observation >
[ 0.          0.88367645]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 925 #########################################
< action >
[-0.01733141  0.01286737]
< returned_observation >
[ 0.          0.89654382]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 926 #########################################
< action >
[-0.01646999  0.01106724]
< returned_observation >
[ 0.          0.90761106]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 927 #########################################
< action >
[-0.01623796  0.01006665]
< returned_observation >
[ 0.          0.91767771]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 928 #########################################
< action >
[-0.01684776  0.00971029]
< returned_observation >
[ 0.        0.927388]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 929 #########################################
< action >
[-0.01722818  0.008748  ]
< returned_observation >
[ 0.        0.936136]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 930 #########################################
< action >
[-0.01712448  0.00920227]
< returned_observation >
[ 0.          0.94533827]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 931 #########################################
< action >
[-0.0174779   0.00802076]
< returned_observation >
[ 0.          0.95335903]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 932 #########################################
< action >
[-0.01799991  0.00956844]
< returned_observation >
[ 0.          0.96292747]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 933 #########################################
< action >
[-0.01747826  0.00895616]
< returned_observation >
[ 0.          0.97188363]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 934 #########################################
< action >
[-0.01862352  0.00909879]
< returned_observation >
[ 0.          0.98098242]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 935 #########################################
< action >
[-0.01848266  0.01119919]
< returned_observation >
[ 0.          0.99218161]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 936 #########################################
< action >
[-0.02011527  0.01153152]
< returned_observation >
[ 0.  1.]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
True
##################### episode 14 infomation #####################
{'max_reward': 4.0, 'nb_episode_steps': 80, 'min_reward': -13.600000000000001, 'episode_reward': -206.4, 'nb_steps': 937, 'ave_reward': -2.58}
######################################### STEP 937 #########################################
< action >
[-0.03148349  0.01047319]
< returned_observation >
[ 0.          0.21502873]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 938 #########################################
< action >
[-0.03141375  0.01072898]
< returned_observation >
[ 0.          0.22575771]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 939 #########################################
< action >
[-0.03102687  0.00994049]
< returned_observation >
[ 0.         0.2356982]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 940 #########################################
< action >
[-0.03056623  0.00898269]
< returned_observation >
[ 0.          0.24468089]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 941 #########################################
< action >
[-0.03210968  0.0082989 ]
< returned_observation >
[ 0.          0.25297979]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 942 #########################################
< action >
[-0.03193739  0.00986323]
< returned_observation >
[ 0.          0.26284302]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 943 #########################################
< action >
[-0.03238528  0.01124148]
< returned_observation >
[ 0.         0.2740845]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 944 #########################################
< action >
[-0.03328236  0.01049804]
< returned_observation >
[ 0.          0.28458254]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 945 #########################################
< action >
[-0.03479214  0.01030371]
< returned_observation >
[ 0.          0.29488625]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 946 #########################################
< action >
[-0.03489797  0.01099145]
< returned_observation >
[ 0.         0.3058777]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 947 #########################################
< action >
[-0.03536887  0.01101307]
< returned_observation >
[ 0.          0.31689078]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 948 #########################################
< action >
[-0.03668343  0.01062723]
< returned_observation >
[ 0.        0.327518]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 949 #########################################
< action >
[-0.03507041  0.00943774]
< returned_observation >
[ 0.          0.33695574]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 950 #########################################
< action >
[-0.03514115  0.01015675]
< returned_observation >
[ 0.          0.34711249]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 951 #########################################
< action >
[-0.03458308  0.00979586]
< returned_observation >
[ 0.          0.35690836]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 952 #########################################
< action >
[-0.035198    0.00839456]
< returned_observation >
[ 0.          0.36530292]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 953 #########################################
< action >
[-0.03402374  0.00661485]
< returned_observation >
[ 0.          0.37191777]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 954 #########################################
< action >
[-0.03448939  0.00525679]
< returned_observation >
[ 0.          0.37717456]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 955 #########################################
< action >
[-0.03519751  0.00375769]
< returned_observation >
[ 0.          0.38093224]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 956 #########################################
< action >
[-0.03543982  0.00435097]
< returned_observation >
[ 0.          0.38528321]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 957 #########################################
< action >
[-0.03620122  0.00409128]
< returned_observation >
[ 0.          0.38937449]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 958 #########################################
< action >
[-0.03621293  0.00347566]
< returned_observation >
[ 0.          0.39285015]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 959 #########################################
< action >
[-0.0346299   0.00234101]
< returned_observation >
[ 0.          0.39519116]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 960 #########################################
< action >
[-0.03532747  0.00306056]
< returned_observation >
[ 0.          0.39825172]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 961 #########################################
< action >
[-0.03526972  0.00274489]
< returned_observation >
[ 0.          0.40099661]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 962 #########################################
< action >
[-0.03421696  0.00044513]
< returned_observation >
[ 0.          0.40144174]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 963 #########################################
< action >
[-0.03399693  0.00159219]
< returned_observation >
[ 0.          0.40303393]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 964 #########################################
< action >
[-0.03533588  0.00430083]
< returned_observation >
[ 0.          0.40733476]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 965 #########################################
< action >
[-0.03502107  0.00460318]
< returned_observation >
[ 0.          0.41193794]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 966 #########################################
< action >
[-0.03453148  0.00461888]
< returned_observation >
[ 0.          0.41655682]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 967 #########################################
< action >
[-0.03233541  0.00329363]
< returned_observation >
[ 0.          0.41985044]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 968 #########################################
< action >
[-0.03326731  0.0037825 ]
< returned_observation >
[ 0.          0.42363295]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 969 #########################################
< action >
[-0.03268905  0.00263975]
< returned_observation >
[ 0.         0.4262727]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 970 #########################################
< action >
[-0.03162285  0.00136144]
< returned_observation >
[ 0.          0.42763414]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 971 #########################################
< action >
[-0.0323072   0.00078871]
< returned_observation >
[ 0.          0.42842285]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 972 #########################################
< action >
[-0.03224687  0.00051062]
< returned_observation >
[ 0.          0.42893346]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 973 #########################################
< action >
[-0.03199462  0.00108519]
< returned_observation >
[ 0.          0.43001865]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 974 #########################################
< action >
[ -3.13066676e-02   2.02119350e-05]
< returned_observation >
[ 0.          0.43003886]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 975 #########################################
< action >
[-0.03194203  0.00135638]
< returned_observation >
[ 0.          0.43139524]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 976 #########################################
< action >
[-0.03133747  0.00200232]
< returned_observation >
[ 0.          0.43339756]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 977 #########################################
< action >
[-0.03254028 -0.00156459]
< returned_observation >
[ 0.          0.43183297]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 978 #########################################
< action >
[-0.03218196  0.00068243]
< returned_observation >
[ 0.         0.4325154]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 979 #########################################
< action >
[-0.03425952  0.00091598]
< returned_observation >
[ 0.          0.43343138]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 980 #########################################
< action >
[-0.03415617 -0.00126126]
< returned_observation >
[ 0.          0.43217012]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 981 #########################################
< action >
[-0.03292296 -0.00111327]
< returned_observation >
[ 0.          0.43105685]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 982 #########################################
< action >
[-0.03372952 -0.00063408]
< returned_observation >
[ 0.          0.43042277]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 983 #########################################
< action >
[-0.03400758  0.00025972]
< returned_observation >
[ 0.          0.43068249]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 984 #########################################
< action >
[ -3.22678223e-02  -9.77069139e-05]
< returned_observation >
[ 0.          0.43058478]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 985 #########################################
< action >
[-0.03167371  0.00162831]
< returned_observation >
[ 0.          0.43221309]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 986 #########################################
< action >
[-0.03300568  0.00158845]
< returned_observation >
[ 0.          0.43380154]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 987 #########################################
< action >
[-0.03408532  0.00228634]
< returned_observation >
[ 0.          0.43608788]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 988 #########################################
< action >
[-0.03523648  0.00256198]
< returned_observation >
[ 0.          0.43864986]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 989 #########################################
< action >
[-0.0357603   0.00276961]
< returned_observation >
[ 0.          0.44141948]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 990 #########################################
< action >
[-0.03625079  0.00048885]
< returned_observation >
[ 0.          0.44190832]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 991 #########################################
< action >
[-0.0380161   0.00160417]
< returned_observation >
[ 0.          0.44351249]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 992 #########################################
< action >
[-0.03679861  0.00115293]
< returned_observation >
[ 0.          0.44466542]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 993 #########################################
< action >
[ -3.65777403e-02  -7.21484423e-05]
< returned_observation >
[ 0.          0.44459327]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 994 #########################################
< action >
[-0.03763677 -0.00182268]
< returned_observation >
[ 0.          0.44277059]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 995 #########################################
< action >
[-0.03805265 -0.00019624]
< returned_observation >
[ 0.          0.44257435]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 996 #########################################
< action >
[-0.03934195  0.0005765 ]
< returned_observation >
[ 0.          0.44315084]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 997 #########################################
< action >
[-0.03888681  0.00106637]
< returned_observation >
[ 0.          0.44421722]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 998 #########################################
< action >
[-0.0406344  -0.00022285]
< returned_observation >
[ 0.          0.44399437]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 999 #########################################
< action >
[-0.0396366  -0.00214582]
< returned_observation >
[ 0.          0.44184855]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1000 #########################################
< action >
[-0.03985211 -0.00261434]
< returned_observation >
[ 0.          0.43923421]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1001 #########################################
< action >
[-0.04003049 -0.00188386]
< returned_observation >
[ 0.          0.43735035]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1002 #########################################
< action >
[-0.04061578 -0.0009712 ]
< returned_observation >
[ 0.          0.43637915]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1003 #########################################
< action >
[-0.03980167 -0.00279592]
< returned_observation >
[ 0.          0.43358323]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1004 #########################################
< action >
[-0.03980181 -0.00332752]
< returned_observation >
[ 0.          0.43025571]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1005 #########################################
< action >
[-0.03983256 -0.0042165 ]
< returned_observation >
[ 0.          0.42603921]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1006 #########################################
< action >
[-0.03999398 -0.00296938]
< returned_observation >
[ 0.          0.42306982]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1007 #########################################
< action >
[-0.03992891 -0.00425349]
< returned_observation >
[ 0.          0.41881633]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1008 #########################################
< action >
[-0.03983774 -0.00369823]
< returned_observation >
[ 0.         0.4151181]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1009 #########################################
< action >
[-0.04146862 -0.00430897]
< returned_observation >
[ 0.          0.41080914]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1010 #########################################
< action >
[-0.04199544 -0.00363221]
< returned_observation >
[ 0.          0.40717693]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1011 #########################################
< action >
[-0.04235264 -0.00391068]
< returned_observation >
[ 0.          0.40326625]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1012 #########################################
< action >
[-0.04191072 -0.00334014]
< returned_observation >
[ 0.          0.39992611]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1013 #########################################
< action >
[-0.04229583 -0.00133399]
< returned_observation >
[ 0.          0.39859211]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1014 #########################################
< action >
[-0.04175878 -0.00047559]
< returned_observation >
[ 0.          0.39811652]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1015 #########################################
< action >
[-0.04197874 -0.00086172]
< returned_observation >
[ 0.         0.3972548]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1016 #########################################
< action >
[-0.04312267 -0.00311966]
< returned_observation >
[ 0.          0.39413514]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1017 #########################################
< action >
[-0.04188891 -0.00323283]
< returned_observation >
[ 0.          0.39090231]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1018 #########################################
< action >
[-0.04294052 -0.00357437]
< returned_observation >
[ 0.          0.38732794]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1019 #########################################
< action >
[-0.04215363 -0.00350561]
< returned_observation >
[ 0.          0.38382233]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1020 #########################################
< action >
[-0.04101267 -0.00509618]
< returned_observation >
[ 0.          0.37872616]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1021 #########################################
< action >
[-0.04103555 -0.0053951 ]
< returned_observation >
[ 0.          0.37333106]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1022 #########################################
< action >
[-0.039634   -0.00493039]
< returned_observation >
[ 0.          0.36840067]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1023 #########################################
< action >
[-0.0389509  -0.00367523]
< returned_observation >
[ 0.          0.36472544]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1024 #########################################
< action >
[-0.03830972 -0.00526276]
< returned_observation >
[ 0.          0.35946268]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1025 #########################################
< action >
[-0.03688715 -0.00465885]
< returned_observation >
[ 0.          0.35480383]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1026 #########################################
< action >
[-0.03701319 -0.00426969]
< returned_observation >
[ 0.          0.35053414]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1027 #########################################
< action >
[-0.03534525 -0.00349543]
< returned_observation >
[ 0.          0.34703871]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1028 #########################################
< action >
[-0.03542455 -0.00294417]
< returned_observation >
[ 0.          0.34409454]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1029 #########################################
< action >
[-0.03621404 -0.00250077]
< returned_observation >
[ 0.          0.34159377]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1030 #########################################
< action >
[-0.03623416 -0.00214792]
< returned_observation >
[ 0.          0.33944585]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1031 #########################################
< action >
[-0.03806297 -0.00368804]
< returned_observation >
[ 0.          0.33575781]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1032 #########################################
< action >
[-0.03532558 -0.00398161]
< returned_observation >
[ 0.          0.33177621]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1033 #########################################
< action >
[-0.03545712 -0.00348428]
< returned_observation >
[ 0.          0.32829192]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1034 #########################################
< action >
[-0.03570259 -0.00317541]
< returned_observation >
[ 0.          0.32511651]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1035 #########################################
< action >
[-0.03747424 -0.00322581]
< returned_observation >
[ 0.         0.3218907]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1036 #########################################
< action >
[-0.03748552 -0.00509488]
< returned_observation >
[ 0.          0.31679583]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 15 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 100, 'min_reward': -12.7, 'episode_reward': -659.4000000000001, 'nb_steps': 1037, 'ave_reward': -6.594000000000001}
######################################### STEP 1037 #########################################
< action >
[-0.03271205  0.00241083]
< returned_observation >
[ 0.66713157  0.78192541]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 1038 #########################################
< action >
[-0.03230968  0.00198013]
< returned_observation >
[ 0.63482188  0.78390555]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1039 #########################################
< action >
[-0.03452076  0.00151418]
< returned_observation >
[ 0.60030112  0.78541973]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1040 #########################################
< action >
[-0.03486265  0.00107862]
< returned_observation >
[ 0.56543848  0.78649835]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1041 #########################################
< action >
[-0.03369068  0.00141179]
< returned_observation >
[ 0.5317478   0.78791014]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 1042 #########################################
< action >
[-0.03448915  0.00394352]
< returned_observation >
[ 0.49725865  0.79185366]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1043 #########################################
< action >
[-0.03456461  0.00234282]
< returned_observation >
[ 0.46269404  0.79419648]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1044 #########################################
< action >
[-0.03511761  0.00100303]
< returned_observation >
[ 0.42757643  0.79519951]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1045 #########################################
< action >
[-0.03602488  0.00087111]
< returned_observation >
[ 0.39155155  0.79607062]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1046 #########################################
< action >
[-0.03707802  0.00187592]
< returned_observation >
[ 0.35447353  0.79794654]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1047 #########################################
< action >
[-0.0368567  0.0013303]
< returned_observation >
[ 0.31761683  0.79927683]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1048 #########################################
< action >
[-0.03728017  0.00116695]
< returned_observation >
[ 0.28033666  0.80044379]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1049 #########################################
< action >
[-0.03733966  0.00030161]
< returned_observation >
[ 0.242997    0.80074539]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1050 #########################################
< action >
[-0.03662244 -0.00154231]
< returned_observation >
[ 0.20637455  0.79920308]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1051 #########################################
< action >
[-0.03644872 -0.00127532]
< returned_observation >
[ 0.16992584  0.79792776]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 1052 #########################################
< action >
[-0.03618126 -0.00038199]
< returned_observation >
[ 0.13374458  0.79754577]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1053 #########################################
< action >
[-0.03702849  0.00024073]
< returned_observation >
[ 0.09671609  0.79778651]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1054 #########################################
< action >
[-0.03901315 -0.00081255]
< returned_observation >
[ 0.05770293  0.79697396]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 1055 #########################################
< action >
[-0.04033819 -0.00022462]
< returned_observation >
[ 0.01736474  0.79674933]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1056 #########################################
< action >
[-0.04266986  0.00056093]
< returned_observation >
[ 0.          0.79731026]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1057 #########################################
< action >
[-0.0426917  -0.00013914]
< returned_observation >
[ 0.          0.79717112]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1058 #########################################
< action >
[-0.04411547 -0.00056029]
< returned_observation >
[ 0.          0.79661084]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 1059 #########################################
< action >
[-0.04183975 -0.00292648]
< returned_observation >
[ 0.          0.79368435]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1060 #########################################
< action >
[-0.04249136 -0.00257834]
< returned_observation >
[ 0.          0.79110601]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1061 #########################################
< action >
[-0.04219977 -0.00239494]
< returned_observation >
[ 0.          0.78871107]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1062 #########################################
< action >
[-0.04275433 -0.00260444]
< returned_observation >
[ 0.          0.78610663]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1063 #########################################
< action >
[-0.04397086 -0.00177853]
< returned_observation >
[ 0.         0.7843281]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1064 #########################################
< action >
[-0.044747   -0.00254302]
< returned_observation >
[ 0.          0.78178507]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1065 #########################################
< action >
[-0.0440773  -0.00297537]
< returned_observation >
[ 0.         0.7788097]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 1066 #########################################
< action >
[-0.04320926 -0.00368243]
< returned_observation >
[ 0.          0.77512727]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1067 #########################################
< action >
[-0.04407909 -0.00421316]
< returned_observation >
[ 0.          0.77091411]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1068 #########################################
< action >
[-0.04458408 -0.00483145]
< returned_observation >
[ 0.          0.76608266]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1069 #########################################
< action >
[-0.04433661 -0.0047355 ]
< returned_observation >
[ 0.          0.76134716]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1070 #########################################
< action >
[-0.0445236  -0.00426115]
< returned_observation >
[ 0.        0.757086]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1071 #########################################
< action >
[-0.04416722 -0.00353531]
< returned_observation >
[ 0.         0.7535507]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 1072 #########################################
< action >
[-0.04445998 -0.00402208]
< returned_observation >
[ 0.          0.74952862]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1073 #########################################
< action >
[-0.04454573 -0.00233082]
< returned_observation >
[ 0.         0.7471978]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1074 #########################################
< action >
[-0.04307766 -0.00218677]
< returned_observation >
[ 0.          0.74501103]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1075 #########################################
< action >
[-0.0439255  -0.00158983]
< returned_observation >
[ 0.         0.7434212]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1076 #########################################
< action >
[-0.04251478  0.00015066]
< returned_observation >
[ 0.          0.74357186]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1077 #########################################
< action >
[-0.04185826 -0.00110128]
< returned_observation >
[ 0.          0.74247058]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1078 #########################################
< action >
[-0.04293201 -0.00177946]
< returned_observation >
[ 0.          0.74069112]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1079 #########################################
< action >
[-0.04179434 -0.00231971]
< returned_observation >
[ 0.          0.73837141]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1080 #########################################
< action >
[-0.04127072 -0.00389717]
< returned_observation >
[ 0.          0.73447423]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1081 #########################################
< action >
[-0.04048075 -0.00348822]
< returned_observation >
[ 0.          0.73098602]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1082 #########################################
< action >
[-0.04123437 -0.0038178 ]
< returned_observation >
[ 0.          0.72716821]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1083 #########################################
< action >
[-0.04174642 -0.00369124]
< returned_observation >
[ 0.          0.72347697]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1084 #########################################
< action >
[-0.04219491 -0.00461532]
< returned_observation >
[ 0.          0.71886166]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1085 #########################################
< action >
[-0.04249903 -0.00539177]
< returned_observation >
[ 0.          0.71346989]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1086 #########################################
< action >
[-0.0421842  -0.00588459]
< returned_observation >
[ 0.          0.70758529]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 1087 #########################################
< action >
[-0.04303445 -0.00678616]
< returned_observation >
[ 0.          0.70079913]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1088 #########################################
< action >
[-0.04358539 -0.00698058]
< returned_observation >
[ 0.          0.69381856]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1089 #########################################
< action >
[-0.04379067 -0.00815345]
< returned_observation >
[ 0.          0.68566511]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 1090 #########################################
< action >
[-0.0443129  -0.00835353]
< returned_observation >
[ 0.          0.67731158]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1091 #########################################
< action >
[-0.04362451 -0.00722301]
< returned_observation >
[ 0.          0.67008857]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1092 #########################################
< action >
[-0.04353109 -0.00604997]
< returned_observation >
[ 0.         0.6640386]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1093 #########################################
< action >
[-0.04193635 -0.00560406]
< returned_observation >
[ 0.          0.65843455]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1094 #########################################
< action >
[-0.04004291 -0.00717382]
< returned_observation >
[ 0.          0.65126073]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1095 #########################################
< action >
[-0.03979609 -0.00749284]
< returned_observation >
[ 0.          0.64376789]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 1096 #########################################
< action >
[-0.04024277 -0.00845769]
< returned_observation >
[ 0.         0.6353102]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1097 #########################################
< action >
[-0.04118409 -0.00830768]
< returned_observation >
[ 0.          0.62700252]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1098 #########################################
< action >
[-0.04200257 -0.00844124]
< returned_observation >
[ 0.          0.61856127]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1099 #########################################
< action >
[-0.04292348 -0.00624688]
< returned_observation >
[ 0.          0.61231439]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1100 #########################################
< action >
[-0.0427672  -0.00733234]
< returned_observation >
[ 0.          0.60498205]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1101 #########################################
< action >
[-0.04446171 -0.00994651]
< returned_observation >
[ 0.          0.59503554]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1102 #########################################
< action >
[-0.04547658 -0.00927808]
< returned_observation >
[ 0.          0.58575746]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1103 #########################################
< action >
[-0.04617838 -0.00994591]
< returned_observation >
[ 0.          0.57581155]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 1104 #########################################
< action >
[-0.04525386 -0.01038047]
< returned_observation >
[ 0.          0.56543107]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1105 #########################################
< action >
[-0.04516208 -0.01074679]
< returned_observation >
[ 0.          0.55468428]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1106 #########################################
< action >
[-0.04464167 -0.01087061]
< returned_observation >
[ 0.          0.54381367]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1107 #########################################
< action >
[-0.04548154 -0.01153192]
< returned_observation >
[ 0.          0.53228176]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1108 #########################################
< action >
[-0.04448926 -0.01096433]
< returned_observation >
[ 0.          0.52131742]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1109 #########################################
< action >
[-0.04391946 -0.00938137]
< returned_observation >
[ 0.          0.51193606]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1110 #########################################
< action >
[-0.04454025 -0.00861493]
< returned_observation >
[ 0.          0.50332113]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1111 #########################################
< action >
[-0.04636997 -0.0084275 ]
< returned_observation >
[ 0.          0.49489363]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1112 #########################################
< action >
[-0.04690327 -0.00856396]
< returned_observation >
[ 0.          0.48632967]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1113 #########################################
< action >
[-0.04745422 -0.00682205]
< returned_observation >
[ 0.          0.47950762]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1114 #########################################
< action >
[-0.04741933 -0.00580719]
< returned_observation >
[ 0.          0.47370043]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1115 #########################################
< action >
[-0.04792727 -0.00564172]
< returned_observation >
[ 0.          0.46805871]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1116 #########################################
< action >
[-0.04817971 -0.00645379]
< returned_observation >
[ 0.          0.46160492]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1117 #########################################
< action >
[-0.04835889 -0.00590142]
< returned_observation >
[ 0.         0.4557035]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1118 #########################################
< action >
[-0.04678157 -0.0058308 ]
< returned_observation >
[ 0.         0.4498727]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1119 #########################################
< action >
[-0.04798875 -0.00469881]
< returned_observation >
[ 0.          0.44517389]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1120 #########################################
< action >
[-0.04837997 -0.00405097]
< returned_observation >
[ 0.          0.44112292]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1121 #########################################
< action >
[-0.04941416 -0.00399392]
< returned_observation >
[ 0.        0.437129]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1122 #########################################
< action >
[-0.04896879 -0.00396813]
< returned_observation >
[ 0.          0.43316087]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1123 #########################################
< action >
[-0.04794573 -0.00485125]
< returned_observation >
[ 0.          0.42830961]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1124 #########################################
< action >
[-0.04662698 -0.00619276]
< returned_observation >
[ 0.          0.42211685]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1125 #########################################
< action >
[-0.04497784 -0.00505821]
< returned_observation >
[ 0.          0.41705864]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1126 #########################################
< action >
[-0.04431922 -0.00659642]
< returned_observation >
[ 0.          0.41046222]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1127 #########################################
< action >
[-0.04367591 -0.00719019]
< returned_observation >
[ 0.          0.40327203]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1128 #########################################
< action >
[-0.0441856 -0.0071496]
< returned_observation >
[ 0.          0.39612243]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1129 #########################################
< action >
[-0.04244225 -0.00747753]
< returned_observation >
[ 0.         0.3886449]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1130 #########################################
< action >
[-0.04402159 -0.00861277]
< returned_observation >
[ 0.          0.38003213]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1131 #########################################
< action >
[-0.04353435 -0.00937091]
< returned_observation >
[ 0.          0.37066122]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1132 #########################################
< action >
[-0.04391489 -0.00767881]
< returned_observation >
[ 0.         0.3629824]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1133 #########################################
< action >
[-0.04409554 -0.00802684]
< returned_observation >
[ 0.          0.35495556]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1134 #########################################
< action >
[-0.04542296 -0.0095033 ]
< returned_observation >
[ 0.          0.34545226]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1135 #########################################
< action >
[-0.0465189 -0.009413 ]
< returned_observation >
[ 0.          0.33603926]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1136 #########################################
< action >
[-0.04490269 -0.01023857]
< returned_observation >
[ 0.          0.32580069]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 16 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 100, 'min_reward': -12.7, 'episode_reward': -317.19999999999993, 'nb_steps': 1137, 'ave_reward': -3.1719999999999993}
######################################### STEP 1137 #########################################
< action >
[-0.03454878 -0.00376756]
< returned_observation >
[ 0.          0.57389529]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1138 #########################################
< action >
[-0.03558871 -0.00377518]
< returned_observation >
[ 0.          0.57012011]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1139 #########################################
< action >
[-0.03647036 -0.00463803]
< returned_observation >
[ 0.          0.56548208]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1140 #########################################
< action >
[-0.03856987 -0.00485709]
< returned_observation >
[ 0.          0.56062499]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1141 #########################################
< action >
[-0.03847184 -0.00430872]
< returned_observation >
[ 0.          0.55631627]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1142 #########################################
< action >
[-0.03870574 -0.00282715]
< returned_observation >
[ 0.          0.55348912]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1143 #########################################
< action >
[-0.04028029 -0.00355321]
< returned_observation >
[ 0.         0.5499359]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1144 #########################################
< action >
[-0.04176532 -0.00304425]
< returned_observation >
[ 0.          0.54689165]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1145 #########################################
< action >
[-0.04036487 -0.00290782]
< returned_observation >
[ 0.          0.54398383]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1146 #########################################
< action >
[-0.03922155 -0.00196229]
< returned_observation >
[ 0.          0.54202154]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1147 #########################################
< action >
[-0.04044859 -0.00268911]
< returned_observation >
[ 0.          0.53933243]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1148 #########################################
< action >
[-0.04081536 -0.0033732 ]
< returned_observation >
[ 0.          0.53595924]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1149 #########################################
< action >
[-0.04235068 -0.00478188]
< returned_observation >
[ 0.          0.53117735]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1150 #########################################
< action >
[-0.04027299 -0.00319516]
< returned_observation >
[ 0.          0.52798219]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1151 #########################################
< action >
[-0.04041143 -0.00320106]
< returned_observation >
[ 0.          0.52478113]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1152 #########################################
< action >
[-0.04302353 -0.00487854]
< returned_observation >
[ 0.          0.51990258]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1153 #########################################
< action >
[-0.04455856 -0.00548084]
< returned_observation >
[ 0.          0.51442174]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1154 #########################################
< action >
[-0.04443707 -0.00437236]
< returned_observation >
[ 0.          0.51004938]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1155 #########################################
< action >
[-0.04545822 -0.00480729]
< returned_observation >
[ 0.          0.50524209]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1156 #########################################
< action >
[-0.04703047 -0.00533558]
< returned_observation >
[ 0.          0.49990651]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1157 #########################################
< action >
[-0.04875209 -0.00448069]
< returned_observation >
[ 0.          0.49542582]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1158 #########################################
< action >
[-0.04848537 -0.0048189 ]
< returned_observation >
[ 0.          0.49060692]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1159 #########################################
< action >
[-0.04916622 -0.00480705]
< returned_observation >
[ 0.          0.48579987]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1160 #########################################
< action >
[-0.04934065 -0.00598804]
< returned_observation >
[ 0.          0.47981183]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1161 #########################################
< action >
[-0.05       -0.00548954]
< returned_observation >
[ 0.          0.47432229]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1162 #########################################
< action >
[-0.05       -0.00727068]
< returned_observation >
[ 0.          0.46705161]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1163 #########################################
< action >
[-0.05       -0.00566738]
< returned_observation >
[ 0.          0.46138424]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1164 #########################################
< action >
[-0.05       -0.00681637]
< returned_observation >
[ 0.          0.45456786]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1165 #########################################
< action >
[-0.05       -0.00631432]
< returned_observation >
[ 0.          0.44825354]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1166 #########################################
< action >
[-0.05       -0.00612304]
< returned_observation >
[ 0.          0.44213051]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1167 #########################################
< action >
[-0.04992815 -0.00564942]
< returned_observation >
[ 0.          0.43648109]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1168 #########################################
< action >
[-0.04951981 -0.00669578]
< returned_observation >
[ 0.          0.42978531]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1169 #########################################
< action >
[-0.05       -0.00676654]
< returned_observation >
[ 0.          0.42301877]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1170 #########################################
< action >
[-0.05       -0.00549649]
< returned_observation >
[ 0.          0.41752228]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1171 #########################################
< action >
[-0.05       -0.00613202]
< returned_observation >
[ 0.          0.41139026]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1172 #########################################
< action >
[-0.05       -0.00725002]
< returned_observation >
[ 0.          0.40414024]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1173 #########################################
< action >
[-0.05       -0.00478436]
< returned_observation >
[ 0.          0.39935588]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1174 #########################################
< action >
[-0.05       -0.00430187]
< returned_observation >
[ 0.          0.39505401]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1175 #########################################
< action >
[-0.05       -0.00510794]
< returned_observation >
[ 0.          0.38994607]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1176 #########################################
< action >
[-0.05       -0.00379693]
< returned_observation >
[ 0.          0.38614914]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1177 #########################################
< action >
[-0.05       -0.00269995]
< returned_observation >
[ 0.          0.38344919]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1178 #########################################
< action >
[-0.05       -0.00134092]
< returned_observation >
[ 0.          0.38210827]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1179 #########################################
< action >
[-0.04963265 -0.0020328 ]
< returned_observation >
[ 0.          0.38007547]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1180 #########################################
< action >
[-0.04873647 -0.00439408]
< returned_observation >
[ 0.          0.37568139]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1181 #########################################
< action >
[-0.04993457 -0.00400851]
< returned_observation >
[ 0.          0.37167288]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1182 #########################################
< action >
[-0.04976294 -0.00383543]
< returned_observation >
[ 0.          0.36783745]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1183 #########################################
< action >
[-0.04965384 -0.00356729]
< returned_observation >
[ 0.          0.36427016]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1184 #########################################
< action >
[-0.05       -0.00221946]
< returned_observation >
[ 0.         0.3620507]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1185 #########################################
< action >
[-0.05       -0.00280555]
< returned_observation >
[ 0.          0.35924515]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1186 #########################################
< action >
[-0.05       -0.00324225]
< returned_observation >
[ 0.         0.3560029]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1187 #########################################
< action >
[-0.05      -0.0042487]
< returned_observation >
[ 0.         0.3517542]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1188 #########################################
< action >
[-0.05       -0.00626478]
< returned_observation >
[ 0.          0.34548942]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1189 #########################################
< action >
[-0.05       -0.00701219]
< returned_observation >
[ 0.          0.33847723]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1190 #########################################
< action >
[-0.05       -0.00524451]
< returned_observation >
[ 0.          0.33323272]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1191 #########################################
< action >
[-0.05       -0.00561952]
< returned_observation >
[ 0.         0.3276132]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1192 #########################################
< action >
[-0.05      -0.0043772]
< returned_observation >
[ 0.          0.32323601]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1193 #########################################
< action >
[-0.05       -0.00558794]
< returned_observation >
[ 0.          0.31764807]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1194 #########################################
< action >
[-0.05       -0.00484843]
< returned_observation >
[ 0.          0.31279964]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1195 #########################################
< action >
[-0.05       -0.00583522]
< returned_observation >
[ 0.          0.30696442]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1196 #########################################
< action >
[-0.05      -0.0065623]
< returned_observation >
[ 0.          0.30040212]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1197 #########################################
< action >
[-0.05       -0.00726779]
< returned_observation >
[ 0.          0.29313433]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1198 #########################################
< action >
[-0.05       -0.00905411]
< returned_observation >
[ 0.          0.28408022]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1199 #########################################
< action >
[-0.05       -0.00869337]
< returned_observation >
[ 0.          0.27538686]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1200 #########################################
< action >
[-0.05       -0.00757955]
< returned_observation >
[ 0.          0.26780731]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1201 #########################################
< action >
[-0.05       -0.00734366]
< returned_observation >
[ 0.          0.26046365]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1202 #########################################
< action >
[-0.05       -0.00740536]
< returned_observation >
[ 0.          0.25305829]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1203 #########################################
< action >
[-0.05       -0.00754638]
< returned_observation >
[ 0.          0.24551191]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1204 #########################################
< action >
[-0.05       -0.00742211]
< returned_observation >
[ 0.         0.2380898]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1205 #########################################
< action >
[-0.05       -0.00750013]
< returned_observation >
[ 0.          0.23058967]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1206 #########################################
< action >
[-0.05       -0.00676002]
< returned_observation >
[ 0.          0.22382965]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1207 #########################################
< action >
[-0.05       -0.00759079]
< returned_observation >
[ 0.          0.21623885]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1208 #########################################
< action >
[-0.05       -0.00790962]
< returned_observation >
[ 0.          0.20832923]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1209 #########################################
< action >
[-0.05       -0.00808417]
< returned_observation >
[ 0.          0.20024506]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1210 #########################################
< action >
[-0.05       -0.00925768]
< returned_observation >
[ 0.          0.19098738]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1211 #########################################
< action >
[-0.05       -0.00998868]
< returned_observation >
[ 0.         0.1809987]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1212 #########################################
< action >
[-0.05       -0.01042112]
< returned_observation >
[ 0.          0.17057758]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1213 #########################################
< action >
[-0.05      -0.0096082]
< returned_observation >
[ 0.          0.16096938]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1214 #########################################
< action >
[-0.04961347 -0.00948281]
< returned_observation >
[ 0.          0.15148657]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1215 #########################################
< action >
[-0.05       -0.00879843]
< returned_observation >
[ 0.          0.14268814]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1216 #########################################
< action >
[-0.04905572 -0.00823433]
< returned_observation >
[ 0.          0.13445381]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1217 #########################################
< action >
[-0.04774873 -0.00959454]
< returned_observation >
[ 0.          0.12485928]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1218 #########################################
< action >
[-0.04740133 -0.00925806]
< returned_observation >
[ 0.          0.11560121]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1219 #########################################
< action >
[-0.04639238 -0.00946549]
< returned_observation >
[ 0.          0.10613572]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1220 #########################################
< action >
[-0.04583517 -0.01100655]
< returned_observation >
[ 0.          0.09512917]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1221 #########################################
< action >
[-0.04661116 -0.01145497]
< returned_observation >
[ 0.         0.0836742]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1222 #########################################
< action >
[-0.04622447 -0.01098398]
< returned_observation >
[ 0.          0.07269022]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1223 #########################################
< action >
[-0.0475908  -0.01064833]
< returned_observation >
[ 0.          0.06204188]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1224 #########################################
< action >
[-0.04572868 -0.01051771]
< returned_observation >
[ 0.          0.05152418]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1225 #########################################
< action >
[-0.04420233 -0.00930962]
< returned_observation >
[ 0.          0.04221456]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1226 #########################################
< action >
[-0.04303035 -0.00903811]
< returned_observation >
[ 0.          0.03317645]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1227 #########################################
< action >
[-0.04408203 -0.00962138]
< returned_observation >
[ 0.          0.02355508]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1228 #########################################
< action >
[-0.04311198 -0.00814145]
< returned_observation >
[ 0.          0.01541363]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1229 #########################################
< action >
[-0.04311282 -0.00689619]
< returned_observation >
[ 0.          0.00851744]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1230 #########################################
< action >
[-0.04512624 -0.00725742]
< returned_observation >
[ 0.          0.00126002]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1231 #########################################
< action >
[-0.04449893 -0.0068408 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 17 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 95, 'min_reward': -12.7, 'episode_reward': -675.6, 'nb_steps': 1232, 'ave_reward': -7.111578947368422}
######################################### STEP 1232 #########################################
< action >
[-0.03427122 -0.00857131]
< returned_observation >
[ 0.          0.50690131]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1233 #########################################
< action >
[-0.03321234 -0.00901785]
< returned_observation >
[ 0.          0.49788345]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1234 #########################################
< action >
[-0.03404225 -0.00879461]
< returned_observation >
[ 0.          0.48908884]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1235 #########################################
< action >
[-0.03200523 -0.00930948]
< returned_observation >
[ 0.          0.47977936]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1236 #########################################
< action >
[-0.03328732 -0.00921674]
< returned_observation >
[ 0.          0.47056262]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1237 #########################################
< action >
[-0.03274519 -0.00930299]
< returned_observation >
[ 0.          0.46125963]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1238 #########################################
< action >
[-0.03198006 -0.00900264]
< returned_observation >
[ 0.          0.45225699]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1239 #########################################
< action >
[-0.03170675 -0.00751236]
< returned_observation >
[ 0.          0.44474463]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1240 #########################################
< action >
[-0.0301172  -0.00622846]
< returned_observation >
[ 0.          0.43851617]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1241 #########################################
< action >
[-0.02925445 -0.00623848]
< returned_observation >
[ 0.          0.43227769]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1242 #########################################
< action >
[-0.02893184 -0.00600537]
< returned_observation >
[ 0.          0.42627232]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1243 #########################################
< action >
[-0.02923234 -0.00550277]
< returned_observation >
[ 0.          0.42076955]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1244 #########################################
< action >
[-0.02975146 -0.00474891]
< returned_observation >
[ 0.          0.41602064]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1245 #########################################
< action >
[-0.02959289 -0.00460103]
< returned_observation >
[ 0.         0.4114196]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1246 #########################################
< action >
[-0.02966837 -0.00576256]
< returned_observation >
[ 0.          0.40565705]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1247 #########################################
< action >
[-0.02981305 -0.00711193]
< returned_observation >
[ 0.          0.39854511]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1248 #########################################
< action >
[-0.02915698 -0.00707683]
< returned_observation >
[ 0.          0.39146829]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1249 #########################################
< action >
[-0.02855677 -0.00607676]
< returned_observation >
[ 0.          0.38539153]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1250 #########################################
< action >
[-0.02663844 -0.0073086 ]
< returned_observation >
[ 0.          0.37808293]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1251 #########################################
< action >
[-0.02646267 -0.00728703]
< returned_observation >
[ 0.         0.3707959]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1252 #########################################
< action >
[-0.02586952 -0.00586767]
< returned_observation >
[ 0.          0.36492823]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1253 #########################################
< action >
[-0.02595953 -0.00421757]
< returned_observation >
[ 0.          0.36071066]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1254 #########################################
< action >
[-0.02492124 -0.00615763]
< returned_observation >
[ 0.          0.35455303]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1255 #########################################
< action >
[-0.02646961 -0.00659101]
< returned_observation >
[ 0.          0.34796202]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1256 #########################################
< action >
[-0.02624052 -0.00588421]
< returned_observation >
[ 0.          0.34207781]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1257 #########################################
< action >
[-0.02489226 -0.00445342]
< returned_observation >
[ 0.          0.33762439]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 1258 #########################################
< action >
[-0.0237037 -0.0057596]
< returned_observation >
[ 0.          0.33186479]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1259 #########################################
< action >
[-0.02291223 -0.00565242]
< returned_observation >
[ 0.          0.32621237]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1260 #########################################
< action >
[-0.02286536 -0.00516451]
< returned_observation >
[ 0.          0.32104786]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1261 #########################################
< action >
[-0.02348292 -0.0043928 ]
< returned_observation >
[ 0.          0.31665506]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1262 #########################################
< action >
[-0.02342672 -0.0054105 ]
< returned_observation >
[ 0.          0.31124456]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1263 #########################################
< action >
[-0.02338968 -0.00603857]
< returned_observation >
[ 0.          0.30520599]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1264 #########################################
< action >
[-0.02349926 -0.00447945]
< returned_observation >
[ 0.          0.30072654]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1265 #########################################
< action >
[-0.02300017 -0.00317863]
< returned_observation >
[ 0.          0.29754792]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1266 #########################################
< action >
[-0.02240056 -0.00504997]
< returned_observation >
[ 0.          0.29249794]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1267 #########################################
< action >
[-0.02057051 -0.0049638 ]
< returned_observation >
[ 0.          0.28753414]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1268 #########################################
< action >
[-0.02087408 -0.00805633]
< returned_observation >
[ 0.          0.27947781]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1269 #########################################
< action >
[-0.02050749 -0.00996139]
< returned_observation >
[ 0.          0.26951642]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1270 #########################################
< action >
[-0.01925573 -0.01074111]
< returned_observation >
[ 0.          0.25877531]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1271 #########################################
< action >
[-0.01903104 -0.01106405]
< returned_observation >
[ 0.          0.24771125]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1272 #########################################
< action >
[-0.01958787 -0.011172  ]
< returned_observation >
[ 0.          0.23653925]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1273 #########################################
< action >
[-0.01781845 -0.01205852]
< returned_observation >
[ 0.          0.22448074]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1274 #########################################
< action >
[-0.01816773 -0.01069002]
< returned_observation >
[ 0.          0.21379072]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1275 #########################################
< action >
[-0.01915953 -0.0112984 ]
< returned_observation >
[ 0.          0.20249231]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1276 #########################################
< action >
[-0.01998808 -0.01224445]
< returned_observation >
[ 0.          0.19024787]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1277 #########################################
< action >
[-0.01924669 -0.01150098]
< returned_observation >
[ 0.          0.17874689]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1278 #########################################
< action >
[-0.01932553 -0.01173176]
< returned_observation >
[ 0.          0.16701513]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1279 #########################################
< action >
[-0.02085399 -0.01341482]
< returned_observation >
[ 0.          0.15360031]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1280 #########################################
< action >
[-0.02176957 -0.01330259]
< returned_observation >
[ 0.          0.14029772]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1281 #########################################
< action >
[-0.02061603 -0.01233249]
< returned_observation >
[ 0.          0.12796523]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1282 #########################################
< action >
[-0.02272812 -0.01248162]
< returned_observation >
[ 0.         0.1154836]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1283 #########################################
< action >
[-0.02219591 -0.01350499]
< returned_observation >
[ 0.          0.10197861]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1284 #########################################
< action >
[-0.02159073 -0.01528665]
< returned_observation >
[ 0.          0.08669195]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1285 #########################################
< action >
[-0.02236054 -0.01624599]
< returned_observation >
[ 0.          0.07044596]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1286 #########################################
< action >
[-0.02187639 -0.01560047]
< returned_observation >
[ 0.          0.05484549]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1287 #########################################
< action >
[-0.02321412 -0.0153347 ]
< returned_observation >
[ 0.         0.0395108]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1288 #########################################
< action >
[-0.02253076 -0.0153754 ]
< returned_observation >
[ 0.         0.0241354]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1289 #########################################
< action >
[-0.02301168 -0.01692959]
< returned_observation >
[ 0.          0.00720581]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1290 #########################################
< action >
[-0.02331935 -0.01751594]
< returned_observation >
[ 0.  0.]
< reward >
-12.3
< running_reward >
-3.69
< done >
True
##################### episode 18 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 59, 'min_reward': -12.5, 'episode_reward': -506.50000000000017, 'nb_steps': 1291, 'ave_reward': -8.584745762711867}
######################################### STEP 1291 #########################################
< action >
[-0.03391071 -0.01350487]
< returned_observation >
[ 0.60588447  0.97211954]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 1292 #########################################
< action >
[-0.03308523 -0.014473  ]
< returned_observation >
[ 0.57279924  0.95764653]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 1293 #########################################
< action >
[-0.03141174 -0.01489542]
< returned_observation >
[ 0.54138749  0.94275112]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1294 #########################################
< action >
[-0.03041109 -0.0137325 ]
< returned_observation >
[ 0.51097641  0.92901862]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1295 #########################################
< action >
[-0.02932748 -0.01404726]
< returned_observation >
[ 0.48164893  0.91497136]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 1296 #########################################
< action >
[-0.02890299 -0.01390943]
< returned_observation >
[ 0.45274594  0.90106193]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1297 #########################################
< action >
[-0.0296377  -0.01554351]
< returned_observation >
[ 0.42310824  0.88551842]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1298 #########################################
< action >
[-0.03098839 -0.01637021]
< returned_observation >
[ 0.39211985  0.86914821]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 1299 #########################################
< action >
[-0.03052585 -0.01720513]
< returned_observation >
[ 0.36159399  0.85194308]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1300 #########################################
< action >
[-0.03030375 -0.01696738]
< returned_observation >
[ 0.33129024  0.8349757 ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1301 #########################################
< action >
[-0.03081185 -0.01660866]
< returned_observation >
[ 0.30047839  0.81836704]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1302 #########################################
< action >
[-0.0309383 -0.017069 ]
< returned_observation >
[ 0.26954009  0.80129804]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1303 #########################################
< action >
[-0.03098149 -0.01708421]
< returned_observation >
[ 0.2385586   0.78421383]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1304 #########################################
< action >
[-0.03250895 -0.016051  ]
< returned_observation >
[ 0.20604965  0.76816283]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1305 #########################################
< action >
[-0.03454219 -0.01573586]
< returned_observation >
[ 0.17150746  0.75242697]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1306 #########################################
< action >
[-0.03375252 -0.01434259]
< returned_observation >
[ 0.13775495  0.73808437]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1307 #########################################
< action >
[-0.03306507 -0.01306921]
< returned_observation >
[ 0.10468987  0.72501516]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1308 #########################################
< action >
[-0.03229852 -0.01416132]
< returned_observation >
[ 0.07239135  0.71085384]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1309 #########################################
< action >
[-0.02978068 -0.01346068]
< returned_observation >
[ 0.04261067  0.69739316]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1310 #########################################
< action >
[-0.03179463 -0.01399045]
< returned_observation >
[ 0.01081603  0.68340272]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1311 #########################################
< action >
[-0.03065239 -0.01470372]
< returned_observation >
[ 0.        0.668699]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1312 #########################################
< action >
[-0.0305614  -0.01631216]
< returned_observation >
[ 0.          0.65238684]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1313 #########################################
< action >
[-0.03023161 -0.01456684]
< returned_observation >
[ 0.       0.63782]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1314 #########################################
< action >
[-0.02816784 -0.01196536]
< returned_observation >
[ 0.          0.62585464]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1315 #########################################
< action >
[-0.02813355 -0.01130766]
< returned_observation >
[ 0.          0.61454698]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1316 #########################################
< action >
[-0.02926311 -0.0111673 ]
< returned_observation >
[ 0.          0.60337968]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 1317 #########################################
< action >
[-0.02829103 -0.01143433]
< returned_observation >
[ 0.          0.59194535]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1318 #########################################
< action >
[-0.02831478 -0.0127467 ]
< returned_observation >
[ 0.          0.57919865]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1319 #########################################
< action >
[-0.02775164 -0.01215806]
< returned_observation >
[ 0.          0.56704059]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1320 #########################################
< action >
[-0.02921292 -0.0111295 ]
< returned_observation >
[ 0.          0.55591109]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1321 #########################################
< action >
[-0.0290986 -0.0117595]
< returned_observation >
[ 0.          0.54415159]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1322 #########################################
< action >
[-0.02764776 -0.0115468 ]
< returned_observation >
[ 0.          0.53260479]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1323 #########################################
< action >
[-0.02544869 -0.01226234]
< returned_observation >
[ 0.          0.52034245]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1324 #########################################
< action >
[-0.02564849 -0.0123636 ]
< returned_observation >
[ 0.          0.50797885]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1325 #########################################
< action >
[-0.02802166 -0.0111791 ]
< returned_observation >
[ 0.          0.49679975]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1326 #########################################
< action >
[-0.02817893 -0.01170195]
< returned_observation >
[ 0.         0.4850978]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1327 #########################################
< action >
[-0.02781392 -0.01149963]
< returned_observation >
[ 0.          0.47359816]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1328 #########################################
< action >
[-0.02801115 -0.01255806]
< returned_observation >
[ 0.         0.4610401]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1329 #########################################
< action >
[-0.02758615 -0.01248344]
< returned_observation >
[ 0.          0.44855666]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1330 #########################################
< action >
[-0.02713043 -0.01259032]
< returned_observation >
[ 0.          0.43596634]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1331 #########################################
< action >
[-0.02929225 -0.01292061]
< returned_observation >
[ 0.          0.42304573]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1332 #########################################
< action >
[-0.03029365 -0.01518523]
< returned_observation >
[ 0.          0.40786049]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1333 #########################################
< action >
[-0.03106431 -0.0143776 ]
< returned_observation >
[ 0.          0.39348289]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1334 #########################################
< action >
[-0.03267406 -0.015654  ]
< returned_observation >
[ 0.          0.37782889]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1335 #########################################
< action >
[-0.0323669  -0.01825201]
< returned_observation >
[ 0.          0.35957688]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1336 #########################################
< action >
[-0.03188876 -0.01785576]
< returned_observation >
[ 0.          0.34172112]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1337 #########################################
< action >
[-0.03381712 -0.0173891 ]
< returned_observation >
[ 0.          0.32433202]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1338 #########################################
< action >
[-0.03437279 -0.0189251 ]
< returned_observation >
[ 0.          0.30540692]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1339 #########################################
< action >
[-0.03186396 -0.02003962]
< returned_observation >
[ 0.         0.2853673]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1340 #########################################
< action >
[-0.03323614 -0.0197252 ]
< returned_observation >
[ 0.         0.2656421]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1341 #########################################
< action >
[-0.03212184 -0.02037874]
< returned_observation >
[ 0.          0.24526336]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1342 #########################################
< action >
[-0.03193645 -0.01899878]
< returned_observation >
[ 0.          0.22626459]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1343 #########################################
< action >
[-0.03155864 -0.01808584]
< returned_observation >
[ 0.          0.20817874]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1344 #########################################
< action >
[-0.03315237 -0.0184408 ]
< returned_observation >
[ 0.          0.18973794]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1345 #########################################
< action >
[-0.03232434 -0.01958772]
< returned_observation >
[ 0.          0.17015023]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1346 #########################################
< action >
[-0.03284238 -0.02004844]
< returned_observation >
[ 0.          0.15010179]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1347 #########################################
< action >
[-0.03064611 -0.02013898]
< returned_observation >
[ 0.          0.12996281]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1348 #########################################
< action >
[-0.03075417 -0.01944519]
< returned_observation >
[ 0.          0.11051762]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1349 #########################################
< action >
[-0.03192934 -0.02071186]
< returned_observation >
[ 0.          0.08980576]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1350 #########################################
< action >
[-0.03242915 -0.01906864]
< returned_observation >
[ 0.          0.07073712]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1351 #########################################
< action >
[-0.03187559 -0.0185525 ]
< returned_observation >
[ 0.          0.05218462]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1352 #########################################
< action >
[-0.03141361 -0.01871381]
< returned_observation >
[ 0.          0.03347081]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1353 #########################################
< action >
[-0.03191702 -0.01787111]
< returned_observation >
[ 0.         0.0155997]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1354 #########################################
< action >
[-0.03148891 -0.01785211]
< returned_observation >
[ 0.  0.]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
True
##################### episode 19 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 64, 'min_reward': -13.399999999999999, 'episode_reward': -289.09999999999997, 'nb_steps': 1355, 'ave_reward': -4.5171874999999995}
######################################### STEP 1355 #########################################
< action >
[-0.03222314 -0.01364485]
< returned_observation >
[ 0.22687446  0.78885203]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1356 #########################################
< action >
[-0.03282966 -0.01207108]
< returned_observation >
[ 0.1940448   0.77678095]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1357 #########################################
< action >
[-0.03451698 -0.01097344]
< returned_observation >
[ 0.15952782  0.76580751]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1358 #########################################
< action >
[-0.03576012 -0.00962285]
< returned_observation >
[ 0.12376769  0.75618466]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1359 #########################################
< action >
[-0.0345309  -0.01030719]
< returned_observation >
[ 0.08923679  0.74587747]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1360 #########################################
< action >
[-0.03402129 -0.00916977]
< returned_observation >
[ 0.05521551  0.7367077 ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1361 #########################################
< action >
[-0.03533043 -0.01093003]
< returned_observation >
[ 0.01988508  0.72577767]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1362 #########################################
< action >
[-0.0340052 -0.0118847]
< returned_observation >
[ 0.          0.71389297]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1363 #########################################
< action >
[-0.03435166 -0.01083206]
< returned_observation >
[ 0.          0.70306091]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1364 #########################################
< action >
[-0.03557408 -0.01089827]
< returned_observation >
[ 0.          0.69216263]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1365 #########################################
< action >
[-0.03464844 -0.01203877]
< returned_observation >
[ 0.          0.68012386]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1366 #########################################
< action >
[-0.03443871 -0.01188058]
< returned_observation >
[ 0.          0.66824329]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1367 #########################################
< action >
[-0.03449    -0.01246443]
< returned_observation >
[ 0.          0.65577886]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1368 #########################################
< action >
[-0.0343359  -0.01276247]
< returned_observation >
[ 0.          0.64301639]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1369 #########################################
< action >
[-0.03353095 -0.01359995]
< returned_observation >
[ 0.          0.62941644]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1370 #########################################
< action >
[-0.03211121 -0.01387639]
< returned_observation >
[ 0.          0.61554005]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1371 #########################################
< action >
[-0.03049607 -0.01232025]
< returned_observation >
[ 0.         0.6032198]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1372 #########################################
< action >
[-0.03103436 -0.01147217]
< returned_observation >
[ 0.          0.59174763]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1373 #########################################
< action >
[-0.03060271 -0.01122424]
< returned_observation >
[ 0.          0.58052339]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1374 #########################################
< action >
[-0.02974455 -0.01106709]
< returned_observation >
[ 0.          0.56945631]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1375 #########################################
< action >
[-0.03088462 -0.01171386]
< returned_observation >
[ 0.          0.55774245]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1376 #########################################
< action >
[-0.03077    -0.01051932]
< returned_observation >
[ 0.          0.54722313]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1377 #########################################
< action >
[-0.03164289 -0.00967134]
< returned_observation >
[ 0.          0.53755179]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1378 #########################################
< action >
[-0.03019326 -0.0110415 ]
< returned_observation >
[ 0.          0.52651029]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1379 #########################################
< action >
[-0.0313321  -0.01007972]
< returned_observation >
[ 0.          0.51643057]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1380 #########################################
< action >
[-0.03108293 -0.01219773]
< returned_observation >
[ 0.          0.50423284]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1381 #########################################
< action >
[-0.02929938 -0.01180066]
< returned_observation >
[ 0.          0.49243218]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1382 #########################################
< action >
[-0.03109105 -0.01272956]
< returned_observation >
[ 0.          0.47970262]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1383 #########################################
< action >
[-0.03107274 -0.01300662]
< returned_observation >
[ 0.          0.46669599]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1384 #########################################
< action >
[-0.03049902 -0.01323557]
< returned_observation >
[ 0.          0.45346042]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1385 #########################################
< action >
[-0.03066527 -0.01380071]
< returned_observation >
[ 0.          0.43965971]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1386 #########################################
< action >
[-0.03108787 -0.01361069]
< returned_observation >
[ 0.          0.42604902]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1387 #########################################
< action >
[-0.03179858 -0.01285898]
< returned_observation >
[ 0.          0.41319004]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1388 #########################################
< action >
[-0.031763   -0.01500351]
< returned_observation >
[ 0.          0.39818653]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1389 #########################################
< action >
[-0.03126666 -0.0143465 ]
< returned_observation >
[ 0.          0.38384003]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1390 #########################################
< action >
[-0.02884183 -0.0139369 ]
< returned_observation >
[ 0.          0.36990313]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1391 #########################################
< action >
[-0.02932001 -0.01543596]
< returned_observation >
[ 0.          0.35446717]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1392 #########################################
< action >
[-0.02973776 -0.01492818]
< returned_observation >
[ 0.          0.33953899]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1393 #########################################
< action >
[-0.02877069 -0.01594175]
< returned_observation >
[ 0.          0.32359724]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1394 #########################################
< action >
[-0.03009673 -0.01543796]
< returned_observation >
[ 0.          0.30815928]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 1395 #########################################
< action >
[-0.03158448 -0.01681601]
< returned_observation >
[ 0.          0.29134327]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1396 #########################################
< action >
[-0.03118061 -0.01663633]
< returned_observation >
[ 0.          0.27470694]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1397 #########################################
< action >
[-0.03109068 -0.016503  ]
< returned_observation >
[ 0.          0.25820394]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1398 #########################################
< action >
[-0.03349383 -0.01685003]
< returned_observation >
[ 0.          0.24135391]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1399 #########################################
< action >
[-0.03392537 -0.01659579]
< returned_observation >
[ 0.          0.22475812]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1400 #########################################
< action >
[-0.03504607 -0.01680261]
< returned_observation >
[ 0.          0.20795551]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1401 #########################################
< action >
[-0.03530105 -0.01925595]
< returned_observation >
[ 0.          0.18869956]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1402 #########################################
< action >
[-0.03771714 -0.01861636]
< returned_observation >
[ 0.         0.1700832]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1403 #########################################
< action >
[-0.03723151 -0.01799439]
< returned_observation >
[ 0.          0.15208881]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1404 #########################################
< action >
[-0.0368071  -0.01831268]
< returned_observation >
[ 0.          0.13377613]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1405 #########################################
< action >
[-0.0361458  -0.01880466]
< returned_observation >
[ 0.          0.11497147]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1406 #########################################
< action >
[-0.03617865 -0.01954691]
< returned_observation >
[ 0.          0.09542456]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1407 #########################################
< action >
[-0.03816    -0.02109589]
< returned_observation >
[ 0.          0.07432868]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1408 #########################################
< action >
[-0.03816548 -0.02006969]
< returned_observation >
[ 0.          0.05425899]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1409 #########################################
< action >
[-0.03858872 -0.01991864]
< returned_observation >
[ 0.          0.03434036]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1410 #########################################
< action >
[-0.03920574 -0.02166354]
< returned_observation >
[ 0.          0.01267681]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1411 #########################################
< action >
[-0.0394614  -0.02157156]
< returned_observation >
[ 0.  0.]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
True
##################### episode 20 infomation #####################
{'max_reward': 3.3999999999999986, 'nb_episode_steps': 57, 'min_reward': -13.5, 'episode_reward': -389.70000000000005, 'nb_steps': 1412, 'ave_reward': -6.836842105263159}
######################################### STEP 1412 #########################################
< action >
[-0.03257904 -0.01574029]
< returned_observation >
[ 0.83790404  0.90700933]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 1413 #########################################
< action >
[-0.03204764 -0.01547837]
< returned_observation >
[ 0.80585641  0.89153096]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 1414 #########################################
< action >
[-0.0319558  -0.01553974]
< returned_observation >
[ 0.77390061  0.87599122]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1415 #########################################
< action >
[-0.03237111 -0.01678622]
< returned_observation >
[ 0.7415295  0.859205 ]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 1416 #########################################
< action >
[-0.03159696 -0.01735784]
< returned_observation >
[ 0.70993253  0.84184716]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 1417 #########################################
< action >
[-0.03073061 -0.01713411]
< returned_observation >
[ 0.67920192  0.82471305]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1418 #########################################
< action >
[-0.03066287 -0.01808314]
< returned_observation >
[ 0.64853906  0.80662991]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1419 #########################################
< action >
[-0.03242369 -0.01640655]
< returned_observation >
[ 0.61611537  0.79022336]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1420 #########################################
< action >
[-0.03367303 -0.01676761]
< returned_observation >
[ 0.58244234  0.77345575]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1421 #########################################
< action >
[-0.03392995 -0.01725936]
< returned_observation >
[ 0.54851239  0.75619639]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 1422 #########################################
< action >
[-0.03456694 -0.01827782]
< returned_observation >
[ 0.51394545  0.73791857]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1423 #########################################
< action >
[-0.03413504 -0.01809885]
< returned_observation >
[ 0.4798104   0.71981972]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1424 #########################################
< action >
[-0.03423078 -0.01804189]
< returned_observation >
[ 0.44557962  0.70177783]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1425 #########################################
< action >
[-0.03489911 -0.01779913]
< returned_observation >
[ 0.41068052  0.68397871]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1426 #########################################
< action >
[-0.03552754 -0.0165958 ]
< returned_observation >
[ 0.37515298  0.66738291]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1427 #########################################
< action >
[-0.0341944  -0.01623373]
< returned_observation >
[ 0.34095858  0.65114918]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1428 #########################################
< action >
[-0.03514984 -0.01729088]
< returned_observation >
[ 0.30580874  0.6338583 ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1429 #########################################
< action >
[-0.03490603 -0.01587244]
< returned_observation >
[ 0.27090271  0.61798586]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1430 #########################################
< action >
[-0.03543607 -0.01574883]
< returned_observation >
[ 0.23546664  0.60223702]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1431 #########################################
< action >
[-0.03423927 -0.01682555]
< returned_observation >
[ 0.20122737  0.58541148]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1432 #########################################
< action >
[-0.03322622 -0.01532216]
< returned_observation >
[ 0.16800115  0.57008932]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1433 #########################################
< action >
[-0.03331536 -0.01627858]
< returned_observation >
[ 0.13468579  0.55381073]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1434 #########################################
< action >
[-0.03447883 -0.01566446]
< returned_observation >
[ 0.10020696  0.53814627]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1435 #########################################
< action >
[-0.03475997 -0.01438938]
< returned_observation >
[ 0.06544699  0.52375689]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1436 #########################################
< action >
[-0.03351737 -0.01363203]
< returned_observation >
[ 0.03192962  0.51012486]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1437 #########################################
< action >
[-0.03317254 -0.01344305]
< returned_observation >
[ 0.          0.49668181]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1438 #########################################
< action >
[-0.03261511 -0.0115456 ]
< returned_observation >
[ 0.          0.48513622]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1439 #########################################
< action >
[-0.03355099 -0.01039761]
< returned_observation >
[ 0.          0.47473861]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1440 #########################################
< action >
[-0.03387725 -0.0097475 ]
< returned_observation >
[ 0.          0.46499111]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1441 #########################################
< action >
[-0.03523988 -0.00843736]
< returned_observation >
[ 0.          0.45655375]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1442 #########################################
< action >
[-0.03603185 -0.00873911]
< returned_observation >
[ 0.          0.44781464]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1443 #########################################
< action >
[-0.03743551 -0.00895797]
< returned_observation >
[ 0.          0.43885667]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1444 #########################################
< action >
[-0.03815934 -0.00899381]
< returned_observation >
[ 0.          0.42986286]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1445 #########################################
< action >
[-0.0365415  -0.00876383]
< returned_observation >
[ 0.          0.42109903]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1446 #########################################
< action >
[-0.03827383 -0.01147783]
< returned_observation >
[ 0.          0.40962119]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1447 #########################################
< action >
[-0.03841254 -0.01294282]
< returned_observation >
[ 0.          0.39667837]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1448 #########################################
< action >
[-0.03765898 -0.01331653]
< returned_observation >
[ 0.          0.38336184]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1449 #########################################
< action >
[-0.0372535  -0.01186227]
< returned_observation >
[ 0.          0.37149957]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1450 #########################################
< action >
[-0.03624966 -0.01206273]
< returned_observation >
[ 0.          0.35943684]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1451 #########################################
< action >
[-0.03694829 -0.01063184]
< returned_observation >
[ 0.          0.34880499]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1452 #########################################
< action >
[-0.03671797 -0.0100347 ]
< returned_observation >
[ 0.          0.33877029]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1453 #########################################
< action >
[-0.03652579 -0.0088073 ]
< returned_observation >
[ 0.        0.329963]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1454 #########################################
< action >
[-0.03635471 -0.00906361]
< returned_observation >
[ 0.          0.32089939]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1455 #########################################
< action >
[-0.03511898 -0.00898286]
< returned_observation >
[ 0.          0.31191653]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1456 #########################################
< action >
[-0.03403512 -0.00787453]
< returned_observation >
[ 0.        0.304042]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1457 #########################################
< action >
[-0.03440163 -0.0067173 ]
< returned_observation >
[ 0.         0.2973247]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1458 #########################################
< action >
[-0.03349925 -0.00527914]
< returned_observation >
[ 0.          0.29204556]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1459 #########################################
< action >
[-0.03345043 -0.00486116]
< returned_observation >
[ 0.         0.2871844]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1460 #########################################
< action >
[-0.03302188 -0.00361242]
< returned_observation >
[ 0.          0.28357198]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1461 #########################################
< action >
[-0.034376   -0.00413018]
< returned_observation >
[ 0.         0.2794418]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1462 #########################################
< action >
[-0.03419988 -0.00368584]
< returned_observation >
[ 0.          0.27575595]
< reward >
-10.0
< running_reward >
-3.0
< done >
False
######################################### STEP 1463 #########################################
< action >
[-0.0332026  -0.00281664]
< returned_observation >
[ 0.          0.27293932]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1464 #########################################
< action >
[-0.03452828 -0.00294681]
< returned_observation >
[ 0.         0.2699925]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1465 #########################################
< action >
[-0.03285265 -0.00502994]
< returned_observation >
[ 0.          0.26496257]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1466 #########################################
< action >
[-0.03197726 -0.00571451]
< returned_observation >
[ 0.          0.25924806]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1467 #########################################
< action >
[-0.03214409 -0.0052229 ]
< returned_observation >
[ 0.          0.25402516]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1468 #########################################
< action >
[-0.03057103 -0.0047901 ]
< returned_observation >
[ 0.          0.24923506]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1469 #########################################
< action >
[-0.02875783 -0.00388969]
< returned_observation >
[ 0.          0.24534537]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1470 #########################################
< action >
[-0.0282939 -0.0023353]
< returned_observation >
[ 0.          0.24301007]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1471 #########################################
< action >
[-0.02658813 -0.00198775]
< returned_observation >
[ 0.          0.24102232]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1472 #########################################
< action >
[-0.02867164 -0.0007707 ]
< returned_observation >
[ 0.          0.24025162]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1473 #########################################
< action >
[-0.03096261 -0.00250126]
< returned_observation >
[ 0.          0.23775036]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1474 #########################################
< action >
[-0.03178517 -0.00336928]
< returned_observation >
[ 0.          0.23438108]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1475 #########################################
< action >
[-0.03021485 -0.00199184]
< returned_observation >
[ 0.          0.23238924]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1476 #########################################
< action >
[-0.0292538  -0.00138958]
< returned_observation >
[ 0.          0.23099966]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1477 #########################################
< action >
[-0.03092842 -0.00287556]
< returned_observation >
[ 0.         0.2281241]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1478 #########################################
< action >
[-0.03046761 -0.00214055]
< returned_observation >
[ 0.          0.22598355]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1479 #########################################
< action >
[-0.03045701 -0.00298555]
< returned_observation >
[ 0.          0.22299801]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1480 #########################################
< action >
[-0.03020825 -0.00284142]
< returned_observation >
[ 0.          0.22015658]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1481 #########################################
< action >
[-0.03005574 -0.00354823]
< returned_observation >
[ 0.          0.21660835]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1482 #########################################
< action >
[-0.03004667 -0.00273075]
< returned_observation >
[ 0.         0.2138776]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1483 #########################################
< action >
[-0.02902995 -0.00510956]
< returned_observation >
[ 0.          0.20876804]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1484 #########################################
< action >
[-0.0291982  -0.00463662]
< returned_observation >
[ 0.          0.20413142]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1485 #########################################
< action >
[-0.0281941  -0.00584531]
< returned_observation >
[ 0.          0.19828612]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1486 #########################################
< action >
[-0.02968543 -0.00724608]
< returned_observation >
[ 0.          0.19104004]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1487 #########################################
< action >
[-0.03053432 -0.0083542 ]
< returned_observation >
[ 0.          0.18268584]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1488 #########################################
< action >
[-0.03189521 -0.00852055]
< returned_observation >
[ 0.          0.17416529]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1489 #########################################
< action >
[-0.03102568 -0.00921877]
< returned_observation >
[ 0.          0.16494652]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1490 #########################################
< action >
[-0.03205765 -0.0075583 ]
< returned_observation >
[ 0.          0.15738822]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1491 #########################################
< action >
[-0.03298291 -0.00835098]
< returned_observation >
[ 0.          0.14903724]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1492 #########################################
< action >
[-0.03299017 -0.00832747]
< returned_observation >
[ 0.          0.14070977]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1493 #########################################
< action >
[-0.03242611 -0.00987788]
< returned_observation >
[ 0.          0.13083189]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1494 #########################################
< action >
[-0.03260667 -0.01072465]
< returned_observation >
[ 0.          0.12010724]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1495 #########################################
< action >
[-0.03409075 -0.00887437]
< returned_observation >
[ 0.          0.11123287]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1496 #########################################
< action >
[-0.03407058 -0.00838093]
< returned_observation >
[ 0.          0.10285194]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1497 #########################################
< action >
[-0.03391363 -0.00902464]
< returned_observation >
[ 0.          0.09382729]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1498 #########################################
< action >
[-0.03420644 -0.00685875]
< returned_observation >
[ 0.          0.08696854]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1499 #########################################
< action >
[-0.03404615 -0.00672821]
< returned_observation >
[ 0.          0.08024034]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1500 #########################################
< action >
[-0.03350443 -0.00699526]
< returned_observation >
[ 0.          0.07324508]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1501 #########################################
< action >
[-0.03367601 -0.0084145 ]
< returned_observation >
[ 0.          0.06483058]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1502 #########################################
< action >
[-0.03217295 -0.00863916]
< returned_observation >
[ 0.          0.05619142]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1503 #########################################
< action >
[-0.03175717 -0.00790103]
< returned_observation >
[ 0.          0.04829039]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1504 #########################################
< action >
[-0.03222053 -0.00890352]
< returned_observation >
[ 0.          0.03938688]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1505 #########################################
< action >
[-0.032133   -0.00898315]
< returned_observation >
[ 0.          0.03040372]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1506 #########################################
< action >
[-0.03128043 -0.01049342]
< returned_observation >
[ 0.         0.0199103]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1507 #########################################
< action >
[-0.03320374 -0.01070829]
< returned_observation >
[ 0.          0.00920201]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1508 #########################################
< action >
[-0.03354051 -0.01083501]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 21 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 97, 'min_reward': -12.600000000000001, 'episode_reward': -652.8, 'nb_steps': 1509, 'ave_reward': -6.729896907216494}
######################################### STEP 1509 #########################################
< action >
[-0.02944511 -0.01896872]
< returned_observation >
[ 0.          0.45051965]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1510 #########################################
< action >
[-0.03027146 -0.01870494]
< returned_observation >
[ 0.          0.43181472]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1511 #########################################
< action >
[-0.02983162 -0.02027468]
< returned_observation >
[ 0.          0.41154004]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1512 #########################################
< action >
[-0.02985793 -0.01959111]
< returned_observation >
[ 0.          0.39194892]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1513 #########################################
< action >
[-0.03142367 -0.02182516]
< returned_observation >
[ 0.          0.37012376]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1514 #########################################
< action >
[-0.03143472 -0.02098489]
< returned_observation >
[ 0.          0.34913888]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1515 #########################################
< action >
[-0.02922434 -0.01976922]
< returned_observation >
[ 0.          0.32936966]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1516 #########################################
< action >
[-0.02693674 -0.02035021]
< returned_observation >
[ 0.          0.30901945]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1517 #########################################
< action >
[-0.02648449 -0.02175446]
< returned_observation >
[ 0.          0.28726499]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1518 #########################################
< action >
[-0.02648106 -0.0201944 ]
< returned_observation >
[ 0.          0.26707058]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1519 #########################################
< action >
[-0.0264884  -0.02047682]
< returned_observation >
[ 0.          0.24659376]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1520 #########################################
< action >
[-0.02555493 -0.02100751]
< returned_observation >
[ 0.          0.22558625]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1521 #########################################
< action >
[-0.02528388 -0.02033252]
< returned_observation >
[ 0.          0.20525373]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1522 #########################################
< action >
[-0.02659263 -0.01889432]
< returned_observation >
[ 0.         0.1863594]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1523 #########################################
< action >
[-0.0252787  -0.01850826]
< returned_observation >
[ 0.          0.16785114]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1524 #########################################
< action >
[-0.02490291 -0.01847898]
< returned_observation >
[ 0.          0.14937216]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1525 #########################################
< action >
[-0.02496101 -0.01839342]
< returned_observation >
[ 0.          0.13097874]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1526 #########################################
< action >
[-0.02305966 -0.01729663]
< returned_observation >
[ 0.          0.11368211]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1527 #########################################
< action >
[-0.02221112 -0.01861943]
< returned_observation >
[ 0.          0.09506268]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1528 #########################################
< action >
[-0.02112799 -0.01814798]
< returned_observation >
[ 0.         0.0769147]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1529 #########################################
< action >
[-0.02310584 -0.02010475]
< returned_observation >
[ 0.          0.05680995]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1530 #########################################
< action >
[-0.02316249 -0.0204121 ]
< returned_observation >
[ 0.          0.03639785]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1531 #########################################
< action >
[-0.02405488 -0.018735  ]
< returned_observation >
[ 0.          0.01766285]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1532 #########################################
< action >
[-0.02410707 -0.01791709]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 22 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 24, 'min_reward': -12.5, 'episode_reward': -163.00000000000003, 'nb_steps': 1533, 'ave_reward': -6.791666666666668}
######################################### STEP 1533 #########################################
< action >
[-0.02982966 -0.02056667]
< returned_observation >
[ 0.95163908  0.37837813]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1534 #########################################
< action >
[-0.02829954 -0.02075413]
< returned_observation >
[ 0.92333954  0.357624  ]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 1535 #########################################
< action >
[-0.02772285 -0.02003589]
< returned_observation >
[ 0.89561669  0.33758811]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1536 #########################################
< action >
[-0.028817   -0.01854791]
< returned_observation >
[ 0.86679968  0.3190402 ]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 1537 #########################################
< action >
[-0.03108218 -0.0177819 ]
< returned_observation >
[ 0.83571751  0.30125831]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1538 #########################################
< action >
[-0.03143773 -0.01826824]
< returned_observation >
[ 0.80427977  0.28299007]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 1539 #########################################
< action >
[-0.03272782 -0.01840137]
< returned_observation >
[ 0.77155195  0.2645887 ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1540 #########################################
< action >
[-0.03028052 -0.01650113]
< returned_observation >
[ 0.74127143  0.24808757]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1541 #########################################
< action >
[-0.02997171 -0.01854331]
< returned_observation >
[ 0.71129972  0.22954426]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1542 #########################################
< action >
[-0.03085242 -0.01970318]
< returned_observation >
[ 0.6804473   0.20984109]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1543 #########################################
< action >
[-0.03268912 -0.01977829]
< returned_observation >
[ 0.64775818  0.19006279]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1544 #########################################
< action >
[-0.03344946 -0.02000594]
< returned_observation >
[ 0.61430872  0.17005686]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1545 #########################################
< action >
[-0.03237989 -0.01895007]
< returned_observation >
[ 0.58192882  0.15110679]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1546 #########################################
< action >
[-0.03409789 -0.01978088]
< returned_observation >
[ 0.54783093  0.13132591]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1547 #########################################
< action >
[-0.03363448 -0.01797721]
< returned_observation >
[ 0.51419645  0.1133487 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1548 #########################################
< action >
[-0.03249732 -0.01695203]
< returned_observation >
[ 0.48169913  0.09639667]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1549 #########################################
< action >
[-0.03131178 -0.01500247]
< returned_observation >
[ 0.45038735  0.0813942 ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1550 #########################################
< action >
[-0.03102349 -0.0143364 ]
< returned_observation >
[ 0.41936386  0.0670578 ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1551 #########################################
< action >
[-0.03126867 -0.01555421]
< returned_observation >
[ 0.38809519  0.05150358]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1552 #########################################
< action >
[-0.03196267 -0.0150196 ]
< returned_observation >
[ 0.35613252  0.03648398]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1553 #########################################
< action >
[-0.03319072 -0.01510597]
< returned_observation >
[ 0.3229418   0.02137801]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1554 #########################################
< action >
[-0.03425536 -0.01539897]
< returned_observation >
[ 0.28868644  0.00597904]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1555 #########################################
< action >
[-0.03273532 -0.01580355]
< returned_observation >
[ 0.25595112  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1556 #########################################
< action >
[-0.03431717 -0.01449748]
< returned_observation >
[ 0.22163395  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1557 #########################################
< action >
[-0.03424409 -0.01414245]
< returned_observation >
[ 0.18738986  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1558 #########################################
< action >
[-0.03543755 -0.01278931]
< returned_observation >
[ 0.15195232  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1559 #########################################
< action >
[-0.03669202 -0.01393779]
< returned_observation >
[ 0.1152603  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1560 #########################################
< action >
[-0.03552294 -0.01508818]
< returned_observation >
[ 0.07973737  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1561 #########################################
< action >
[-0.03658194 -0.01449598]
< returned_observation >
[ 0.04315543  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1562 #########################################
< action >
[-0.03788768 -0.0139525 ]
< returned_observation >
[ 0.00526774  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1563 #########################################
< action >
[-0.0361593  -0.01354885]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 23 infomation #####################
{'max_reward': 3.3000000000000007, 'nb_episode_steps': 31, 'min_reward': -13.399999999999999, 'episode_reward': -323.8999999999999, 'nb_steps': 1564, 'ave_reward': -10.44838709677419}
######################################### STEP 1564 #########################################
< action >
[-0.02872184 -0.02030672]
< returned_observation >
[ 0.78501064  0.52614978]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1565 #########################################
< action >
[-0.03000534 -0.01881388]
< returned_observation >
[ 0.75500529  0.5073359 ]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1566 #########################################
< action >
[-0.02933508 -0.01742864]
< returned_observation >
[ 0.72567021  0.48990726]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1567 #########################################
< action >
[-0.03137031 -0.01810838]
< returned_observation >
[ 0.6942999   0.47179888]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1568 #########################################
< action >
[-0.03016346 -0.01924003]
< returned_observation >
[ 0.66413643  0.45255885]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1569 #########################################
< action >
[-0.03141366 -0.02022108]
< returned_observation >
[ 0.63272277  0.43233777]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1570 #########################################
< action >
[-0.03074394 -0.02021564]
< returned_observation >
[ 0.60197883  0.41212213]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1571 #########################################
< action >
[-0.03064605 -0.02305478]
< returned_observation >
[ 0.57133278  0.38906735]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1572 #########################################
< action >
[-0.03085838 -0.02252672]
< returned_observation >
[ 0.5404744   0.36654063]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1573 #########################################
< action >
[-0.03112012 -0.02219915]
< returned_observation >
[ 0.50935429  0.34434148]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1574 #########################################
< action >
[-0.03083083 -0.02267577]
< returned_observation >
[ 0.47852346  0.32166572]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1575 #########################################
< action >
[-0.03153447 -0.02319806]
< returned_observation >
[ 0.44698898  0.29846766]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1576 #########################################
< action >
[-0.03009306 -0.02237491]
< returned_observation >
[ 0.41689592  0.27609275]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1577 #########################################
< action >
[-0.02950122 -0.02358829]
< returned_observation >
[ 0.38739469  0.25250446]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1578 #########################################
< action >
[-0.03039114 -0.02364369]
< returned_observation >
[ 0.35700355  0.22886076]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1579 #########################################
< action >
[-0.03110036 -0.02522926]
< returned_observation >
[ 0.32590319  0.2036315 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1580 #########################################
< action >
[-0.03218367 -0.0258767 ]
< returned_observation >
[ 0.29371951  0.1777548 ]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1581 #########################################
< action >
[-0.03206761 -0.02572147]
< returned_observation >
[ 0.2616519   0.15203333]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1582 #########################################
< action >
[-0.03317589 -0.02522357]
< returned_observation >
[ 0.22847602  0.12680976]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1583 #########################################
< action >
[-0.0350647  -0.02493324]
< returned_observation >
[ 0.19341132  0.10187652]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1584 #########################################
< action >
[-0.03490094 -0.02511467]
< returned_observation >
[ 0.15851038  0.07676184]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1585 #########################################
< action >
[-0.03571226 -0.02552259]
< returned_observation >
[ 0.12279813  0.05123926]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1586 #########################################
< action >
[-0.03569531 -0.02533754]
< returned_observation >
[ 0.08710282  0.02590171]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1587 #########################################
< action >
[-0.03603991 -0.02597399]
< returned_observation >
[ 0.05106291  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1588 #########################################
< action >
[-0.03771    -0.02592294]
< returned_observation >
[ 0.01335291  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1589 #########################################
< action >
[-0.03646848 -0.02474779]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 24 infomation #####################
{'max_reward': 3.3999999999999986, 'nb_episode_steps': 26, 'min_reward': -12.399999999999999, 'episode_reward': -202.89999999999998, 'nb_steps': 1590, 'ave_reward': -7.803846153846153}
######################################### STEP 1590 #########################################
< action >
[-0.02919467 -0.02023947]
< returned_observation >
[ 0.74165942  0.46469161]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1591 #########################################
< action >
[-0.02867262 -0.02100695]
< returned_observation >
[ 0.71298679  0.44368466]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1592 #########################################
< action >
[-0.0282311  -0.01980789]
< returned_observation >
[ 0.68475569  0.42387676]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 1593 #########################################
< action >
[-0.02969322 -0.02012914]
< returned_observation >
[ 0.65506247  0.40374762]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 1594 #########################################
< action >
[-0.02918412 -0.0196285 ]
< returned_observation >
[ 0.62587835  0.38411912]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1595 #########################################
< action >
[-0.02868897 -0.01974241]
< returned_observation >
[ 0.59718938  0.36437671]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1596 #########################################
< action >
[-0.02904475 -0.01867541]
< returned_observation >
[ 0.56814462  0.3457013 ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1597 #########################################
< action >
[-0.02861047 -0.01816654]
< returned_observation >
[ 0.53953415  0.32753476]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1598 #########################################
< action >
[-0.02954026 -0.01727294]
< returned_observation >
[ 0.50999389  0.31026182]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1599 #########################################
< action >
[-0.02871159 -0.01856308]
< returned_observation >
[ 0.4812823   0.29169874]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1600 #########################################
< action >
[-0.02956238 -0.01907136]
< returned_observation >
[ 0.45171992  0.27262739]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1601 #########################################
< action >
[-0.02992191 -0.01844565]
< returned_observation >
[ 0.42179801  0.25418173]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1602 #########################################
< action >
[-0.02775895 -0.01738639]
< returned_observation >
[ 0.39403906  0.23679535]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1603 #########################################
< action >
[-0.02871736 -0.0177873 ]
< returned_observation >
[ 0.36532169  0.21900805]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1604 #########################################
< action >
[-0.02943024 -0.01841221]
< returned_observation >
[ 0.33589145  0.20059583]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1605 #########################################
< action >
[-0.03010714 -0.01880759]
< returned_observation >
[ 0.30578431  0.18178825]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1606 #########################################
< action >
[-0.03063215 -0.01886944]
< returned_observation >
[ 0.27515216  0.16291881]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1607 #########################################
< action >
[-0.03071468 -0.01681788]
< returned_observation >
[ 0.24443748  0.14610093]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1608 #########################################
< action >
[-0.03061653 -0.01553597]
< returned_observation >
[ 0.21382095  0.13056496]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1609 #########################################
< action >
[-0.02800447 -0.01670265]
< returned_observation >
[ 0.18581647  0.11386231]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1610 #########################################
< action >
[-0.02733534 -0.01677719]
< returned_observation >
[ 0.15848113  0.09708512]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1611 #########################################
< action >
[-0.02636907 -0.01860429]
< returned_observation >
[ 0.13211206  0.07848083]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1612 #########################################
< action >
[-0.02708064 -0.0185771 ]
< returned_observation >
[ 0.10503142  0.05990374]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1613 #########################################
< action >
[-0.02875092 -0.01798474]
< returned_observation >
[ 0.07628051  0.041919  ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1614 #########################################
< action >
[-0.02635047 -0.01807159]
< returned_observation >
[ 0.04993003  0.02384741]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1615 #########################################
< action >
[-0.02507306 -0.01890099]
< returned_observation >
[ 0.02485697  0.00494642]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1616 #########################################
< action >
[-0.02443936 -0.01773204]
< returned_observation >
[ 0.00041761  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1617 #########################################
< action >
[-0.02369765 -0.01725415]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 25 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 28, 'min_reward': -13.100000000000001, 'episode_reward': -271.99999999999994, 'nb_steps': 1618, 'ave_reward': -9.714285714285712}
######################################### STEP 1618 #########################################
< action >
[-0.03140263 -0.02255013]
< returned_observation >
[ 0.          0.06397556]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1619 #########################################
< action >
[-0.0309792  -0.02228314]
< returned_observation >
[ 0.          0.04169242]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1620 #########################################
< action >
[-0.02964265 -0.0228128 ]
< returned_observation >
[ 0.          0.01887963]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1621 #########################################
< action >
[-0.02761577 -0.02164645]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 26 infomation #####################
{'max_reward': -11.100000000000001, 'nb_episode_steps': 4, 'min_reward': -12.3, 'episode_reward': -45.6, 'nb_steps': 1622, 'ave_reward': -11.4}
######################################### STEP 1622 #########################################
< action >
[-0.02978662 -0.02141449]
< returned_observation >
[ 0.0816672   0.22983062]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1623 #########################################
< action >
[-0.03114187 -0.02153334]
< returned_observation >
[ 0.05052532  0.20829728]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1624 #########################################
< action >
[-0.03107139 -0.02131089]
< returned_observation >
[ 0.01945393  0.18698639]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1625 #########################################
< action >
[-0.03128465 -0.02011456]
< returned_observation >
[ 0.          0.16687183]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1626 #########################################
< action >
[-0.03231027 -0.01818639]
< returned_observation >
[ 0.          0.14868544]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1627 #########################################
< action >
[-0.03072492 -0.01683373]
< returned_observation >
[ 0.          0.13185171]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1628 #########################################
< action >
[-0.03162384 -0.01653297]
< returned_observation >
[ 0.          0.11531874]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1629 #########################################
< action >
[-0.03052269 -0.0160744 ]
< returned_observation >
[ 0.          0.09924434]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1630 #########################################
< action >
[-0.03043893 -0.01640458]
< returned_observation >
[ 0.          0.08283976]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1631 #########################################
< action >
[-0.03141882 -0.01691442]
< returned_observation >
[ 0.          0.06592535]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1632 #########################################
< action >
[-0.0301823  -0.01610974]
< returned_observation >
[ 0.         0.0498156]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1633 #########################################
< action >
[-0.03050523 -0.01769071]
< returned_observation >
[ 0.         0.0321249]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1634 #########################################
< action >
[-0.03127047 -0.01834795]
< returned_observation >
[ 0.          0.01377695]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1635 #########################################
< action >
[-0.03206453 -0.01482893]
< returned_observation >
[ 0.  0.]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
True
##################### episode 27 infomation #####################
{'max_reward': 3.5, 'nb_episode_steps': 14, 'min_reward': -12.600000000000001, 'episode_reward': -119.19999999999999, 'nb_steps': 1636, 'ave_reward': -8.514285714285714}
######################################### STEP 1636 #########################################
< action >
[-0.02854529 -0.02225241]
< returned_observation >
[ 0.93637001  0.60951364]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1637 #########################################
< action >
[-0.02819475 -0.02170568]
< returned_observation >
[ 0.90817526  0.58780796]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1638 #########################################
< action >
[-0.02934058 -0.01987857]
< returned_observation >
[ 0.87883467  0.56792939]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 1639 #########################################
< action >
[-0.03105587 -0.02024067]
< returned_observation >
[ 0.8477788   0.54768872]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1640 #########################################
< action >
[-0.03018506 -0.02127124]
< returned_observation >
[ 0.81759374  0.52641748]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1641 #########################################
< action >
[-0.03205312 -0.02252463]
< returned_observation >
[ 0.78554062  0.50389285]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1642 #########################################
< action >
[-0.03249632 -0.0225731 ]
< returned_observation >
[ 0.7530443   0.48131975]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 1643 #########################################
< action >
[-0.03014687 -0.02173389]
< returned_observation >
[ 0.72289743  0.45958585]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 1644 #########################################
< action >
[-0.02896412 -0.02115702]
< returned_observation >
[ 0.69393331  0.43842883]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 1645 #########################################
< action >
[-0.02946151 -0.02037342]
< returned_observation >
[ 0.6644718   0.41805541]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1646 #########################################
< action >
[-0.02842412 -0.02063009]
< returned_observation >
[ 0.63604768  0.39742532]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1647 #########################################
< action >
[-0.02762962 -0.0195212 ]
< returned_observation >
[ 0.60841806  0.37790412]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1648 #########################################
< action >
[-0.03011826 -0.02044704]
< returned_observation >
[ 0.57829981  0.35745708]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1649 #########################################
< action >
[-0.0302475  -0.02305252]
< returned_observation >
[ 0.54805231  0.33440456]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1650 #########################################
< action >
[-0.0301081  -0.02174459]
< returned_observation >
[ 0.5179442   0.31265997]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1651 #########################################
< action >
[-0.03056773 -0.02329307]
< returned_observation >
[ 0.48737647  0.2893669 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1652 #########################################
< action >
[-0.0309376  -0.02164047]
< returned_observation >
[ 0.45643888  0.26772643]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1653 #########################################
< action >
[-0.03134345 -0.02209755]
< returned_observation >
[ 0.42509543  0.24562887]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1654 #########################################
< action >
[-0.03116067 -0.02130353]
< returned_observation >
[ 0.39393476  0.22432535]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1655 #########################################
< action >
[-0.03186059 -0.02151239]
< returned_observation >
[ 0.36207417  0.20281296]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1656 #########################################
< action >
[-0.03098879 -0.02107974]
< returned_observation >
[ 0.33108538  0.18173322]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1657 #########################################
< action >
[-0.02950974 -0.02182982]
< returned_observation >
[ 0.30157564  0.1599034 ]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 1658 #########################################
< action >
[-0.02799515 -0.01962854]
< returned_observation >
[ 0.27358049  0.14027486]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1659 #########################################
< action >
[-0.02619222 -0.01970218]
< returned_observation >
[ 0.24738826  0.12057268]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1660 #########################################
< action >
[-0.02517059 -0.01749312]
< returned_observation >
[ 0.22221768  0.10307957]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1661 #########################################
< action >
[-0.02621304 -0.01764765]
< returned_observation >
[ 0.19600464  0.08543192]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1662 #########################################
< action >
[-0.02671442 -0.01697844]
< returned_observation >
[ 0.16929022  0.06845348]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1663 #########################################
< action >
[-0.02642434 -0.01669435]
< returned_observation >
[ 0.14286588  0.05175913]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1664 #########################################
< action >
[-0.0259001  -0.01592896]
< returned_observation >
[ 0.11696578  0.03583017]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1665 #########################################
< action >
[-0.02548604 -0.01653708]
< returned_observation >
[ 0.09147974  0.01929309]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1666 #########################################
< action >
[-0.02427331 -0.01473034]
< returned_observation >
[ 0.06720643  0.00456275]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1667 #########################################
< action >
[-0.02420869 -0.01498765]
< returned_observation >
[ 0.04299774  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1668 #########################################
< action >
[-0.02259349 -0.01535378]
< returned_observation >
[ 0.02040425  0.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 1669 #########################################
< action >
[-0.0213955  -0.01577529]
< returned_observation >
[ 0.  0.]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
True
##################### episode 28 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 34, 'min_reward': -13.0, 'episode_reward': -212.70000000000002, 'nb_steps': 1670, 'ave_reward': -6.255882352941177}
######################################### STEP 1670 #########################################
< action >
[-0.02758629 -0.02385884]
< returned_observation >
[ 0.78907391  0.54222316]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1671 #########################################
< action >
[-0.02969514 -0.02222923]
< returned_observation >
[ 0.75937877  0.51999393]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1672 #########################################
< action >
[-0.02766374 -0.02171142]
< returned_observation >
[ 0.73171502  0.49828251]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 1673 #########################################
< action >
[-0.02901369 -0.02027988]
< returned_observation >
[ 0.70270133  0.47800263]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1674 #########################################
< action >
[-0.02838973 -0.01845829]
< returned_observation >
[ 0.67431159  0.45954434]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1675 #########################################
< action >
[-0.02838345 -0.01818804]
< returned_observation >
[ 0.64592814  0.4413563 ]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1676 #########################################
< action >
[-0.02807663 -0.01928237]
< returned_observation >
[ 0.61785151  0.42207393]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 1677 #########################################
< action >
[-0.0283499  -0.02013117]
< returned_observation >
[ 0.58950161  0.40194276]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 1678 #########################################
< action >
[-0.0285701  -0.02103963]
< returned_observation >
[ 0.56093151  0.38090313]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1679 #########################################
< action >
[-0.02898968 -0.01991449]
< returned_observation >
[ 0.53194183  0.36098865]
< reward >
-13.2
< running_reward >
-3.9599999999999995
< done >
False
######################################### STEP 1680 #########################################
< action >
[-0.02866461 -0.02048717]
< returned_observation >
[ 0.50327721  0.34050147]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1681 #########################################
< action >
[-0.02793345 -0.01926571]
< returned_observation >
[ 0.47534377  0.32123576]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1682 #########################################
< action >
[-0.02844159 -0.02029424]
< returned_observation >
[ 0.44690217  0.30094151]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1683 #########################################
< action >
[-0.03016246 -0.01985826]
< returned_observation >
[ 0.41673972  0.28108326]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1684 #########################################
< action >
[-0.02981082 -0.02205291]
< returned_observation >
[ 0.3869289   0.25903035]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1685 #########################################
< action >
[-0.02865494 -0.02023126]
< returned_observation >
[ 0.35827396  0.23879909]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1686 #########################################
< action >
[-0.02776595 -0.01811626]
< returned_observation >
[ 0.33050801  0.22068283]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1687 #########################################
< action >
[-0.02787895 -0.01963712]
< returned_observation >
[ 0.30262905  0.20104571]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1688 #########################################
< action >
[-0.02728623 -0.0200781 ]
< returned_observation >
[ 0.27534282  0.1809676 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1689 #########################################
< action >
[-0.02712338 -0.02033215]
< returned_observation >
[ 0.24821944  0.16063545]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1690 #########################################
< action >
[-0.0296781  -0.02136324]
< returned_observation >
[ 0.21854135  0.13927221]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 1691 #########################################
< action >
[-0.03023966 -0.0213299 ]
< returned_observation >
[ 0.18830169  0.1179423 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1692 #########################################
< action >
[-0.02938459 -0.02004348]
< returned_observation >
[ 0.1589171   0.09789882]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1693 #########################################
< action >
[-0.02891845 -0.01977388]
< returned_observation >
[ 0.12999865  0.07812494]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1694 #########################################
< action >
[-0.0291118  -0.02078896]
< returned_observation >
[ 0.10088685  0.05733598]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1695 #########################################
< action >
[-0.02918036 -0.02072839]
< returned_observation >
[ 0.07170649  0.03660759]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1696 #########################################
< action >
[-0.02982265 -0.02161121]
< returned_observation >
[ 0.04188383  0.01499638]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1697 #########################################
< action >
[-0.02928796 -0.02167361]
< returned_observation >
[ 0.01259587  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1698 #########################################
< action >
[-0.02766757 -0.0221047 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 29 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 29, 'min_reward': -13.5, 'episode_reward': -176.00000000000006, 'nb_steps': 1699, 'ave_reward': -6.068965517241382}
######################################### STEP 1699 #########################################
< action >
[-0.02474836 -0.02367764]
< returned_observation >
[ 0.61060785  0.78822475]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1700 #########################################
< action >
[-0.02580575 -0.02312272]
< returned_observation >
[ 0.5848021   0.76510203]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1701 #########################################
< action >
[-0.02680381 -0.02374766]
< returned_observation >
[ 0.55799829  0.74135437]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1702 #########################################
< action >
[-0.02704621 -0.0233052 ]
< returned_observation >
[ 0.53095209  0.71804917]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1703 #########################################
< action >
[-0.02825104 -0.02220924]
< returned_observation >
[ 0.50270105  0.69583994]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 1704 #########################################
< action >
[-0.02861134 -0.02303829]
< returned_observation >
[ 0.47408971  0.67280165]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1705 #########################################
< action >
[-0.0284684  -0.02220546]
< returned_observation >
[ 0.44562131  0.65059619]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 1706 #########################################
< action >
[-0.0263452  -0.02365232]
< returned_observation >
[ 0.41927611  0.62694387]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1707 #########################################
< action >
[-0.02634779 -0.02420908]
< returned_observation >
[ 0.39292832  0.60273479]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1708 #########################################
< action >
[-0.02547567 -0.02301996]
< returned_observation >
[ 0.36745265  0.57971483]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1709 #########################################
< action >
[-0.02545746 -0.02169565]
< returned_observation >
[ 0.3419952   0.55801918]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1710 #########################################
< action >
[-0.02522089 -0.02008088]
< returned_observation >
[ 0.31677431  0.5379383 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1711 #########################################
< action >
[-0.02578247 -0.01836465]
< returned_observation >
[ 0.29099184  0.51957365]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1712 #########################################
< action >
[-0.02846116 -0.0198932 ]
< returned_observation >
[ 0.26253067  0.49968045]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 1713 #########################################
< action >
[-0.02779864 -0.01879486]
< returned_observation >
[ 0.23473203  0.48088559]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1714 #########################################
< action >
[-0.02913353 -0.01936149]
< returned_observation >
[ 0.2055985   0.46152409]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1715 #########################################
< action >
[-0.02880258 -0.02009277]
< returned_observation >
[ 0.17679592  0.44143132]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1716 #########################################
< action >
[-0.02762943 -0.02119871]
< returned_observation >
[ 0.14916649  0.42023261]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1717 #########################################
< action >
[-0.02624761 -0.01964369]
< returned_observation >
[ 0.12291888  0.40058892]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1718 #########################################
< action >
[-0.02588419 -0.02062745]
< returned_observation >
[ 0.09703469  0.37996147]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1719 #########################################
< action >
[-0.02610274 -0.02156854]
< returned_observation >
[ 0.07093195  0.35839293]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1720 #########################################
< action >
[-0.02706767 -0.02387321]
< returned_observation >
[ 0.04386428  0.33451972]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1721 #########################################
< action >
[-0.02523083 -0.02446376]
< returned_observation >
[ 0.01863345  0.31005596]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1722 #########################################
< action >
[-0.02581886 -0.0255724 ]
< returned_observation >
[ 0.          0.28448356]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1723 #########################################
< action >
[-0.02601087 -0.02570876]
< returned_observation >
[ 0.         0.2587748]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1724 #########################################
< action >
[-0.02872361 -0.02451043]
< returned_observation >
[ 0.          0.23426436]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1725 #########################################
< action >
[-0.02862012 -0.02447085]
< returned_observation >
[ 0.          0.20979351]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1726 #########################################
< action >
[-0.03009802 -0.02472464]
< returned_observation >
[ 0.          0.18506886]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1727 #########################################
< action >
[-0.03056309 -0.02322253]
< returned_observation >
[ 0.          0.16184633]
< reward >
-10.0
< running_reward >
-3.0
< done >
False
######################################### STEP 1728 #########################################
< action >
[-0.0313667  -0.02307474]
< returned_observation >
[ 0.         0.1387716]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1729 #########################################
< action >
[-0.03183091 -0.02365088]
< returned_observation >
[ 0.          0.11512071]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1730 #########################################
< action >
[-0.03214948 -0.02532293]
< returned_observation >
[ 0.          0.08979778]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1731 #########################################
< action >
[-0.03189649 -0.02464705]
< returned_observation >
[ 0.          0.06515073]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1732 #########################################
< action >
[-0.03135248 -0.02419236]
< returned_observation >
[ 0.          0.04095836]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1733 #########################################
< action >
[-0.03165288 -0.02371419]
< returned_observation >
[ 0.          0.01724417]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1734 #########################################
< action >
[-0.03174479 -0.02357401]
< returned_observation >
[ 0.  0.]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
True
##################### episode 30 infomation #####################
{'max_reward': 3.6999999999999993, 'nb_episode_steps': 36, 'min_reward': -13.399999999999999, 'episode_reward': -134.20000000000002, 'nb_steps': 1735, 'ave_reward': -3.7277777777777783}
######################################### STEP 1735 #########################################
< action >
[-0.02497123 -0.02605916]
< returned_observation >
[ 0.90171138  0.8865676 ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1736 #########################################
< action >
[-0.02739661 -0.02621694]
< returned_observation >
[ 0.87431477  0.86035066]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1737 #########################################
< action >
[-0.02721809 -0.02622026]
< returned_observation >
[ 0.84709668  0.8341304 ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1738 #########################################
< action >
[-0.02703512 -0.02714175]
< returned_observation >
[ 0.82006156  0.80698865]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1739 #########################################
< action >
[-0.03005925 -0.02659731]
< returned_observation >
[ 0.7900023   0.78039134]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1740 #########################################
< action >
[-0.02949555 -0.02601564]
< returned_observation >
[ 0.76050676  0.7543757 ]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 1741 #########################################
< action >
[-0.02797321 -0.02429108]
< returned_observation >
[ 0.73253354  0.73008462]
< reward >
-2.0
< running_reward >
-0.6
< done >
False
######################################### STEP 1742 #########################################
< action >
[-0.02725479 -0.0229398 ]
< returned_observation >
[ 0.70527876  0.70714482]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1743 #########################################
< action >
[-0.02656533 -0.02379034]
< returned_observation >
[ 0.67871342  0.68335447]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 1744 #########################################
< action >
[-0.0268823  -0.02497093]
< returned_observation >
[ 0.65183112  0.65838355]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1745 #########################################
< action >
[-0.02745761 -0.02483996]
< returned_observation >
[ 0.62437351  0.63354358]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1746 #########################################
< action >
[-0.02758919 -0.02479046]
< returned_observation >
[ 0.59678432  0.60875312]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1747 #########################################
< action >
[-0.02904761 -0.0259048 ]
< returned_observation >
[ 0.56773672  0.58284832]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1748 #########################################
< action >
[-0.02889813 -0.02506385]
< returned_observation >
[ 0.53883858  0.55778447]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1749 #########################################
< action >
[-0.0266534  -0.02683856]
< returned_observation >
[ 0.51218519  0.53094591]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1750 #########################################
< action >
[-0.02772618 -0.02633018]
< returned_observation >
[ 0.48445901  0.50461573]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1751 #########################################
< action >
[-0.02791717 -0.0259746 ]
< returned_observation >
[ 0.45654184  0.47864113]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1752 #########################################
< action >
[-0.0267544  -0.02699772]
< returned_observation >
[ 0.42978743  0.45164341]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1753 #########################################
< action >
[-0.02765435 -0.02728269]
< returned_observation >
[ 0.40213309  0.42436071]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1754 #########################################
< action >
[-0.02732789 -0.02678576]
< returned_observation >
[ 0.3748052   0.39757495]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1755 #########################################
< action >
[-0.02644965 -0.02727001]
< returned_observation >
[ 0.34835555  0.37030494]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1756 #########################################
< action >
[-0.02588793 -0.027208  ]
< returned_observation >
[ 0.32246762  0.34309694]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1757 #########################################
< action >
[-0.02413148 -0.0258275 ]
< returned_observation >
[ 0.29833614  0.31726944]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1758 #########################################
< action >
[-0.02332183 -0.02605157]
< returned_observation >
[ 0.27501431  0.29121787]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1759 #########################################
< action >
[-0.02560446 -0.02448955]
< returned_observation >
[ 0.24940985  0.26672832]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1760 #########################################
< action >
[-0.02683049 -0.02556982]
< returned_observation >
[ 0.22257936  0.2411585 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1761 #########################################
< action >
[-0.02626781 -0.02416179]
< returned_observation >
[ 0.19631155  0.21699671]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1762 #########################################
< action >
[-0.02641346 -0.02463001]
< returned_observation >
[ 0.1698981  0.1923667]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1763 #########################################
< action >
[-0.0269641  -0.02429019]
< returned_observation >
[ 0.14293399  0.1680765 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1764 #########################################
< action >
[-0.02666018 -0.02381119]
< returned_observation >
[ 0.11627382  0.14426532]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1765 #########################################
< action >
[-0.02834206 -0.02266784]
< returned_observation >
[ 0.08793176  0.12159748]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1766 #########################################
< action >
[-0.02932173 -0.0231996 ]
< returned_observation >
[ 0.05861003  0.09839787]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1767 #########################################
< action >
[-0.0289672  -0.02241732]
< returned_observation >
[ 0.02964283  0.07598055]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1768 #########################################
< action >
[-0.02912363 -0.02391582]
< returned_observation >
[ 0.00051919  0.05206473]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1769 #########################################
< action >
[-0.0283321  -0.02392842]
< returned_observation >
[ 0.         0.0281363]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1770 #########################################
< action >
[-0.02807052 -0.0242348 ]
< returned_observation >
[ 0.         0.0039015]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1771 #########################################
< action >
[-0.02763453 -0.02319671]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 31 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 37, 'min_reward': -12.7, 'episode_reward': -278.5, 'nb_steps': 1772, 'ave_reward': -7.527027027027027}
######################################### STEP 1772 #########################################
< action >
[-0.02470687 -0.0252378 ]
< returned_observation >
[ 0.80010385  0.06896493]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1773 #########################################
< action >
[-0.02554906 -0.02726557]
< returned_observation >
[ 0.77455479  0.04169935]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1774 #########################################
< action >
[-0.02562104 -0.02794435]
< returned_observation >
[ 0.74893374  0.013755  ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1775 #########################################
< action >
[-0.02655913 -0.02924441]
< returned_observation >
[ 0.72237461  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1776 #########################################
< action >
[-0.0263499  -0.02988354]
< returned_observation >
[ 0.69602471  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1777 #########################################
< action >
[-0.02542519 -0.031701  ]
< returned_observation >
[ 0.67059952  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1778 #########################################
< action >
[-0.02435392 -0.03222125]
< returned_observation >
[ 0.6462456  0.       ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1779 #########################################
< action >
[-0.02405899 -0.03259269]
< returned_observation >
[ 0.62218662  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1780 #########################################
< action >
[-0.02400385 -0.03156772]
< returned_observation >
[ 0.59818276  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1781 #########################################
< action >
[-0.02332228 -0.03228963]
< returned_observation >
[ 0.57486049  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1782 #########################################
< action >
[-0.02294844 -0.03283762]
< returned_observation >
[ 0.55191205  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1783 #########################################
< action >
[-0.02481281 -0.03314827]
< returned_observation >
[ 0.52709924  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1784 #########################################
< action >
[-0.0241675  -0.03138102]
< returned_observation >
[ 0.50293174  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1785 #########################################
< action >
[-0.02240608 -0.03219903]
< returned_observation >
[ 0.48052566  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1786 #########################################
< action >
[-0.02347364 -0.03398335]
< returned_observation >
[ 0.45705202  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1787 #########################################
< action >
[-0.02397716 -0.03552114]
< returned_observation >
[ 0.43307486  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1788 #########################################
< action >
[-0.02207124 -0.03555139]
< returned_observation >
[ 0.41100362  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1789 #########################################
< action >
[-0.02087366 -0.03471922]
< returned_observation >
[ 0.39012997  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1790 #########################################
< action >
[-0.02047385 -0.03380352]
< returned_observation >
[ 0.36965612  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1791 #########################################
< action >
[-0.0185743  -0.03234438]
< returned_observation >
[ 0.35108182  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1792 #########################################
< action >
[-0.0166339  -0.03273801]
< returned_observation >
[ 0.33444792  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1793 #########################################
< action >
[-0.01670699 -0.0325795 ]
< returned_observation >
[ 0.31774093  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1794 #########################################
< action >
[-0.01551647 -0.03337281]
< returned_observation >
[ 0.30222446  0.        ]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1795 #########################################
< action >
[-0.0150015  -0.03320869]
< returned_observation >
[ 0.28722296  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1796 #########################################
< action >
[-0.01518074 -0.03296129]
< returned_observation >
[ 0.27204222  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1797 #########################################
< action >
[-0.01548993 -0.03291483]
< returned_observation >
[ 0.25655229  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1798 #########################################
< action >
[-0.01567742 -0.03386422]
< returned_observation >
[ 0.24087487  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1799 #########################################
< action >
[-0.01403522 -0.03512958]
< returned_observation >
[ 0.22683964  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1800 #########################################
< action >
[-0.01338098 -0.03502552]
< returned_observation >
[ 0.21345867  0.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1801 #########################################
< action >
[-0.01211918 -0.03430142]
< returned_observation >
[ 0.20133949  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1802 #########################################
< action >
[-0.01197426 -0.03278876]
< returned_observation >
[ 0.18936522  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1803 #########################################
< action >
[-0.01200663 -0.03320653]
< returned_observation >
[ 0.17735859  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1804 #########################################
< action >
[-0.01160475 -0.03295079]
< returned_observation >
[ 0.16575384  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1805 #########################################
< action >
[-0.01200604 -0.03157711]
< returned_observation >
[ 0.1537478  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1806 #########################################
< action >
[-0.00935861 -0.03081429]
< returned_observation >
[ 0.14438918  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1807 #########################################
< action >
[-0.01039922 -0.03190452]
< returned_observation >
[ 0.13398997  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1808 #########################################
< action >
[-0.01076269 -0.03184302]
< returned_observation >
[ 0.12322727  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1809 #########################################
< action >
[-0.01162727 -0.03121861]
< returned_observation >
[ 0.1116  0.    ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1810 #########################################
< action >
[-0.0122046  -0.03075524]
< returned_observation >
[ 0.0993954  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1811 #########################################
< action >
[-0.01220995 -0.02958445]
< returned_observation >
[ 0.08718545  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1812 #########################################
< action >
[-0.01298068 -0.02761478]
< returned_observation >
[ 0.07420477  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1813 #########################################
< action >
[-0.0134074  -0.02727886]
< returned_observation >
[ 0.06079737  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1814 #########################################
< action >
[-0.01356537 -0.0274939 ]
< returned_observation >
[ 0.047232  0.      ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1815 #########################################
< action >
[-0.01437123 -0.02771179]
< returned_observation >
[ 0.03286076  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1816 #########################################
< action >
[-0.01358485 -0.0283754 ]
< returned_observation >
[ 0.01927592  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1817 #########################################
< action >
[-0.01322299 -0.0278072 ]
< returned_observation >
[ 0.00605293  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1818 #########################################
< action >
[-0.01325013 -0.0298008 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 32 infomation #####################
{'max_reward': 2.3000000000000007, 'nb_episode_steps': 47, 'min_reward': -12.7, 'episode_reward': -530.6, 'nb_steps': 1819, 'ave_reward': -11.28936170212766}
######################################### STEP 1819 #########################################
< action >
[-0.02177352 -0.02593658]
< returned_observation >
[ 0.3392749   0.00957246]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1820 #########################################
< action >
[-0.02095012 -0.02650747]
< returned_observation >
[ 0.31832477  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1821 #########################################
< action >
[-0.01960868 -0.02560536]
< returned_observation >
[ 0.2987161  0.       ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1822 #########################################
< action >
[-0.01999351 -0.02533799]
< returned_observation >
[ 0.27872259  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1823 #########################################
< action >
[-0.02020317 -0.02541634]
< returned_observation >
[ 0.25851941  0.        ]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 1824 #########################################
< action >
[-0.01892564 -0.02554064]
< returned_observation >
[ 0.23959377  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1825 #########################################
< action >
[-0.02015242 -0.02385815]
< returned_observation >
[ 0.21944135  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1826 #########################################
< action >
[-0.01953694 -0.02160774]
< returned_observation >
[ 0.19990441  0.        ]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1827 #########################################
< action >
[-0.01949052 -0.02235119]
< returned_observation >
[ 0.18041389  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1828 #########################################
< action >
[-0.01966047 -0.02074784]
< returned_observation >
[ 0.16075342  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1829 #########################################
< action >
[-0.01785383 -0.01939041]
< returned_observation >
[ 0.14289959  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1830 #########################################
< action >
[-0.016772   -0.01860181]
< returned_observation >
[ 0.12612759  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1831 #########################################
< action >
[-0.0154312  -0.01906676]
< returned_observation >
[ 0.11069638  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1832 #########################################
< action >
[-0.0149359  -0.01902668]
< returned_observation >
[ 0.09576048  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1833 #########################################
< action >
[-0.01372165 -0.01723012]
< returned_observation >
[ 0.08203883  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1834 #########################################
< action >
[-0.01383899 -0.020181  ]
< returned_observation >
[ 0.06819984  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1835 #########################################
< action >
[-0.01417725 -0.02129525]
< returned_observation >
[ 0.05402259  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1836 #########################################
< action >
[-0.01464697 -0.02020426]
< returned_observation >
[ 0.03937562  0.        ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1837 #########################################
< action >
[-0.01528205 -0.02209607]
< returned_observation >
[ 0.02409357  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1838 #########################################
< action >
[-0.01433333 -0.02140988]
< returned_observation >
[ 0.00976024  0.        ]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 1839 #########################################
< action >
[-0.01220312 -0.02110603]
< returned_observation >
[ 0.  0.]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
True
##################### episode 33 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 21, 'min_reward': -13.0, 'episode_reward': -168.1, 'nb_steps': 1840, 'ave_reward': -8.004761904761905}
######################################### STEP 1840 #########################################
< action >
[-0.02220324 -0.02677334]
< returned_observation >
[ 0.52415511  0.76936938]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1841 #########################################
< action >
[-0.02197867 -0.02792732]
< returned_observation >
[ 0.50217644  0.74144206]
< reward >
-1.5
< running_reward >
-0.44999999999999996
< done >
False
######################################### STEP 1842 #########################################
< action >
[-0.01880694 -0.02956926]
< returned_observation >
[ 0.48336951  0.71187281]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1843 #########################################
< action >
[-0.0202954  -0.02854283]
< returned_observation >
[ 0.46307411  0.68332998]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1844 #########################################
< action >
[-0.01911695 -0.02784288]
< returned_observation >
[ 0.44395715  0.6554871 ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1845 #########################################
< action >
[-0.01882361 -0.02590998]
< returned_observation >
[ 0.42513355  0.62957712]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1846 #########################################
< action >
[-0.01953361 -0.02459737]
< returned_observation >
[ 0.40559994  0.60497975]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1847 #########################################
< action >
[-0.01805244 -0.02405587]
< returned_observation >
[ 0.38754749  0.58092388]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1848 #########################################
< action >
[-0.01844535 -0.02360427]
< returned_observation >
[ 0.36910214  0.55731961]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1849 #########################################
< action >
[-0.01935761 -0.02303993]
< returned_observation >
[ 0.34974453  0.53427968]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1850 #########################################
< action >
[-0.01907059 -0.02353694]
< returned_observation >
[ 0.33067394  0.51074273]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1851 #########################################
< action >
[-0.01907334 -0.02404742]
< returned_observation >
[ 0.3116006   0.48669532]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1852 #########################################
< action >
[-0.01723576 -0.0229284 ]
< returned_observation >
[ 0.29436484  0.46376691]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1853 #########################################
< action >
[-0.01907981 -0.02330945]
< returned_observation >
[ 0.27528503  0.44045747]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1854 #########################################
< action >
[-0.01801348 -0.02323302]
< returned_observation >
[ 0.25727154  0.41722445]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1855 #########################################
< action >
[-0.01719655 -0.02340894]
< returned_observation >
[ 0.240075    0.39381551]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1856 #########################################
< action >
[-0.01768419 -0.02250272]
< returned_observation >
[ 0.22239081  0.37131279]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1857 #########################################
< action >
[-0.01902755 -0.02378586]
< returned_observation >
[ 0.20336326  0.34752693]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1858 #########################################
< action >
[-0.01596751 -0.02400716]
< returned_observation >
[ 0.18739576  0.32351977]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1859 #########################################
< action >
[-0.01462358 -0.02385945]
< returned_observation >
[ 0.17277218  0.29966032]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1860 #########################################
< action >
[-0.01351019 -0.02383936]
< returned_observation >
[ 0.15926198  0.27582096]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1861 #########################################
< action >
[-0.0138467  -0.02314855]
< returned_observation >
[ 0.14541529  0.25267241]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1862 #########################################
< action >
[-0.01407577 -0.02285045]
< returned_observation >
[ 0.13133952  0.22982196]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1863 #########################################
< action >
[-0.01471723 -0.02193424]
< returned_observation >
[ 0.11662229  0.20788771]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1864 #########################################
< action >
[-0.01626079 -0.02268344]
< returned_observation >
[ 0.10036149  0.18520427]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1865 #########################################
< action >
[-0.01727044 -0.02283505]
< returned_observation >
[ 0.08309105  0.16236923]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1866 #########################################
< action >
[-0.01618048 -0.02207587]
< returned_observation >
[ 0.06691057  0.14029336]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1867 #########################################
< action >
[-0.0163761  -0.02140445]
< returned_observation >
[ 0.05053447  0.11888891]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1868 #########################################
< action >
[-0.01677065 -0.02233935]
< returned_observation >
[ 0.03376382  0.09654955]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1869 #########################################
< action >
[-0.01758833 -0.0238152 ]
< returned_observation >
[ 0.01617548  0.07273435]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1870 #########################################
< action >
[-0.01829635 -0.02286549]
< returned_observation >
[ 0.          0.04986886]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1871 #########################################
< action >
[-0.01989737 -0.02228092]
< returned_observation >
[ 0.          0.02758794]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1872 #########################################
< action >
[-0.01949575 -0.02144762]
< returned_observation >
[ 0.          0.00614032]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1873 #########################################
< action >
[-0.01987956 -0.02260257]
< returned_observation >
[ 0.  0.]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
True
##################### episode 34 infomation #####################
{'max_reward': 3.6000000000000014, 'nb_episode_steps': 34, 'min_reward': -12.399999999999999, 'episode_reward': -210.50000000000006, 'nb_steps': 1874, 'ave_reward': -6.191176470588237}
######################################### STEP 1874 #########################################
< action >
[-0.01952307 -0.02687926]
< returned_observation >
[ 0.03161974  0.16178848]
< reward >
3.8000000000000007
< running_reward >
1.1400000000000001
< done >
False
######################################### STEP 1875 #########################################
< action >
[-0.01950456 -0.02693492]
< returned_observation >
[ 0.01211518  0.13485356]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1876 #########################################
< action >
[-0.02020214 -0.02516171]
< returned_observation >
[ 0.          0.10969185]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1877 #########################################
< action >
[-0.02145484 -0.02586197]
< returned_observation >
[ 0.          0.08382988]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1878 #########################################
< action >
[-0.02238621 -0.02646992]
< returned_observation >
[ 0.          0.05735996]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1879 #########################################
< action >
[-0.02158995 -0.02539833]
< returned_observation >
[ 0.          0.03196163]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1880 #########################################
< action >
[-0.02118889 -0.02606614]
< returned_observation >
[ 0.          0.00589549]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1881 #########################################
< action >
[-0.02411481 -0.0253842 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 35 infomation #####################
{'max_reward': 3.8000000000000007, 'nb_episode_steps': 8, 'min_reward': -12.3, 'episode_reward': -76.30000000000001, 'nb_steps': 1882, 'ave_reward': -9.537500000000001}
######################################### STEP 1882 #########################################
< action >
[-0.01935808 -0.02617794]
< returned_observation >
[ 0.34611968  0.21811292]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1883 #########################################
< action >
[-0.0192163  -0.02529093]
< returned_observation >
[ 0.32690339  0.192822  ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1884 #########################################
< action >
[-0.02030597 -0.024493  ]
< returned_observation >
[ 0.30659742  0.168329  ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1885 #########################################
< action >
[-0.02096184 -0.02424497]
< returned_observation >
[ 0.28563558  0.14408402]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1886 #########################################
< action >
[-0.02089778 -0.02397592]
< returned_observation >
[ 0.2647378  0.1201081]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1887 #########################################
< action >
[-0.01916392 -0.02338915]
< returned_observation >
[ 0.24557387  0.09671895]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1888 #########################################
< action >
[-0.01930326 -0.02393435]
< returned_observation >
[ 0.22627061  0.07278461]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1889 #########################################
< action >
[-0.02052102 -0.02353404]
< returned_observation >
[ 0.2057496   0.04925056]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1890 #########################################
< action >
[-0.0215074  -0.02271968]
< returned_observation >
[ 0.1842422   0.02653089]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1891 #########################################
< action >
[-0.0211579  -0.02317294]
< returned_observation >
[ 0.1630843   0.00335795]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1892 #########################################
< action >
[-0.0204993  -0.02378763]
< returned_observation >
[ 0.142585  0.      ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1893 #########################################
< action >
[-0.02090797 -0.02363382]
< returned_observation >
[ 0.12167703  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1894 #########################################
< action >
[-0.02104357 -0.02230451]
< returned_observation >
[ 0.10063347  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1895 #########################################
< action >
[-0.02030002 -0.02299785]
< returned_observation >
[ 0.08033344  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1896 #########################################
< action >
[-0.0185823  -0.02268281]
< returned_observation >
[ 0.06175115  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1897 #########################################
< action >
[-0.01775309 -0.02246398]
< returned_observation >
[ 0.04399806  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1898 #########################################
< action >
[-0.01632096 -0.02175185]
< returned_observation >
[ 0.0276771  0.       ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1899 #########################################
< action >
[-0.01501122 -0.02157213]
< returned_observation >
[ 0.01266588  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1900 #########################################
< action >
[-0.01513871 -0.02085456]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 36 infomation #####################
{'max_reward': 3.3000000000000007, 'nb_episode_steps': 19, 'min_reward': -12.5, 'episode_reward': -189.60000000000002, 'nb_steps': 1901, 'ave_reward': -9.978947368421053}
######################################### STEP 1901 #########################################
< action >
[-0.01950819 -0.02745196]
< returned_observation >
[ 0.77557928  0.32464297]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1902 #########################################
< action >
[-0.01857966 -0.02668213]
< returned_observation >
[ 0.75699963  0.29796085]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1903 #########################################
< action >
[-0.01850572 -0.025117  ]
< returned_observation >
[ 0.73849391  0.27284385]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1904 #########################################
< action >
[-0.0175869  -0.02423854]
< returned_observation >
[ 0.72090701  0.2486053 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1905 #########################################
< action >
[-0.01548949 -0.02406258]
< returned_observation >
[ 0.70541752  0.22454272]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1906 #########################################
< action >
[-0.01420015 -0.02540281]
< returned_observation >
[ 0.69121738  0.19913991]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1907 #########################################
< action >
[-0.01549187 -0.02492581]
< returned_observation >
[ 0.67572551  0.1742141 ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1908 #########################################
< action >
[-0.01562565 -0.0247305 ]
< returned_observation >
[ 0.66009986  0.14948361]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1909 #########################################
< action >
[-0.01538888 -0.02511621]
< returned_observation >
[ 0.64471097  0.1243674 ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1910 #########################################
< action >
[-0.01609031 -0.02482351]
< returned_observation >
[ 0.62862066  0.09954389]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1911 #########################################
< action >
[-0.0169956  -0.02521032]
< returned_observation >
[ 0.61162506  0.07433357]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1912 #########################################
< action >
[-0.01693499 -0.02603106]
< returned_observation >
[ 0.59469007  0.04830251]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1913 #########################################
< action >
[-0.01755125 -0.02519617]
< returned_observation >
[ 0.57713882  0.02310634]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 1914 #########################################
< action >
[-0.01646191 -0.02488166]
< returned_observation >
[ 0.56067692  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1915 #########################################
< action >
[-0.01637326 -0.02301131]
< returned_observation >
[ 0.54430365  0.        ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1916 #########################################
< action >
[-0.01718946 -0.02249495]
< returned_observation >
[ 0.52711419  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1917 #########################################
< action >
[-0.01564489 -0.02258343]
< returned_observation >
[ 0.5114693  0.       ]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1918 #########################################
< action >
[-0.01337382 -0.01991084]
< returned_observation >
[ 0.49809548  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1919 #########################################
< action >
[-0.01387834 -0.01966488]
< returned_observation >
[ 0.48421714  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1920 #########################################
< action >
[-0.01363515 -0.02129007]
< returned_observation >
[ 0.47058199  0.        ]
< reward >
0.0
< running_reward >
0.0
< done >
False
