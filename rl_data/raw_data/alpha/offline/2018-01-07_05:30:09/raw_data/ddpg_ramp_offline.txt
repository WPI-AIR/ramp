######################################### STEP 0 #########################################
< action >
[  2.60244012e-03   7.96914101e-05]
< returned_observation >
[ 0.69907163  0.28621903]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1 #########################################
< action >
[ 0.00433927  0.00131692]
< returned_observation >
[ 0.7034109   0.28753594]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2 #########################################
< action >
[ 0.00352323  0.00120481]
< returned_observation >
[ 0.70693413  0.28874075]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 3 #########################################
< action >
[ 0.00295367  0.00290584]
< returned_observation >
[ 0.70988779  0.29164659]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 4 #########################################
< action >
[ 0.00288242  0.00100957]
< returned_observation >
[ 0.71277022  0.29265616]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 5 #########################################
< action >
[ 0.00211066  0.00232773]
< returned_observation >
[ 0.71488088  0.29498388]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 6 #########################################
< action >
[ 0.00391791  0.00136583]
< returned_observation >
[ 0.71879878  0.29634971]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 7 #########################################
< action >
[ 0.00260835  0.00074575]
< returned_observation >
[ 0.72140713  0.29709546]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 8 #########################################
< action >
[ 0.00228732  0.00044205]
< returned_observation >
[ 0.72369445  0.29753751]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 9 #########################################
< action >
[ 0.00312034  0.00151707]
< returned_observation >
[ 0.72681479  0.29905458]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 10 #########################################
< action >
[  7.03036785e-05   2.52788663e-03]
< returned_observation >
[ 0.72688509  0.30158246]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 11 #########################################
< action >
[-0.00169524  0.00314116]
< returned_observation >
[ 0.72518985  0.30472363]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 12 #########################################
< action >
[ 0.00030408  0.00311139]
< returned_observation >
[ 0.72549393  0.30783501]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 13 #########################################
< action >
[-0.0012799   0.00308636]
< returned_observation >
[ 0.72421403  0.31092138]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 14 #########################################
< action >
[ 0.00028841  0.00269195]
< returned_observation >
[ 0.72450244  0.31361333]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 15 #########################################
< action >
[ 0.00172218  0.00260168]
< returned_observation >
[ 0.72622462  0.316215  ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 16 #########################################
< action >
[ 0.00120371  0.00090694]
< returned_observation >
[ 0.72742833  0.31712195]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 17 #########################################
< action >
[ 0.00197541  0.00130365]
< returned_observation >
[ 0.72940374  0.3184256 ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 18 #########################################
< action >
[ 0.00166237 -0.00039527]
< returned_observation >
[ 0.7310661   0.31803033]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 19 #########################################
< action >
[ 0.00240718 -0.00089919]
< returned_observation >
[ 0.73347328  0.31713113]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 20 #########################################
< action >
[ 0.00264326 -0.00263489]
< returned_observation >
[ 0.73611655  0.31449624]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 21 #########################################
< action >
[ 0.0021198  -0.00356731]
< returned_observation >
[ 0.73823634  0.31092892]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 22 #########################################
< action >
[ 0.00064518 -0.0035917 ]
< returned_observation >
[ 0.73888152  0.30733723]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 23 #########################################
< action >
[-0.00058242 -0.00351223]
< returned_observation >
[ 0.7382991  0.303825 ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 24 #########################################
< action >
[-0.00252001 -0.00374487]
< returned_observation >
[ 0.73577909  0.30008013]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 25 #########################################
< action >
[-0.0043295  -0.00368496]
< returned_observation >
[ 0.73144959  0.29639517]
< reward >
-13.8
< running_reward >
-4.14
< done >
False
######################################### STEP 26 #########################################
< action >
[-0.00472484 -0.00341858]
< returned_observation >
[ 0.72672475  0.29297659]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 27 #########################################
< action >
[-0.0038326  -0.00339532]
< returned_observation >
[ 0.72289215  0.28958126]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 28 #########################################
< action >
[-0.00442818 -0.00462703]
< returned_observation >
[ 0.71846398  0.28495424]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 29 #########################################
< action >
[-0.00397767 -0.00387799]
< returned_observation >
[ 0.7144863   0.28107625]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 30 #########################################
< action >
[-0.0053492  -0.00442694]
< returned_observation >
[ 0.7091371   0.27664931]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 31 #########################################
< action >
[-0.00446508 -0.00658002]
< returned_observation >
[ 0.70467202  0.27006929]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 32 #########################################
< action >
[-0.00454315 -0.00657161]
< returned_observation >
[ 0.70012887  0.26349767]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 33 #########################################
< action >
[-0.00506347 -0.00640869]
< returned_observation >
[ 0.6950654   0.25708898]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 34 #########################################
< action >
[-0.00406396 -0.00719551]
< returned_observation >
[ 0.69100144  0.24989348]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 35 #########################################
< action >
[-0.00314655 -0.00751808]
< returned_observation >
[ 0.68785489  0.2423754 ]
< reward >
-10.2
< running_reward >
-3.0599999999999996
< done >
False
######################################### STEP 36 #########################################
< action >
[-0.00308553 -0.00798227]
< returned_observation >
[ 0.68476937  0.23439313]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 37 #########################################
< action >
[-0.0026237  -0.00828662]
< returned_observation >
[ 0.68214566  0.22610651]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 38 #########################################
< action >
[-0.00398624 -0.00846385]
< returned_observation >
[ 0.67815943  0.21764266]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 39 #########################################
< action >
[-0.00309328 -0.00903747]
< returned_observation >
[ 0.67506615  0.20860519]
< reward >
-13.8
< running_reward >
-4.14
< done >
False
######################################### STEP 40 #########################################
< action >
[-0.00120327 -0.00840912]
< returned_observation >
[ 0.67386287  0.20019607]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 41 #########################################
< action >
[-0.00088812 -0.00815423]
< returned_observation >
[ 0.67297475  0.19204184]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 42 #########################################
< action >
[-0.00152158 -0.00827215]
< returned_observation >
[ 0.67145317  0.18376969]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 43 #########################################
< action >
[ 0.00083977 -0.01066075]
< returned_observation >
[ 0.67229294  0.17310894]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 44 #########################################
< action >
[-0.00087767 -0.00993086]
< returned_observation >
[ 0.67141527  0.16317809]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 45 #########################################
< action >
[-0.00064199 -0.00931247]
< returned_observation >
[ 0.67077327  0.15386561]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 46 #########################################
< action >
[ -6.96510077e-05  -1.13980681e-02]
< returned_observation >
[ 0.67070362  0.14246754]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 47 #########################################
< action >
[-0.00181043 -0.01181239]
< returned_observation >
[ 0.6688932   0.13065515]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 48 #########################################
< action >
[-0.00125849 -0.01357996]
< returned_observation >
[ 0.66763471  0.11707519]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 49 #########################################
< action >
[-0.0011019  -0.01176049]
< returned_observation >
[ 0.66653281  0.10531471]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 50 #########################################
< action >
[ 0.00021365 -0.01318461]
< returned_observation >
[ 0.66674646  0.0921301 ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 51 #########################################
< action >
[ 0.00020875 -0.01313301]
< returned_observation >
[ 0.66695521  0.07899709]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 52 #########################################
< action >
[ 0.0001538  -0.01389654]
< returned_observation >
[ 0.66710901  0.06510055]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 53 #########################################
< action >
[-0.00252297 -0.01359254]
< returned_observation >
[ 0.66458604  0.05150801]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 54 #########################################
< action >
[-0.00323014 -0.01499343]
< returned_observation >
[ 0.6613559   0.03651458]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 55 #########################################
< action >
[-0.00273736 -0.01447321]
< returned_observation >
[ 0.65861854  0.02204137]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 56 #########################################
< action >
[-0.00402359 -0.0148529 ]
< returned_observation >
[ 0.65459495  0.00718847]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 57 #########################################
< action >
[-0.00329379 -0.01863282]
< returned_observation >
[ 0.65130116  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 58 #########################################
< action >
[-0.00451396 -0.01897016]
< returned_observation >
[ 0.6467872  0.       ]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 59 #########################################
< action >
[-0.00439198 -0.01947434]
< returned_observation >
[ 0.64239522  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 60 #########################################
< action >
[-0.00382547 -0.01979306]
< returned_observation >
[ 0.63856975  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 61 #########################################
< action >
[-0.00451137 -0.01720772]
< returned_observation >
[ 0.63405838  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 62 #########################################
< action >
[-0.00496109 -0.01813421]
< returned_observation >
[ 0.62909729  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 63 #########################################
< action >
[-0.00310712 -0.01870642]
< returned_observation >
[ 0.62599017  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 64 #########################################
< action >
[-0.00260926 -0.01993484]
< returned_observation >
[ 0.62338091  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 65 #########################################
< action >
[-0.00069498 -0.02004322]
< returned_observation >
[ 0.62268593  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 66 #########################################
< action >
[-0.00093217 -0.02283268]
< returned_observation >
[ 0.62175377  0.        ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 67 #########################################
< action >
[-0.00325457 -0.02287033]
< returned_observation >
[ 0.6184992  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 68 #########################################
< action >
[-0.00375313 -0.02075728]
< returned_observation >
[ 0.61474607  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 69 #########################################
< action >
[-0.00568257 -0.01907678]
< returned_observation >
[ 0.6090635  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 70 #########################################
< action >
[-0.00668989 -0.01995024]
< returned_observation >
[ 0.60237362  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 71 #########################################
< action >
[-0.00580053 -0.01940998]
< returned_observation >
[ 0.59657309  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 72 #########################################
< action >
[-0.00667259 -0.01698325]
< returned_observation >
[ 0.58990049  0.        ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 73 #########################################
< action >
[-0.00767789 -0.01535744]
< returned_observation >
[ 0.5822226  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 74 #########################################
< action >
[-0.00618405 -0.01481265]
< returned_observation >
[ 0.57603855  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 75 #########################################
< action >
[-0.00535646 -0.01477018]
< returned_observation >
[ 0.57068208  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 76 #########################################
< action >
[-0.00542816 -0.01668272]
< returned_observation >
[ 0.56525392  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 77 #########################################
< action >
[-0.00602342 -0.01760302]
< returned_observation >
[ 0.5592305  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 78 #########################################
< action >
[-0.00472484 -0.01870858]
< returned_observation >
[ 0.55450566  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 79 #########################################
< action >
[-0.00307072 -0.0175819 ]
< returned_observation >
[ 0.55143494  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 80 #########################################
< action >
[-0.00283429 -0.01590694]
< returned_observation >
[ 0.54860065  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 81 #########################################
< action >
[-0.00284424 -0.01687419]
< returned_observation >
[ 0.5457564  0.       ]
< reward >
-9.9
< running_reward >
-2.97
< done >
False
######################################### STEP 82 #########################################
< action >
[-0.00232125 -0.01777933]
< returned_observation >
[ 0.54343515  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 83 #########################################
< action >
[ -5.47230244e-05  -1.72106832e-02]
< returned_observation >
[ 0.54338043  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 84 #########################################
< action >
[-0.00014375 -0.01917244]
< returned_observation >
[ 0.54323668  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 85 #########################################
< action >
[-0.00038328 -0.0189283 ]
< returned_observation >
[ 0.54285339  0.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 86 #########################################
< action >
[-0.00052674 -0.01992049]
< returned_observation >
[ 0.54232665  0.        ]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 87 #########################################
< action >
[-0.00228218 -0.02113535]
< returned_observation >
[ 0.54004447  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 88 #########################################
< action >
[-0.00122369 -0.02164257]
< returned_observation >
[ 0.53882078  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 89 #########################################
< action >
[ 0.00134935 -0.02025846]
< returned_observation >
[ 0.54017013  0.        ]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 90 #########################################
< action >
[ 0.00161211 -0.02057009]
< returned_observation >
[ 0.54178224  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 91 #########################################
< action >
[ 0.00083571 -0.02065341]
< returned_observation >
[ 0.54261795  0.        ]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 92 #########################################
< action >
[ 0.00092741 -0.02195499]
< returned_observation >
[ 0.54354536  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 93 #########################################
< action >
[-0.00103733 -0.02213399]
< returned_observation >
[ 0.54250803  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 94 #########################################
< action >
[-0.00082931 -0.02295293]
< returned_observation >
[ 0.54167872  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 95 #########################################
< action >
[-0.00023138 -0.02435293]
< returned_observation >
[ 0.54144734  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 96 #########################################
< action >
[ 0.00039831 -0.02461863]
< returned_observation >
[ 0.54184565  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 97 #########################################
< action >
[ 0.00205567 -0.02393691]
< returned_observation >
[ 0.54390132  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 98 #########################################
< action >
[ 0.00240535 -0.02375141]
< returned_observation >
[ 0.54630667  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 99 #########################################
< action >
[ 0.00348552 -0.02572315]
< returned_observation >
[ 0.5497922  0.       ]
< reward >
-12.8
< running_reward >
-3.84
< done >
True
##################### episode 0 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -13.8, 'episode_reward': -898.3999999999997, 'ave_reward': -8.983999999999998, 'nb_steps': 100, 'max_reward': 3.6000000000000014}
######################################### STEP 100 #########################################
< action >
[ 0.00174888  0.00200435]
< returned_observation >
[ 0.22860034  0.55331912]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 101 #########################################
< action >
[ 0.00322579  0.00140484]
< returned_observation >
[ 0.23182613  0.55472396]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 102 #########################################
< action >
[ 0.0046591   0.00090794]
< returned_observation >
[ 0.23648523  0.5556319 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 103 #########################################
< action >
[ 0.00722248 -0.00048455]
< returned_observation >
[ 0.24370771  0.55514735]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 104 #########################################
< action >
[ 0.00535654 -0.00107198]
< returned_observation >
[ 0.24906425  0.55407536]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 105 #########################################
< action >
[ 0.00635951 -0.00145595]
< returned_observation >
[ 0.25542376  0.55261942]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 106 #########################################
< action >
[ 0.00663284 -0.00136054]
< returned_observation >
[ 0.2620566   0.55125887]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 107 #########################################
< action >
[ 0.00755151 -0.00146287]
< returned_observation >
[ 0.26960811  0.549796  ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 108 #########################################
< action >
[ 0.00674363 -0.00066934]
< returned_observation >
[ 0.27635174  0.54912666]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 109 #########################################
< action >
[ 0.00727484 -0.00017371]
< returned_observation >
[ 0.28362658  0.54895296]
< reward >
3.8000000000000007
< running_reward >
1.1400000000000001
< done >
False
######################################### STEP 110 #########################################
< action >
[ 0.00729613 -0.00027902]
< returned_observation >
[ 0.29092271  0.54867394]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 111 #########################################
< action >
[ 0.0083686   0.00072573]
< returned_observation >
[ 0.29929131  0.54939967]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 112 #########################################
< action >
[ 0.0075063   0.00061827]
< returned_observation >
[ 0.30679761  0.55001793]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 113 #########################################
< action >
[ 0.00690611  0.00134729]
< returned_observation >
[ 0.31370372  0.55136522]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 114 #########################################
< action >
[ 0.00598857  0.00137548]
< returned_observation >
[ 0.31969229  0.5527407 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 115 #########################################
< action >
[ 0.00393046  0.00227418]
< returned_observation >
[ 0.32362275  0.55501488]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 116 #########################################
< action >
[ 0.00492768  0.00092303]
< returned_observation >
[ 0.32855043  0.55593791]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 117 #########################################
< action >
[  6.11785054e-03  -2.88784504e-06]
< returned_observation >
[ 0.33466828  0.55593503]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 118 #########################################
< action >
[  6.29540086e-03   7.31170177e-05]
< returned_observation >
[ 0.34096368  0.55600814]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 119 #########################################
< action >
[ 0.0051696 -0.0007697]
< returned_observation >
[ 0.34613328  0.55523844]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 120 #########################################
< action >
[ 0.00499223 -0.00131722]
< returned_observation >
[ 0.35112552  0.55392122]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 121 #########################################
< action >
[ 0.00600823 -0.00278465]
< returned_observation >
[ 0.35713374  0.55113657]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 122 #########################################
< action >
[ 0.00659946 -0.00309423]
< returned_observation >
[ 0.3637332   0.54804235]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 123 #########################################
< action >
[ 0.00598321 -0.00281484]
< returned_observation >
[ 0.36971641  0.54522751]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 124 #########################################
< action >
[ 0.00647298 -0.00246446]
< returned_observation >
[ 0.37618939  0.54276305]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 125 #########################################
< action >
[ 0.0067131  -0.00244623]
< returned_observation >
[ 0.38290249  0.54031682]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 126 #########################################
< action >
[ 0.00595652 -0.00250166]
< returned_observation >
[ 0.38885901  0.53781516]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 127 #########################################
< action >
[ 0.00868823 -0.00070913]
< returned_observation >
[ 0.39754724  0.53710602]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 128 #########################################
< action >
[ 0.00965325 -0.00044881]
< returned_observation >
[ 0.40720049  0.53665722]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 129 #########################################
< action >
[ 0.01011894 -0.000716  ]
< returned_observation >
[ 0.41731943  0.53594122]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 130 #########################################
< action >
[ 0.00825958 -0.00221393]
< returned_observation >
[ 0.42557901  0.5337273 ]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 131 #########################################
< action >
[ 0.00715898 -0.00245296]
< returned_observation >
[ 0.43273798  0.53127433]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 132 #########################################
< action >
[ 0.00905815 -0.00296742]
< returned_observation >
[ 0.44179613  0.52830692]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 133 #########################################
< action >
[ 0.00945801 -0.00332539]
< returned_observation >
[ 0.45125414  0.52498153]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 134 #########################################
< action >
[ 0.00741789 -0.00353836]
< returned_observation >
[ 0.45867204  0.52144317]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 135 #########################################
< action >
[ 0.00545385 -0.00525117]
< returned_observation >
[ 0.46412589  0.51619199]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 136 #########################################
< action >
[ 0.00597493 -0.004429  ]
< returned_observation >
[ 0.47010082  0.51176299]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 137 #########################################
< action >
[ 0.00596287 -0.00789525]
< returned_observation >
[ 0.47606369  0.50386774]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 138 #########################################
< action >
[ 0.00620973 -0.00718736]
< returned_observation >
[ 0.48227341  0.49668039]
< reward >
-1.8000000000000007
< running_reward >
-0.5400000000000001
< done >
False
######################################### STEP 139 #########################################
< action >
[ 0.00762321 -0.00719036]
< returned_observation >
[ 0.48989662  0.48949002]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 140 #########################################
< action >
[ 0.00784206 -0.00927761]
< returned_observation >
[ 0.49773869  0.48021242]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 141 #########################################
< action >
[ 0.00680717 -0.00922472]
< returned_observation >
[ 0.50454585  0.4709877 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 142 #########################################
< action >
[ 0.00763633 -0.00837487]
< returned_observation >
[ 0.51218218  0.46261283]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 143 #########################################
< action >
[ 0.00756564 -0.00548764]
< returned_observation >
[ 0.51974783  0.45712519]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 144 #########################################
< action >
[ 0.00734523 -0.00637067]
< returned_observation >
[ 0.52709306  0.45075452]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 145 #########################################
< action >
[ 0.00816997 -0.00467476]
< returned_observation >
[ 0.53526302  0.44607976]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 146 #########################################
< action >
[ 0.00733764 -0.00454491]
< returned_observation >
[ 0.54260066  0.44153484]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 147 #########################################
< action >
[ 0.00694339 -0.00568342]
< returned_observation >
[ 0.54954405  0.43585143]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 148 #########################################
< action >
[ 0.00519375 -0.00605005]
< returned_observation >
[ 0.5547378   0.42980137]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 149 #########################################
< action >
[ 0.00578339 -0.00641753]
< returned_observation >
[ 0.56052118  0.42338384]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 150 #########################################
< action >
[ 0.00475929 -0.00617933]
< returned_observation >
[ 0.56528047  0.41720451]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 151 #########################################
< action >
[ 0.00449547 -0.00763575]
< returned_observation >
[ 0.56977594  0.40956876]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 152 #########################################
< action >
[ 0.00209364 -0.00606411]
< returned_observation >
[ 0.57186958  0.40350465]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 153 #########################################
< action >
[ 0.00191067 -0.00846683]
< returned_observation >
[ 0.57378025  0.39503782]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 154 #########################################
< action >
[ 0.00101277 -0.00873553]
< returned_observation >
[ 0.57479302  0.38630229]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 155 #########################################
< action >
[-0.00054661 -0.00699403]
< returned_observation >
[ 0.57424641  0.37930827]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 156 #########################################
< action >
[-0.0013696  -0.00811601]
< returned_observation >
[ 0.57287681  0.37119226]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 157 #########################################
< action >
[-0.00113536 -0.00747998]
< returned_observation >
[ 0.57174146  0.36371228]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 158 #########################################
< action >
[-0.00148416 -0.00806119]
< returned_observation >
[ 0.5702573   0.35565108]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 159 #########################################
< action >
[-0.00242261 -0.00875762]
< returned_observation >
[ 0.56783469  0.34689347]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 160 #########################################
< action >
[-0.00570391 -0.01101443]
< returned_observation >
[ 0.56213078  0.33587904]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 161 #########################################
< action >
[-0.00617897 -0.01202904]
< returned_observation >
[ 0.55595181  0.32385   ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 162 #########################################
< action >
[-0.00699241 -0.01105708]
< returned_observation >
[ 0.54895939  0.31279292]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 163 #########################################
< action >
[-0.00600307 -0.01084546]
< returned_observation >
[ 0.54295632  0.30194746]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 164 #########################################
< action >
[-0.00730931 -0.01347333]
< returned_observation >
[ 0.53564701  0.28847414]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 165 #########################################
< action >
[-0.00724013 -0.01320739]
< returned_observation >
[ 0.52840689  0.27526675]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 166 #########################################
< action >
[-0.00728565 -0.01413095]
< returned_observation >
[ 0.52112123  0.2611358 ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 167 #########################################
< action >
[-0.00703357 -0.01451779]
< returned_observation >
[ 0.51408766  0.24661801]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 168 #########################################
< action >
[-0.00881287 -0.01592612]
< returned_observation >
[ 0.50527479  0.2306919 ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 169 #########################################
< action >
[-0.00854214 -0.01630851]
< returned_observation >
[ 0.49673264  0.21438339]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 170 #########################################
< action >
[-0.00864938 -0.01752606]
< returned_observation >
[ 0.48808326  0.19685733]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 171 #########################################
< action >
[-0.00886301 -0.01763587]
< returned_observation >
[ 0.47922025  0.17922146]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 172 #########################################
< action >
[-0.00913819 -0.01864357]
< returned_observation >
[ 0.47008206  0.16057789]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 173 #########################################
< action >
[-0.00808508 -0.01787522]
< returned_observation >
[ 0.46199698  0.14270267]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 174 #########################################
< action >
[-0.00878145 -0.01888315]
< returned_observation >
[ 0.45321553  0.12381952]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 175 #########################################
< action >
[-0.00995479 -0.01892006]
< returned_observation >
[ 0.44326074  0.10489946]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 176 #########################################
< action >
[-0.01086402 -0.01931958]
< returned_observation >
[ 0.43239672  0.08557988]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 177 #########################################
< action >
[-0.01139941 -0.02014812]
< returned_observation >
[ 0.4209973   0.06543176]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 178 #########################################
< action >
[-0.0115546  -0.02077715]
< returned_observation >
[ 0.40944271  0.04465461]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 179 #########################################
< action >
[-0.01290885 -0.02106184]
< returned_observation >
[ 0.39653385  0.02359277]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 180 #########################################
< action >
[-0.01323082 -0.02242233]
< returned_observation >
[ 0.38330303  0.00117044]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 181 #########################################
< action >
[-0.01424009 -0.02249848]
< returned_observation >
[ 0.36906294  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 182 #########################################
< action >
[-0.01502817 -0.02211885]
< returned_observation >
[ 0.35403477  0.        ]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 183 #########################################
< action >
[-0.01306014 -0.0227353 ]
< returned_observation >
[ 0.34097463  0.        ]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 184 #########################################
< action >
[-0.01455943 -0.02265265]
< returned_observation >
[ 0.3264152  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 185 #########################################
< action >
[-0.01526002 -0.0222253 ]
< returned_observation >
[ 0.31115518  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 186 #########################################
< action >
[-0.01339581 -0.02324277]
< returned_observation >
[ 0.29775937  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 187 #########################################
< action >
[-0.01397335 -0.02229844]
< returned_observation >
[ 0.28378602  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 188 #########################################
< action >
[-0.01501389 -0.02413703]
< returned_observation >
[ 0.26877213  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 189 #########################################
< action >
[-0.01483236 -0.02520534]
< returned_observation >
[ 0.25393977  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 190 #########################################
< action >
[-0.01596346 -0.02708683]
< returned_observation >
[ 0.23797631  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 191 #########################################
< action >
[-0.01521736 -0.02585346]
< returned_observation >
[ 0.22275895  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 192 #########################################
< action >
[-0.01781431 -0.0254034 ]
< returned_observation >
[ 0.20494464  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 193 #########################################
< action >
[-0.01977837 -0.02472004]
< returned_observation >
[ 0.18516627  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 194 #########################################
< action >
[-0.02009549 -0.02425688]
< returned_observation >
[ 0.16507077  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 195 #########################################
< action >
[-0.02015427 -0.02602627]
< returned_observation >
[ 0.1449165  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 196 #########################################
< action >
[-0.02009434 -0.02402336]
< returned_observation >
[ 0.12482216  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 197 #########################################
< action >
[-0.02042626 -0.02508462]
< returned_observation >
[ 0.1043959  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 198 #########################################
< action >
[-0.02146603 -0.02430749]
< returned_observation >
[ 0.08292987  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 199 #########################################
< action >
[-0.02253762 -0.02615982]
< returned_observation >
[ 0.06039226  0.        ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
True
##################### episode 1 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -13.5, 'episode_reward': -686.6000000000003, 'ave_reward': -6.866000000000002, 'nb_steps': 200, 'max_reward': 3.8000000000000007}
######################################### STEP 200 #########################################
< action >
[-0.04282065 -0.02673568]
< returned_observation >
[ 0.67664832  0.39637078]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 201 #########################################
< action >
[-0.04214305 -0.02645481]
< returned_observation >
[ 0.63450526  0.36991597]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 202 #########################################
< action >
[-0.04382038 -0.02760283]
< returned_observation >
[ 0.59068488  0.34231314]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 203 #########################################
< action >
[-0.04310611 -0.02684195]
< returned_observation >
[ 0.54757877  0.31547119]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 204 #########################################
< action >
[-0.04379628 -0.02610245]
< returned_observation >
[ 0.50378249  0.28936874]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 205 #########################################
< action >
[-0.04435285 -0.02595223]
< returned_observation >
[ 0.45942964  0.26341651]
< reward >
-14.100000000000001
< running_reward >
-4.23
< done >
False
######################################### STEP 206 #########################################
< action >
[-0.04580544 -0.02583763]
< returned_observation >
[ 0.41362419  0.23757888]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 207 #########################################
< action >
[-0.04499954 -0.02547968]
< returned_observation >
[ 0.36862465  0.21209921]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 208 #########################################
< action >
[-0.04458617 -0.02645849]
< returned_observation >
[ 0.32403848  0.18564071]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 209 #########################################
< action >
[-0.04355538 -0.02668154]
< returned_observation >
[ 0.2804831   0.15895918]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 210 #########################################
< action >
[-0.04406067 -0.02554005]
< returned_observation >
[ 0.23642243  0.13341912]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 211 #########################################
< action >
[-0.04525961 -0.02639575]
< returned_observation >
[ 0.19116283  0.10702337]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 212 #########################################
< action >
[-0.04464845 -0.02686545]
< returned_observation >
[ 0.14651437  0.08015792]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 213 #########################################
< action >
[-0.04433834 -0.0261999 ]
< returned_observation >
[ 0.10217604  0.05395802]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 214 #########################################
< action >
[-0.04491558 -0.02552825]
< returned_observation >
[ 0.05726046  0.02842977]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 215 #########################################
< action >
[-0.04625759 -0.02472426]
< returned_observation >
[ 0.01100286  0.00370551]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 216 #########################################
< action >
[-0.0460384  -0.02336213]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 2 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -14.100000000000001, 'episode_reward': -143.4, 'ave_reward': -8.435294117647059, 'nb_steps': 217, 'max_reward': 2.8000000000000007}
######################################### STEP 217 #########################################
< action >
[-0.05       -0.04519905]
< returned_observation >
[ 0.9307642   0.63963069]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 218 #########################################
< action >
[-0.05       -0.04470475]
< returned_observation >
[ 0.8807642   0.59492594]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 219 #########################################
< action >
[-0.05       -0.04587069]
< returned_observation >
[ 0.8307642   0.54905525]
< reward >
-1.1999999999999993
< running_reward >
-0.35999999999999976
< done >
False
######################################### STEP 220 #########################################
< action >
[-0.05       -0.04602325]
< returned_observation >
[ 0.7807642  0.503032 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 221 #########################################
< action >
[-0.05       -0.04673849]
< returned_observation >
[ 0.7307642   0.45629351]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 222 #########################################
< action >
[-0.05       -0.04849111]
< returned_observation >
[ 0.6807642  0.4078024]
< reward >
-45.0
< running_reward >
-13.5
< done >
True
##################### episode 3 infomation #####################
{'nb_episode_steps': 6, 'min_reward': -45.0, 'episode_reward': -69.0, 'ave_reward': -11.5, 'nb_steps': 223, 'max_reward': 0.8000000000000007}
######################################### STEP 223 #########################################
< action >
[-0.04847185 -0.04181727]
< returned_observation >
[ 0.43246005  0.35030025]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 224 #########################################
< action >
[-0.04906538 -0.04054307]
< returned_observation >
[ 0.38339467  0.30975718]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 225 #########################################
< action >
[-0.0485976  -0.04133507]
< returned_observation >
[ 0.33479707  0.26842211]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 226 #########################################
< action >
[-0.04780985 -0.04170878]
< returned_observation >
[ 0.28698722  0.22671333]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 227 #########################################
< action >
[-0.04643202 -0.04161577]
< returned_observation >
[ 0.2405552   0.18509756]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 228 #########################################
< action >
[-0.04535566 -0.04009444]
< returned_observation >
[ 0.19519954  0.14500312]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 229 #########################################
< action >
[-0.04445836 -0.03823167]
< returned_observation >
[ 0.15074118  0.10677144]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 230 #########################################
< action >
[-0.04287324 -0.03691827]
< returned_observation >
[ 0.10786795  0.06985317]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 231 #########################################
< action >
[-0.04279759 -0.03436663]
< returned_observation >
[ 0.06507036  0.03548654]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 232 #########################################
< action >
[-0.04097802 -0.03424206]
< returned_observation >
[ 0.02409234  0.00124448]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 233 #########################################
< action >
[-0.04183929 -0.03102035]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 4 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -11.8, 'episode_reward': -123.20000000000002, 'ave_reward': -11.200000000000001, 'nb_steps': 234, 'max_reward': -10.899999999999999}
######################################### STEP 234 #########################################
< action >
[-0.04895974 -0.04607824]
< returned_observation >
[ 0.29421828  0.68297147]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 235 #########################################
< action >
[-0.04686828 -0.04460793]
< returned_observation >
[ 0.24735     0.63836354]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 236 #########################################
< action >
[-0.04646837 -0.04476073]
< returned_observation >
[ 0.20088164  0.59360281]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 237 #########################################
< action >
[-0.04742436 -0.04474674]
< returned_observation >
[ 0.15345728  0.54885607]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 238 #########################################
< action >
[-0.04783899 -0.04483494]
< returned_observation >
[ 0.10561829  0.50402113]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 239 #########################################
< action >
[-0.04759068 -0.04353045]
< returned_observation >
[ 0.05802761  0.46049068]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 240 #########################################
< action >
[-0.0495819  -0.04226128]
< returned_observation >
[ 0.00844571  0.41822939]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 241 #########################################
< action >
[-0.04939727 -0.04191683]
< returned_observation >
[ 0.          0.37631256]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 242 #########################################
< action >
[-0.04924849 -0.0430483 ]
< returned_observation >
[ 0.          0.33326427]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 243 #########################################
< action >
[-0.04732263 -0.04246542]
< returned_observation >
[ 0.          0.29079885]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 244 #########################################
< action >
[-0.04782457 -0.04403948]
< returned_observation >
[ 0.          0.24675936]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 245 #########################################
< action >
[-0.04972744 -0.04312686]
< returned_observation >
[ 0.         0.2036325]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 246 #########################################
< action >
[-0.05       -0.04343393]
< returned_observation >
[ 0.          0.16019857]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 247 #########################################
< action >
[-0.05       -0.04452486]
< returned_observation >
[ 0.          0.11567371]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 248 #########################################
< action >
[-0.0495045  -0.04476142]
< returned_observation >
[ 0.         0.0709123]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 249 #########################################
< action >
[-0.05       -0.04482064]
< returned_observation >
[ 0.          0.02609166]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 250 #########################################
< action >
[-0.05       -0.04476479]
< returned_observation >
[ 0.  0.]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
True
##################### episode 5 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.600000000000001, 'episode_reward': -80.5, 'ave_reward': -4.735294117647059, 'nb_steps': 251, 'max_reward': 3.6999999999999993}
######################################### STEP 251 #########################################
< action >
[-0.04978338 -0.04723494]
< returned_observation >
[ 0.38878886  0.01244296]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 252 #########################################
< action >
[-0.04870919 -0.0479144 ]
< returned_observation >
[ 0.34007967  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 253 #########################################
< action >
[-0.04869538 -0.04546536]
< returned_observation >
[ 0.29138429  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 254 #########################################
< action >
[-0.04965223 -0.04428189]
< returned_observation >
[ 0.24173206  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 255 #########################################
< action >
[-0.05     -0.041952]
< returned_observation >
[ 0.19173206  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 256 #########################################
< action >
[-0.05      -0.0405562]
< returned_observation >
[ 0.14173206  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 257 #########################################
< action >
[-0.05       -0.04067278]
< returned_observation >
[ 0.09173206  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 258 #########################################
< action >
[-0.04991939 -0.03972002]
< returned_observation >
[ 0.04181267  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 259 #########################################
< action >
[-0.05       -0.03847325]
< returned_observation >
[ 0.  0.]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
True
##################### episode 6 infomation #####################
{'nb_episode_steps': 9, 'min_reward': -12.2, 'episode_reward': -58.7, 'ave_reward': -6.522222222222222, 'nb_steps': 260, 'max_reward': 3.6000000000000014}
######################################### STEP 260 #########################################
< action >
[-0.05       -0.04889166]
< returned_observation >
[ 0.34804426  0.68910375]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 261 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.29804426  0.63910375]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 262 #########################################
< action >
[-0.05       -0.04958708]
< returned_observation >
[ 0.24804426  0.58951667]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 263 #########################################
< action >
[-0.05       -0.04992603]
< returned_observation >
[ 0.19804426  0.53959064]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 264 #########################################
< action >
[-0.05       -0.04854491]
< returned_observation >
[ 0.14804426  0.49104573]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 265 #########################################
< action >
[-0.05       -0.04847858]
< returned_observation >
[ 0.09804426  0.44256714]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 266 #########################################
< action >
[-0.05       -0.04902804]
< returned_observation >
[ 0.04804426  0.3935391 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 267 #########################################
< action >
[-0.05      -0.0473584]
< returned_observation >
[ 0.         0.3461807]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 268 #########################################
< action >
[-0.05       -0.04738591]
< returned_observation >
[ 0.          0.29879479]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 269 #########################################
< action >
[-0.04859252 -0.04653744]
< returned_observation >
[ 0.          0.25225735]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 270 #########################################
< action >
[-0.04759432 -0.04623407]
< returned_observation >
[ 0.          0.20602328]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 271 #########################################
< action >
[-0.0483408  -0.04722032]
< returned_observation >
[ 0.          0.15880296]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 272 #########################################
< action >
[-0.04717901 -0.04641476]
< returned_observation >
[ 0.         0.1123882]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 273 #########################################
< action >
[-0.04742832 -0.0471791 ]
< returned_observation >
[ 0.         0.0652091]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 274 #########################################
< action >
[-0.0462377  -0.04550013]
< returned_observation >
[ 0.          0.01970897]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 275 #########################################
< action >
[-0.04723441 -0.04464609]
< returned_observation >
[ 0.  0.]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
True
##################### episode 7 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -13.100000000000001, 'episode_reward': -141.0, 'ave_reward': -8.8125, 'nb_steps': 276, 'max_reward': 3.3999999999999986}
######################################### STEP 276 #########################################
< action >
[-0.04729143 -0.04710911]
< returned_observation >
[ 0.1352003   0.12834265]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 277 #########################################
< action >
[-0.04688987 -0.04833389]
< returned_observation >
[ 0.08831043  0.08000876]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 278 #########################################
< action >
[-0.04622917 -0.04715639]
< returned_observation >
[ 0.04208126  0.03285236]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 279 #########################################
< action >
[-0.04636589 -0.04764328]
< returned_observation >
[ 0.  0.]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
True
##################### episode 8 infomation #####################
{'nb_episode_steps': 4, 'min_reward': -11.399999999999999, 'episode_reward': -30.0, 'ave_reward': -7.5, 'nb_steps': 280, 'max_reward': 3.6000000000000014}
######################################### STEP 280 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.48155137  0.48182759]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 281 #########################################
< action >
[-0.04973719 -0.05      ]
< returned_observation >
[ 0.43181419  0.43182759]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 282 #########################################
< action >
[-0.04953492 -0.05      ]
< returned_observation >
[ 0.38227926  0.38182759]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 283 #########################################
< action >
[-0.04876363 -0.05      ]
< returned_observation >
[ 0.33351564  0.33182759]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 284 #########################################
< action >
[-0.0485155 -0.05     ]
< returned_observation >
[ 0.28500014  0.28182759]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 285 #########################################
< action >
[-0.04738194 -0.05      ]
< returned_observation >
[ 0.23761819  0.23182759]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 286 #########################################
< action >
[-0.04737171 -0.05      ]
< returned_observation >
[ 0.19024648  0.18182759]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 287 #########################################
< action >
[-0.04602335 -0.05      ]
< returned_observation >
[ 0.14422313  0.13182759]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 288 #########################################
< action >
[-0.04487854 -0.05      ]
< returned_observation >
[ 0.09934459  0.08182759]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 289 #########################################
< action >
[-0.04532892 -0.05      ]
< returned_observation >
[ 0.05401566  0.03182759]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 290 #########################################
< action >
[-0.04633657 -0.05      ]
< returned_observation >
[ 0.00767909  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 291 #########################################
< action >
[-0.04700063 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
True
##################### episode 9 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.2, 'episode_reward': -66.50000000000001, 'ave_reward': -5.541666666666668, 'nb_steps': 292, 'max_reward': 3.6999999999999993}
######################################### STEP 292 #########################################
< action >
[-0.0488963  -0.04956321]
< returned_observation >
[ 0.58550465  0.79986859]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 293 #########################################
< action >
[-0.04865755 -0.04851727]
< returned_observation >
[ 0.5368471   0.75135131]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 294 #########################################
< action >
[-0.04752092 -0.0471277 ]
< returned_observation >
[ 0.48932619  0.70422362]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 295 #########################################
< action >
[-0.04714208 -0.04943991]
< returned_observation >
[ 0.44218411  0.6547837 ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 296 #########################################
< action >
[-0.047615   -0.04937612]
< returned_observation >
[ 0.39456911  0.60540759]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 297 #########################################
< action >
[-0.04747097 -0.04934766]
< returned_observation >
[ 0.34709814  0.55605992]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 298 #########################################
< action >
[-0.04644741 -0.04979554]
< returned_observation >
[ 0.30065073  0.50626439]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 299 #########################################
< action >
[-0.04827005 -0.04902997]
< returned_observation >
[ 0.25238068  0.45723442]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 300 #########################################
< action >
[-0.04765556 -0.05      ]
< returned_observation >
[ 0.20472512  0.40723442]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 301 #########################################
< action >
[-0.04682257 -0.04969022]
< returned_observation >
[ 0.15790255  0.35754419]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 302 #########################################
< action >
[-0.0458894  -0.04786679]
< returned_observation >
[ 0.11201315  0.30967741]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 303 #########################################
< action >
[-0.04658346 -0.04972912]
< returned_observation >
[ 0.06542969  0.25994829]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 304 #########################################
< action >
[-0.04639972 -0.04896823]
< returned_observation >
[ 0.01902997  0.21098006]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 305 #########################################
< action >
[-0.04511958 -0.0485785 ]
< returned_observation >
[ 0.          0.16240156]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 306 #########################################
< action >
[-0.0447618  -0.04644991]
< returned_observation >
[ 0.          0.11595165]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 307 #########################################
< action >
[-0.0435099 -0.0464511]
< returned_observation >
[ 0.          0.06950055]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 308 #########################################
< action >
[-0.04417646 -0.04707654]
< returned_observation >
[ 0.          0.02242401]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 309 #########################################
< action >
[-0.04291676 -0.0474892 ]
< returned_observation >
[ 0.  0.]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
True
##################### episode 10 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -12.8, 'episode_reward': -91.30000000000001, 'ave_reward': -5.072222222222223, 'nb_steps': 310, 'max_reward': 3.6000000000000014}
######################################### STEP 310 #########################################
< action >
[-0.04861326 -0.05      ]
< returned_observation >
[ 0.67584207  0.56102351]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 311 #########################################
< action >
[-0.04674219 -0.05      ]
< returned_observation >
[ 0.62909988  0.51102351]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 312 #########################################
< action >
[-0.04761845 -0.05      ]
< returned_observation >
[ 0.58148143  0.46102351]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 313 #########################################
< action >
[-0.0479695 -0.05     ]
< returned_observation >
[ 0.53351193  0.41102351]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 314 #########################################
< action >
[-0.04634025 -0.05      ]
< returned_observation >
[ 0.48717168  0.36102351]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 315 #########################################
< action >
[-0.04711598 -0.05      ]
< returned_observation >
[ 0.4400557   0.31102351]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 316 #########################################
< action >
[-0.0463178 -0.05     ]
< returned_observation >
[ 0.3937379   0.26102351]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 317 #########################################
< action >
[-0.04650934 -0.05      ]
< returned_observation >
[ 0.34722856  0.21102351]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 318 #########################################
< action >
[-0.04588298 -0.05      ]
< returned_observation >
[ 0.30134558  0.16102351]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 319 #########################################
< action >
[-0.04385386 -0.05      ]
< returned_observation >
[ 0.25749171  0.11102351]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 320 #########################################
< action >
[-0.04495059 -0.05      ]
< returned_observation >
[ 0.21254112  0.06102351]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 321 #########################################
< action >
[-0.04397936 -0.05      ]
< returned_observation >
[ 0.16856176  0.01102351]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 322 #########################################
< action >
[-0.04488263 -0.04980845]
< returned_observation >
[ 0.12367913  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 323 #########################################
< action >
[-0.04489816 -0.04892824]
< returned_observation >
[ 0.07878097  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 324 #########################################
< action >
[-0.04567659 -0.04796194]
< returned_observation >
[ 0.03310438  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 325 #########################################
< action >
[-0.04588893 -0.04678264]
< returned_observation >
[ 0.  0.]
< reward >
-12.8
< running_reward >
-3.84
< done >
True
##################### episode 11 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.8, 'episode_reward': -145.20000000000002, 'ave_reward': -9.075000000000001, 'nb_steps': 326, 'max_reward': 2.3999999999999986}
######################################### STEP 326 #########################################
< action >
[-0.04982348 -0.04880817]
< returned_observation >
[ 0.6726199   0.27415074]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 327 #########################################
< action >
[-0.04856367 -0.04833425]
< returned_observation >
[ 0.62405624  0.2258165 ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 328 #########################################
< action >
[-0.04866498 -0.05      ]
< returned_observation >
[ 0.57539126  0.1758165 ]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 329 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.52539126  0.1258165 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 330 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.47539126  0.0758165 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 331 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.42539126  0.0258165 ]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 332 #########################################
< action >
[-0.04973666 -0.04971501]
< returned_observation >
[ 0.37565459  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 333 #########################################
< action >
[-0.04890184 -0.0494244 ]
< returned_observation >
[ 0.32675276  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 334 #########################################
< action >
[-0.04981705 -0.04986384]
< returned_observation >
[ 0.2769357  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 335 #########################################
< action >
[-0.04865906 -0.05      ]
< returned_observation >
[ 0.22827665  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 336 #########################################
< action >
[-0.05       -0.04997063]
< returned_observation >
[ 0.17827665  0.        ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 337 #########################################
< action >
[-0.05       -0.04883792]
< returned_observation >
[ 0.12827665  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 338 #########################################
< action >
[-0.04871095 -0.04727774]
< returned_observation >
[ 0.0795657  0.       ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 339 #########################################
< action >
[-0.04788475 -0.04694401]
< returned_observation >
[ 0.03168095  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 340 #########################################
< action >
[-0.04877831 -0.04615881]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 12 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -13.0, 'episode_reward': -142.8, 'ave_reward': -9.520000000000001, 'nb_steps': 341, 'max_reward': 3.3000000000000007}
######################################### STEP 341 #########################################
< action >
[-0.05       -0.04818743]
< returned_observation >
[ 0.31178866  0.1800758 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 342 #########################################
< action >
[-0.05       -0.04932701]
< returned_observation >
[ 0.26178866  0.13074879]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 343 #########################################
< action >
[-0.05       -0.04931682]
< returned_observation >
[ 0.21178866  0.08143197]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 344 #########################################
< action >
[-0.05      -0.0480524]
< returned_observation >
[ 0.16178866  0.03337957]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 345 #########################################
< action >
[-0.05      -0.0487847]
< returned_observation >
[ 0.11178866  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 346 #########################################
< action >
[-0.05       -0.04971215]
< returned_observation >
[ 0.06178866  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 347 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.01178866  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 348 #########################################
< action >
[-0.05       -0.04901297]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 13 infomation #####################
{'nb_episode_steps': 8, 'min_reward': -12.2, 'episode_reward': -75.7, 'ave_reward': -9.4625, 'nb_steps': 349, 'max_reward': 3.6000000000000014}
######################################### STEP 349 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.24371405  0.58097612]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 350 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.19371405  0.53097612]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 351 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.14371405  0.48097612]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 352 #########################################
< action >
[-0.04979808 -0.05      ]
< returned_observation >
[ 0.09391597  0.43097612]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 353 #########################################
< action >
[-0.04952579 -0.05      ]
< returned_observation >
[ 0.04439018  0.38097612]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 354 #########################################
< action >
[-0.04905922 -0.05      ]
< returned_observation >
[ 0.          0.33097612]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 355 #########################################
< action >
[-0.04832913 -0.05      ]
< returned_observation >
[ 0.          0.28097612]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 356 #########################################
< action >
[-0.04651722 -0.05      ]
< returned_observation >
[ 0.          0.23097612]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 357 #########################################
< action >
[-0.04579072 -0.05      ]
< returned_observation >
[ 0.          0.18097612]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 358 #########################################
< action >
[-0.04583944 -0.05      ]
< returned_observation >
[ 0.          0.13097612]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 359 #########################################
< action >
[-0.04687629 -0.05      ]
< returned_observation >
[ 0.          0.08097612]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 360 #########################################
< action >
[-0.04660165 -0.05      ]
< returned_observation >
[ 0.          0.03097612]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 361 #########################################
< action >
[-0.04608443 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 14 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.2, 'episode_reward': -50.800000000000004, 'ave_reward': -3.907692307692308, 'nb_steps': 362, 'max_reward': 3.5}
######################################### STEP 362 #########################################
< action >
[-0.05       -0.04874422]
< returned_observation >
[ 0.04210494  0.38495696]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 363 #########################################
< action >
[-0.05      -0.0477052]
< returned_observation >
[ 0.          0.33725176]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 364 #########################################
< action >
[-0.05       -0.04847706]
< returned_observation >
[ 0.          0.28877469]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 365 #########################################
< action >
[-0.05       -0.04730209]
< returned_observation >
[ 0.         0.2414726]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 366 #########################################
< action >
[-0.04956131 -0.0472396 ]
< returned_observation >
[ 0.        0.194233]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 367 #########################################
< action >
[-0.04952168 -0.04838425]
< returned_observation >
[ 0.          0.14584875]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 368 #########################################
< action >
[-0.04901715 -0.04810697]
< returned_observation >
[ 0.          0.09774178]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 369 #########################################
< action >
[-0.04889438 -0.04652191]
< returned_observation >
[ 0.          0.05121987]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 370 #########################################
< action >
[-0.04707205 -0.0452206 ]
< returned_observation >
[ 0.          0.00599927]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 371 #########################################
< action >
[-0.04899055 -0.04623641]
< returned_observation >
[ 0.  0.]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
True
##################### episode 15 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -12.2, 'episode_reward': -41.60000000000001, 'ave_reward': -4.160000000000001, 'nb_steps': 372, 'max_reward': 3.6000000000000014}
######################################### STEP 372 #########################################
< action >
[-0.04957076 -0.05      ]
< returned_observation >
[ 0.381292   0.4436851]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 373 #########################################
< action >
[-0.04863193 -0.05      ]
< returned_observation >
[ 0.33266007  0.3936851 ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 374 #########################################
< action >
[-0.04839732 -0.05      ]
< returned_observation >
[ 0.28426275  0.3436851 ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 375 #########################################
< action >
[-0.04894409 -0.05      ]
< returned_observation >
[ 0.23531867  0.2936851 ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 376 #########################################
< action >
[-0.04675473 -0.04913136]
< returned_observation >
[ 0.18856394  0.24455374]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 377 #########################################
< action >
[-0.04595297 -0.04711281]
< returned_observation >
[ 0.14261097  0.19744093]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 378 #########################################
< action >
[-0.04620717 -0.04836824]
< returned_observation >
[ 0.09640381  0.1490727 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 379 #########################################
< action >
[-0.0452422  -0.04759566]
< returned_observation >
[ 0.05116161  0.10147704]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 380 #########################################
< action >
[-0.04540843 -0.04635514]
< returned_observation >
[ 0.00575319  0.0551219 ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 381 #########################################
< action >
[-0.04777237 -0.04666475]
< returned_observation >
[ 0.          0.00845715]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 382 #########################################
< action >
[-0.04788892 -0.04684962]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 16 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -12.600000000000001, 'episode_reward': -95.5, 'ave_reward': -8.681818181818182, 'nb_steps': 383, 'max_reward': 3.5}
######################################### STEP 383 #########################################
< action >
[-0.04907186 -0.04958089]
< returned_observation >
[ 0.37675843  0.26268033]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 384 #########################################
< action >
[-0.04877251 -0.04821519]
< returned_observation >
[ 0.32798591  0.21446514]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 385 #########################################
< action >
[-0.04884514 -0.04639321]
< returned_observation >
[ 0.27914077  0.16807193]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 386 #########################################
< action >
[-0.04660181 -0.04649821]
< returned_observation >
[ 0.23253896  0.12157372]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 387 #########################################
< action >
[-0.04613512 -0.0460197 ]
< returned_observation >
[ 0.18640384  0.07555402]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 388 #########################################
< action >
[-0.04647662 -0.04473338]
< returned_observation >
[ 0.13992721  0.03082065]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 389 #########################################
< action >
[-0.04666566 -0.04310355]
< returned_observation >
[ 0.09326155  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 390 #########################################
< action >
[-0.04636676 -0.04298416]
< returned_observation >
[ 0.04689479  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 391 #########################################
< action >
[-0.04646795 -0.04366181]
< returned_observation >
[ 0.00042685  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 392 #########################################
< action >
[-0.04636023 -0.04341413]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 17 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -12.0, 'episode_reward': -57.50000000000001, 'ave_reward': -5.750000000000001, 'nb_steps': 393, 'max_reward': 3.5}
######################################### STEP 393 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.37635131  0.84338916]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 394 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.32635131  0.79338916]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 395 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.27635131  0.74338916]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 396 #########################################
< action >
[-0.04805969 -0.05      ]
< returned_observation >
[ 0.22829162  0.69338916]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 397 #########################################
< action >
[-0.04766584 -0.05      ]
< returned_observation >
[ 0.18062577  0.64338916]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 398 #########################################
< action >
[-0.04849417 -0.05      ]
< returned_observation >
[ 0.1321316   0.59338916]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 399 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0821316   0.54338916]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 400 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0321316   0.49338916]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 401 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.44338916]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 402 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.39338916]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 403 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.34338916]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 404 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.29338916]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 405 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.24338916]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 406 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.19338916]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 407 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.14338916]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 408 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.09338916]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 409 #########################################
< action >
[-0.04891311 -0.05      ]
< returned_observation >
[ 0.          0.04338916]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 410 #########################################
< action >
[-0.04864431 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.7
< running_reward >
-3.51
< done >
True
##################### episode 18 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -11.8, 'episode_reward': -91.60000000000001, 'ave_reward': -5.0888888888888895, 'nb_steps': 411, 'max_reward': 3.6999999999999993}
######################################### STEP 411 #########################################
< action >
[-0.05       -0.04952343]
< returned_observation >
[ 0.89416002  0.45231325]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 412 #########################################
< action >
[-0.05       -0.04804352]
< returned_observation >
[ 0.84416002  0.40426973]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 413 #########################################
< action >
[-0.05       -0.04735737]
< returned_observation >
[ 0.79416002  0.35691236]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 414 #########################################
< action >
[-0.0494712  -0.04752922]
< returned_observation >
[ 0.74468882  0.30938314]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 415 #########################################
< action >
[-0.0477749  -0.04876345]
< returned_observation >
[ 0.69691392  0.26061969]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 416 #########################################
< action >
[-0.04664039 -0.04845107]
< returned_observation >
[ 0.65027353  0.21216862]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 417 #########################################
< action >
[-0.04694919 -0.04982117]
< returned_observation >
[ 0.60332434  0.16234745]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 418 #########################################
< action >
[-0.04660555 -0.04921473]
< returned_observation >
[ 0.55671879  0.11313272]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 419 #########################################
< action >
[-0.04502719 -0.04839315]
< returned_observation >
[ 0.5116916   0.06473956]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 420 #########################################
< action >
[-0.04562795 -0.05      ]
< returned_observation >
[ 0.46606365  0.01473956]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 421 #########################################
< action >
[-0.04507092 -0.05      ]
< returned_observation >
[ 0.42099273  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 422 #########################################
< action >
[-0.04455026 -0.04978773]
< returned_observation >
[ 0.37644247  0.        ]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 423 #########################################
< action >
[-0.04452958 -0.05      ]
< returned_observation >
[ 0.33191289  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 424 #########################################
< action >
[-0.04499579 -0.05      ]
< returned_observation >
[ 0.2869171  0.       ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 425 #########################################
< action >
[-0.0455573 -0.05     ]
< returned_observation >
[ 0.2413598  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 426 #########################################
< action >
[-0.04442142 -0.05      ]
< returned_observation >
[ 0.19693838  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 427 #########################################
< action >
[-0.04402661 -0.05      ]
< returned_observation >
[ 0.15291177  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 428 #########################################
< action >
[-0.04308945 -0.05      ]
< returned_observation >
[ 0.10982232  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 429 #########################################
< action >
[-0.04208007 -0.05      ]
< returned_observation >
[ 0.06774225  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 430 #########################################
< action >
[-0.04444639 -0.05      ]
< returned_observation >
[ 0.02329586  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 431 #########################################
< action >
[-0.04363699 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
True
##################### episode 19 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -13.7, 'episode_reward': -205.6, 'ave_reward': -9.79047619047619, 'nb_steps': 432, 'max_reward': 3.5}
######################################### STEP 432 #########################################
< action >
[-0.04982619 -0.04947305]
< returned_observation >
[ 0.57412676  0.06614535]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 433 #########################################
< action >
[-0.05       -0.04820737]
< returned_observation >
[ 0.52412676  0.01793798]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 434 #########################################
< action >
[-0.04890969 -0.04821564]
< returned_observation >
[ 0.47521708  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 435 #########################################
< action >
[-0.04843672 -0.04882848]
< returned_observation >
[ 0.42678035  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 436 #########################################
< action >
[-0.04732635 -0.05      ]
< returned_observation >
[ 0.379454  0.      ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 437 #########################################
< action >
[-0.0483173 -0.05     ]
< returned_observation >
[ 0.33113671  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 438 #########################################
< action >
[-0.04859528 -0.0494145 ]
< returned_observation >
[ 0.28254143  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 439 #########################################
< action >
[-0.04994599 -0.04920699]
< returned_observation >
[ 0.23259544  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 440 #########################################
< action >
[-0.04912655 -0.04980336]
< returned_observation >
[ 0.18346889  0.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 441 #########################################
< action >
[-0.04830034 -0.05      ]
< returned_observation >
[ 0.13516854  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 442 #########################################
< action >
[-0.04807622 -0.05      ]
< returned_observation >
[ 0.08709232  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 443 #########################################
< action >
[-0.04869972 -0.05      ]
< returned_observation >
[ 0.0383926  0.       ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 444 #########################################
< action >
[-0.04666408 -0.04914887]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 20 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.2, 'episode_reward': -136.70000000000002, 'ave_reward': -10.515384615384617, 'nb_steps': 445, 'max_reward': 2.1000000000000014}
######################################### STEP 445 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.26728548  0.36482621]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 446 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.21728548  0.31482621]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 447 #########################################
< action >
[-0.05      -0.0495141]
< returned_observation >
[ 0.16728548  0.26531211]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 448 #########################################
< action >
[-0.05       -0.04989741]
< returned_observation >
[ 0.11728548  0.21541469]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 449 #########################################
< action >
[-0.05       -0.04998895]
< returned_observation >
[ 0.06728548  0.16542574]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 450 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.01728548  0.11542574]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 451 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.06542574]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 452 #########################################
< action >
[-0.05       -0.04989201]
< returned_observation >
[ 0.          0.01553374]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 453 #########################################
< action >
[-0.05       -0.04976051]
< returned_observation >
[ 0.  0.]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
True
##################### episode 21 infomation #####################
{'nb_episode_steps': 9, 'min_reward': -12.0, 'episode_reward': -74.6, 'ave_reward': -8.288888888888888, 'nb_steps': 454, 'max_reward': 3.1999999999999993}
######################################### STEP 454 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.81630916  0.20045537]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 455 #########################################
< action >
[-0.04936839 -0.05      ]
< returned_observation >
[ 0.76694077  0.15045537]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 456 #########################################
< action >
[-0.04902113 -0.05      ]
< returned_observation >
[ 0.71791964  0.10045537]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 457 #########################################
< action >
[-0.04990746 -0.05      ]
< returned_observation >
[ 0.66801218  0.05045537]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 458 #########################################
< action >
[-0.04907351 -0.05      ]
< returned_observation >
[  6.18938676e-01   4.55365397e-04]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 459 #########################################
< action >
[-0.048756 -0.05    ]
< returned_observation >
[ 0.57018268  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 460 #########################################
< action >
[-0.04825663 -0.05      ]
< returned_observation >
[ 0.52192605  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 461 #########################################
< action >
[-0.04751292 -0.05      ]
< returned_observation >
[ 0.47441313  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 462 #########################################
< action >
[-0.04692673 -0.05      ]
< returned_observation >
[ 0.4274864  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 463 #########################################
< action >
[-0.04626358 -0.05      ]
< returned_observation >
[ 0.38122282  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 464 #########################################
< action >
[-0.04426099 -0.05      ]
< returned_observation >
[ 0.33696184  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 465 #########################################
< action >
[-0.04408421 -0.05      ]
< returned_observation >
[ 0.29287763  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 466 #########################################
< action >
[-0.04490329 -0.05      ]
< returned_observation >
[ 0.24797434  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 467 #########################################
< action >
[-0.04473499 -0.05      ]
< returned_observation >
[ 0.20323936  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 468 #########################################
< action >
[-0.04495113 -0.05      ]
< returned_observation >
[ 0.15828823  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 469 #########################################
< action >
[-0.04378467 -0.05      ]
< returned_observation >
[ 0.11450356  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 470 #########################################
< action >
[-0.0427917 -0.05     ]
< returned_observation >
[ 0.07171185  0.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 471 #########################################
< action >
[-0.04229805 -0.05      ]
< returned_observation >
[ 0.02941381  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 472 #########################################
< action >
[-0.04094533 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
True
##################### episode 22 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -12.5, 'episode_reward': -160.30000000000004, 'ave_reward': -8.43684210526316, 'nb_steps': 473, 'max_reward': 3.1999999999999993}
######################################### STEP 473 #########################################
< action >
[-0.0499726 -0.05     ]
< returned_observation >
[ 0.43306167  0.93555979]
< reward >
-0.3000000000000007
< running_reward >
-0.0900000000000002
< done >
False
######################################### STEP 474 #########################################
< action >
[-0.04782115 -0.05      ]
< returned_observation >
[ 0.38524051  0.88555979]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 475 #########################################
< action >
[-0.04801528 -0.05      ]
< returned_observation >
[ 0.33722523  0.83555979]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 476 #########################################
< action >
[-0.04830826 -0.05      ]
< returned_observation >
[ 0.28891698  0.78555979]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 477 #########################################
< action >
[-0.04896818 -0.05      ]
< returned_observation >
[ 0.23994879  0.73555979]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 478 #########################################
< action >
[-0.04948153 -0.05      ]
< returned_observation >
[ 0.19046727  0.68555979]
< reward >
-10.2
< running_reward >
-3.0599999999999996
< done >
False
######################################### STEP 479 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.14046727  0.63555979]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 480 #########################################
< action >
[-0.04806021 -0.05      ]
< returned_observation >
[ 0.09240706  0.58555979]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 481 #########################################
< action >
[-0.04833042 -0.05      ]
< returned_observation >
[ 0.04407664  0.53555979]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 482 #########################################
< action >
[-0.04867649 -0.05      ]
< returned_observation >
[ 0.          0.48555979]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 483 #########################################
< action >
[-0.04712603 -0.05      ]
< returned_observation >
[ 0.          0.43555979]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 484 #########################################
< action >
[-0.04742025 -0.05      ]
< returned_observation >
[ 0.          0.38555979]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 485 #########################################
< action >
[-0.04651794 -0.05      ]
< returned_observation >
[ 0.          0.33555979]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 486 #########################################
< action >
[-0.04498825 -0.04924775]
< returned_observation >
[ 0.          0.28631203]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 487 #########################################
< action >
[-0.04554045 -0.04763666]
< returned_observation >
[ 0.          0.23867538]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 488 #########################################
< action >
[-0.04508614 -0.04632725]
< returned_observation >
[ 0.          0.19234812]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 489 #########################################
< action >
[-0.04613118 -0.04600381]
< returned_observation >
[ 0.          0.14634432]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 490 #########################################
< action >
[-0.0471985  -0.04473565]
< returned_observation >
[ 0.          0.10160867]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 491 #########################################
< action >
[-0.04776091 -0.04511646]
< returned_observation >
[ 0.          0.05649221]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 492 #########################################
< action >
[-0.04953717 -0.04526695]
< returned_observation >
[ 0.          0.01122526]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 493 #########################################
< action >
[-0.0483931  -0.04541572]
< returned_observation >
[ 0.  0.]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
True
##################### episode 23 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -11.7, 'episode_reward': -83.4, 'ave_reward': -3.9714285714285715, 'nb_steps': 494, 'max_reward': 3.6999999999999993}
######################################### STEP 494 #########################################
< action >
[-0.04816504 -0.05      ]
< returned_observation >
[ 0.47132008  0.56289453]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 495 #########################################
< action >
[-0.04881166 -0.05      ]
< returned_observation >
[ 0.42250842  0.51289453]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 496 #########################################
< action >
[-0.04956927 -0.0499474 ]
< returned_observation >
[ 0.37293914  0.46294712]
< reward >
-9.9
< running_reward >
-2.97
< done >
False
######################################### STEP 497 #########################################
< action >
[-0.04910636 -0.04913575]
< returned_observation >
[ 0.32383278  0.41381137]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 498 #########################################
< action >
[-0.04891024 -0.0489602 ]
< returned_observation >
[ 0.27492255  0.36485117]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 499 #########################################
< action >
[-0.0495637  -0.04922865]
< returned_observation >
[ 0.22535885  0.31562253]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 500 #########################################
< action >
[-0.04824757 -0.0495904 ]
< returned_observation >
[ 0.17711128  0.26603213]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 501 #########################################
< action >
[-0.04740687 -0.04917079]
< returned_observation >
[ 0.12970441  0.21686134]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 502 #########################################
< action >
[-0.0463243  -0.04824641]
< returned_observation >
[ 0.08338012  0.16861493]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 503 #########################################
< action >
[-0.04529441 -0.0471403 ]
< returned_observation >
[ 0.0380857   0.12147462]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 504 #########################################
< action >
[-0.04466205 -0.04681286]
< returned_observation >
[ 0.          0.07466176]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 505 #########################################
< action >
[-0.04353438 -0.04773526]
< returned_observation >
[ 0.          0.02692651]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 506 #########################################
< action >
[-0.04398434 -0.04890914]
< returned_observation >
[ 0.  0.]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
True
##################### episode 24 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.399999999999999, 'episode_reward': -104.1, 'ave_reward': -8.007692307692308, 'nb_steps': 507, 'max_reward': 3.6000000000000014}
######################################### STEP 507 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.07062867  0.7763408 ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 508 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.02062867  0.7263408 ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 509 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.         0.6763408]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 510 #########################################
< action >
[-0.05       -0.04982365]
< returned_observation >
[ 0.          0.62651715]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 511 #########################################
< action >
[-0.05       -0.04844752]
< returned_observation >
[ 0.          0.57806963]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 512 #########################################
< action >
[-0.05       -0.04899813]
< returned_observation >
[ 0.         0.5290715]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 513 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.         0.4790715]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 514 #########################################
< action >
[-0.04949141 -0.05      ]
< returned_observation >
[ 0.         0.4290715]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 515 #########################################
< action >
[-0.05       -0.04873338]
< returned_observation >
[ 0.          0.38033812]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 516 #########################################
< action >
[-0.04912252 -0.04967554]
< returned_observation >
[ 0.          0.33066259]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 517 #########################################
< action >
[-0.05      -0.0488718]
< returned_observation >
[ 0.          0.28179079]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 518 #########################################
< action >
[-0.05       -0.04937062]
< returned_observation >
[ 0.          0.23242017]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 519 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.18242017]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 520 #########################################
< action >
[-0.05       -0.04997902]
< returned_observation >
[ 0.          0.13244114]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 521 #########################################
< action >
[-0.04994823 -0.04940075]
< returned_observation >
[ 0.         0.0830404]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 522 #########################################
< action >
[-0.04972133 -0.04755664]
< returned_observation >
[ 0.          0.03548376]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 523 #########################################
< action >
[-0.05      -0.0488816]
< returned_observation >
[ 0.  0.]
< reward >
-11.7
< running_reward >
-3.51
< done >
True
##################### episode 25 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.100000000000001, 'episode_reward': -125.99999999999999, 'ave_reward': -7.411764705882352, 'nb_steps': 524, 'max_reward': 3.5}
######################################### STEP 524 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.55306013  0.49506801]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 525 #########################################
< action >
[-0.05       -0.04947263]
< returned_observation >
[ 0.50306013  0.44559538]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 526 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.45306013  0.39559538]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 527 #########################################
< action >
[-0.05       -0.04938955]
< returned_observation >
[ 0.40306013  0.34620583]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 528 #########################################
< action >
[-0.05       -0.04934061]
< returned_observation >
[ 0.35306013  0.29686522]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 529 #########################################
< action >
[-0.05       -0.04996677]
< returned_observation >
[ 0.30306013  0.24689845]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 530 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.25306013  0.19689845]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 531 #########################################
< action >
[-0.05       -0.04944457]
< returned_observation >
[ 0.20306013  0.14745388]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 532 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.15306013  0.09745388]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 533 #########################################
< action >
[-0.05       -0.04937649]
< returned_observation >
[ 0.10306013  0.0480774 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 534 #########################################
< action >
[-0.05       -0.04825753]
< returned_observation >
[ 0.05306013  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 535 #########################################
< action >
[-0.05       -0.04750251]
< returned_observation >
[ 0.00306013  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 536 #########################################
< action >
[-0.04798447 -0.04701235]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 26 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.2, 'episode_reward': -105.49999999999999, 'ave_reward': -8.115384615384615, 'nb_steps': 537, 'max_reward': 3.6000000000000014}
######################################### STEP 537 #########################################
< action >
[-0.04961166 -0.04956763]
< returned_observation >
[ 0.29315217  0.25455316]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 538 #########################################
< action >
[-0.04994748 -0.04867176]
< returned_observation >
[ 0.24320469  0.2058814 ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 539 #########################################
< action >
[-0.04916771 -0.04865093]
< returned_observation >
[ 0.19403698  0.15723047]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 540 #########################################
< action >
[-0.04864835 -0.0473035 ]
< returned_observation >
[ 0.14538863  0.10992697]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 541 #########################################
< action >
[-0.04741874 -0.04772243]
< returned_observation >
[ 0.09796989  0.06220454]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 542 #########################################
< action >
[-0.04483299 -0.04672036]
< returned_observation >
[ 0.0531369   0.01548418]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 543 #########################################
< action >
[-0.04516646 -0.04638714]
< returned_observation >
[ 0.00797044  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 544 #########################################
< action >
[-0.04625005 -0.04688166]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 27 infomation #####################
{'nb_episode_steps': 8, 'min_reward': -12.5, 'episode_reward': -91.9, 'ave_reward': -11.4875, 'nb_steps': 545, 'max_reward': -11.100000000000001}
######################################### STEP 545 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.36702221  0.63130077]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 546 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.31702221  0.58130077]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 547 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.26702221  0.53130077]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 548 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.21702221  0.48130077]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 549 #########################################
< action >
[-0.04879286 -0.05      ]
< returned_observation >
[ 0.16822935  0.43130077]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 550 #########################################
< action >
[-0.0490793  -0.04986863]
< returned_observation >
[ 0.11915005  0.38143213]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 551 #########################################
< action >
[-0.04916962 -0.05      ]
< returned_observation >
[ 0.06998043  0.33143213]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 552 #########################################
< action >
[-0.05       -0.04998829]
< returned_observation >
[ 0.01998043  0.28144385]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 553 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.23144385]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 554 #########################################
< action >
[-0.0499519  -0.04957304]
< returned_observation >
[ 0.          0.18187081]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 555 #########################################
< action >
[-0.05       -0.04846779]
< returned_observation >
[ 0.          0.13340302]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 556 #########################################
< action >
[-0.05       -0.04829483]
< returned_observation >
[ 0.          0.08510819]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 557 #########################################
< action >
[-0.05       -0.04834355]
< returned_observation >
[ 0.          0.03676464]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 558 #########################################
< action >
[-0.05       -0.04903283]
< returned_observation >
[ 0.  0.]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
True
##################### episode 28 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.2, 'episode_reward': -89.30000000000001, 'ave_reward': -6.378571428571429, 'nb_steps': 559, 'max_reward': 3.6999999999999993}
######################################### STEP 559 #########################################
< action >
[-0.04816803 -0.04908835]
< returned_observation >
[ 0.82728881  0.46133398]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 560 #########################################
< action >
[-0.04860458 -0.04900346]
< returned_observation >
[ 0.77868424  0.41233053]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 561 #########################################
< action >
[-0.04945345 -0.04924084]
< returned_observation >
[ 0.72923079  0.36308969]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 562 #########################################
< action >
[-0.04874717 -0.05      ]
< returned_observation >
[ 0.68048362  0.31308969]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 563 #########################################
< action >
[-0.05       -0.04974577]
< returned_observation >
[ 0.63048362  0.26334392]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 564 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.58048362  0.21334392]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 565 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.53048362  0.16334392]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 566 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.48048362  0.11334392]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 567 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.43048362  0.06334392]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 568 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.38048362  0.01334392]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 569 #########################################
< action >
[-0.05       -0.04974408]
< returned_observation >
[ 0.33048362  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 570 #########################################
< action >
[-0.05       -0.04860538]
< returned_observation >
[ 0.28048362  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 571 #########################################
< action >
[-0.05       -0.04751418]
< returned_observation >
[ 0.23048362  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 572 #########################################
< action >
[-0.05       -0.04603225]
< returned_observation >
[ 0.18048362  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 573 #########################################
< action >
[-0.05       -0.04435187]
< returned_observation >
[ 0.13048362  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 574 #########################################
< action >
[-0.04951252 -0.04325683]
< returned_observation >
[ 0.0809711  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 575 #########################################
< action >
[-0.04869367 -0.04244777]
< returned_observation >
[ 0.03227743  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 576 #########################################
< action >
[-0.04898328 -0.04294058]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 29 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -12.5, 'episode_reward': -151.9, 'ave_reward': -8.43888888888889, 'nb_steps': 577, 'max_reward': 3.6000000000000014}
######################################### STEP 577 #########################################
< action >
[-0.04931147 -0.05      ]
< returned_observation >
[ 0.62000231  0.53593655]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 578 #########################################
< action >
[-0.04767174 -0.05      ]
< returned_observation >
[ 0.57233057  0.48593655]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 579 #########################################
< action >
[-0.04786363 -0.05      ]
< returned_observation >
[ 0.52446694  0.43593655]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 580 #########################################
< action >
[-0.04846527 -0.05      ]
< returned_observation >
[ 0.47600167  0.38593655]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 581 #########################################
< action >
[-0.04948023 -0.05      ]
< returned_observation >
[ 0.42652144  0.33593655]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 582 #########################################
< action >
[-0.04857437 -0.05      ]
< returned_observation >
[ 0.37794707  0.28593655]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 583 #########################################
< action >
[-0.04859373 -0.04949982]
< returned_observation >
[ 0.32935334  0.23643674]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 584 #########################################
< action >
[-0.04806019 -0.04872503]
< returned_observation >
[ 0.28129315  0.18771171]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 585 #########################################
< action >
[-0.04820693 -0.04865929]
< returned_observation >
[ 0.23308622  0.13905242]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 586 #########################################
< action >
[-0.04909108 -0.04969138]
< returned_observation >
[ 0.18399514  0.08936104]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 587 #########################################
< action >
[-0.048208   -0.04951985]
< returned_observation >
[ 0.13578714  0.03984119]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 588 #########################################
< action >
[-0.04922638 -0.04908305]
< returned_observation >
[ 0.08656076  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 589 #########################################
< action >
[-0.04614372 -0.05      ]
< returned_observation >
[ 0.04041704  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 590 #########################################
< action >
[-0.04519933 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-10.8
< running_reward >
-3.24
< done >
True
##################### episode 30 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.100000000000001, 'episode_reward': -115.99999999999999, 'ave_reward': -8.285714285714285, 'nb_steps': 591, 'max_reward': 3.1999999999999993}
######################################### STEP 591 #########################################
< action >
[-0.05      -0.0488937]
< returned_observation >
[ 0.5749035   0.62579536]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 592 #########################################
< action >
[-0.04784086 -0.04867226]
< returned_observation >
[ 0.52706264  0.57712309]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 593 #########################################
< action >
[-0.0463664  -0.04712765]
< returned_observation >
[ 0.48069624  0.52999544]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 594 #########################################
< action >
[-0.04714219 -0.04612571]
< returned_observation >
[ 0.43355405  0.48386973]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 595 #########################################
< action >
[-0.04693841 -0.04463253]
< returned_observation >
[ 0.38661565  0.4392372 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 596 #########################################
< action >
[-0.0470627  -0.04526455]
< returned_observation >
[ 0.33955295  0.39397265]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 597 #########################################
< action >
[-0.04716031 -0.04412973]
< returned_observation >
[ 0.29239264  0.34984292]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 598 #########################################
< action >
[-0.04894492 -0.04358791]
< returned_observation >
[ 0.24344772  0.30625501]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 599 #########################################
< action >
[-0.04924659 -0.04486815]
< returned_observation >
[ 0.19420113  0.26138685]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 600 #########################################
< action >
[-0.04956453 -0.04417557]
< returned_observation >
[ 0.1446366   0.21721128]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 601 #########################################
< action >
[-0.05       -0.04279898]
< returned_observation >
[ 0.0946366  0.1744123]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 602 #########################################
< action >
[-0.04967245 -0.0424234 ]
< returned_observation >
[ 0.04496415  0.1319889 ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 603 #########################################
< action >
[-0.05       -0.04131861]
< returned_observation >
[ 0.          0.09067029]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 604 #########################################
< action >
[-0.04911549 -0.04000928]
< returned_observation >
[ 0.          0.05066102]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 605 #########################################
< action >
[-0.048677   -0.03925951]
< returned_observation >
[ 0.          0.01140151]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 606 #########################################
< action >
[-0.04967334 -0.03827556]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 31 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.3, 'episode_reward': -119.90000000000002, 'ave_reward': -7.493750000000001, 'nb_steps': 607, 'max_reward': 2.6999999999999993}
######################################### STEP 607 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.79234244  0.03319499]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 608 #########################################
< action >
[-0.05       -0.04954415]
< returned_observation >
[ 0.74234244  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 609 #########################################
< action >
[-0.05       -0.04925435]
< returned_observation >
[ 0.69234244  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 610 #########################################
< action >
[-0.05       -0.04845413]
< returned_observation >
[ 0.64234244  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 611 #########################################
< action >
[-0.04982405 -0.04789507]
< returned_observation >
[ 0.59251839  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 612 #########################################
< action >
[-0.05       -0.04845686]
< returned_observation >
[ 0.54251839  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 613 #########################################
< action >
[-0.05       -0.04848086]
< returned_observation >
[ 0.49251839  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 614 #########################################
< action >
[-0.05       -0.04817893]
< returned_observation >
[ 0.44251839  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 615 #########################################
< action >
[-0.05       -0.04829929]
< returned_observation >
[ 0.39251839  0.        ]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 616 #########################################
< action >
[-0.05       -0.04833537]
< returned_observation >
[ 0.34251839  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 617 #########################################
< action >
[-0.05       -0.04776328]
< returned_observation >
[ 0.29251839  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 618 #########################################
< action >
[-0.05       -0.04629541]
< returned_observation >
[ 0.24251839  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 619 #########################################
< action >
[-0.05       -0.04657093]
< returned_observation >
[ 0.19251839  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 620 #########################################
< action >
[-0.05       -0.04745904]
< returned_observation >
[ 0.14251839  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 621 #########################################
< action >
[-0.05       -0.04535974]
< returned_observation >
[ 0.09251839  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 622 #########################################
< action >
[-0.05      -0.0440564]
< returned_observation >
[ 0.04251839  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 623 #########################################
< action >
[-0.05       -0.04468853]
< returned_observation >
[ 0.  0.]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
True
##################### episode 32 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.399999999999999, 'episode_reward': -148.2, 'ave_reward': -8.717647058823529, 'nb_steps': 624, 'max_reward': 3.6000000000000014}
######################################### STEP 624 #########################################
< action >
[-0.05      -0.0491939]
< returned_observation >
[ 0.71368284  0.19447247]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 625 #########################################
< action >
[-0.04907526 -0.04912108]
< returned_observation >
[ 0.66460758  0.14535139]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 626 #########################################
< action >
[-0.04911612 -0.04992427]
< returned_observation >
[ 0.61549146  0.09542712]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 627 #########################################
< action >
[-0.05       -0.04977897]
< returned_observation >
[ 0.56549146  0.04564815]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 628 #########################################
< action >
[-0.05      -0.0493476]
< returned_observation >
[ 0.51549146  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 629 #########################################
< action >
[-0.04942283 -0.04898735]
< returned_observation >
[ 0.46606863  0.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 630 #########################################
< action >
[-0.04951093 -0.04829823]
< returned_observation >
[ 0.4165577  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 631 #########################################
< action >
[-0.05       -0.04787183]
< returned_observation >
[ 0.3665577  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 632 #########################################
< action >
[-0.05       -0.04694817]
< returned_observation >
[ 0.3165577  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 633 #########################################
< action >
[-0.05       -0.04743378]
< returned_observation >
[ 0.2665577  0.       ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 634 #########################################
< action >
[-0.05       -0.04806789]
< returned_observation >
[ 0.2165577  0.       ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 635 #########################################
< action >
[-0.05      -0.0475759]
< returned_observation >
[ 0.1665577  0.       ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 636 #########################################
< action >
[-0.05       -0.04868908]
< returned_observation >
[ 0.1165577  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 637 #########################################
< action >
[-0.05       -0.04624782]
< returned_observation >
[ 0.0665577  0.       ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 638 #########################################
< action >
[-0.05       -0.04752081]
< returned_observation >
[ 0.0165577  0.       ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 639 #########################################
< action >
[-0.05       -0.04643044]
< returned_observation >
[ 0.  0.]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
True
##################### episode 33 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.600000000000001, 'episode_reward': -166.60000000000002, 'ave_reward': -10.412500000000001, 'nb_steps': 640, 'max_reward': 3.6999999999999993}
######################################### STEP 640 #########################################
< action >
[-0.04946829 -0.04984185]
< returned_observation >
[ 0.14475467  0.52261511]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 641 #########################################
< action >
[-0.0497003 -0.0497746]
< returned_observation >
[ 0.09505437  0.47284051]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 642 #########################################
< action >
[-0.04832653 -0.04828243]
< returned_observation >
[ 0.04672784  0.42455808]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 643 #########################################
< action >
[-0.04864023 -0.0483233 ]
< returned_observation >
[ 0.          0.37623478]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 644 #########################################
< action >
[-0.04641067 -0.0492202 ]
< returned_observation >
[ 0.          0.32701457]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 645 #########################################
< action >
[-0.04709215 -0.0492086 ]
< returned_observation >
[ 0.          0.27780597]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 646 #########################################
< action >
[-0.0462969  -0.04916826]
< returned_observation >
[ 0.          0.22863771]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 647 #########################################
< action >
[-0.04741117 -0.05      ]
< returned_observation >
[ 0.          0.17863771]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 648 #########################################
< action >
[-0.04569253 -0.04854087]
< returned_observation >
[ 0.          0.13009684]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 649 #########################################
< action >
[-0.04521167 -0.04804675]
< returned_observation >
[ 0.          0.08205009]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 650 #########################################
< action >
[-0.04556254 -0.0471283 ]
< returned_observation >
[ 0.          0.03492179]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 651 #########################################
< action >
[-0.04493245 -0.04671692]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 34 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.5, 'episode_reward': -95.4, 'ave_reward': -7.95, 'nb_steps': 652, 'max_reward': 3.3000000000000007}
######################################### STEP 652 #########################################
< action >
[-0.0494534 -0.05     ]
< returned_observation >
[ 0.04625912  0.83532683]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 653 #########################################
< action >
[-0.04936142 -0.04903511]
< returned_observation >
[ 0.          0.78629171]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 654 #########################################
< action >
[-0.04906642 -0.05      ]
< returned_observation >
[ 0.          0.73629171]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 655 #########################################
< action >
[-0.04818452 -0.0483854 ]
< returned_observation >
[ 0.          0.68790631]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 656 #########################################
< action >
[-0.04795547 -0.04761629]
< returned_observation >
[ 0.          0.64029002]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 657 #########################################
< action >
[-0.0496176  -0.04811214]
< returned_observation >
[ 0.          0.59217789]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 658 #########################################
< action >
[-0.05       -0.04858414]
< returned_observation >
[ 0.          0.54359374]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 659 #########################################
< action >
[-0.05      -0.0493292]
< returned_observation >
[ 0.          0.49426454]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 660 #########################################
< action >
[-0.05       -0.04911251]
< returned_observation >
[ 0.          0.44515203]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 661 #########################################
< action >
[-0.05       -0.04869691]
< returned_observation >
[ 0.          0.39645512]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 662 #########################################
< action >
[-0.05       -0.04889758]
< returned_observation >
[ 0.          0.34755753]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 663 #########################################
< action >
[-0.04999331 -0.05      ]
< returned_observation >
[ 0.          0.29755753]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 664 #########################################
< action >
[-0.04949351 -0.05      ]
< returned_observation >
[ 0.          0.24755753]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 665 #########################################
< action >
[-0.04888952 -0.05      ]
< returned_observation >
[ 0.          0.19755753]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 666 #########################################
< action >
[-0.04698505 -0.05      ]
< returned_observation >
[ 0.          0.14755753]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 667 #########################################
< action >
[-0.04759726 -0.05      ]
< returned_observation >
[ 0.          0.09755753]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 668 #########################################
< action >
[-0.04768354 -0.05      ]
< returned_observation >
[ 0.          0.04755753]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 669 #########################################
< action >
[-0.04573723 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
True
##################### episode 35 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -12.399999999999999, 'episode_reward': -59.800000000000004, 'ave_reward': -3.3222222222222224, 'nb_steps': 670, 'max_reward': 3.6000000000000014}
######################################### STEP 670 #########################################
< action >
[-0.04928464 -0.05      ]
< returned_observation >
[ 0.57796434  0.67341636]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 671 #########################################
< action >
[-0.04872845 -0.05      ]
< returned_observation >
[ 0.52923589  0.62341636]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 672 #########################################
< action >
[-0.0483757  -0.04891441]
< returned_observation >
[ 0.48086018  0.57450194]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 673 #########################################
< action >
[-0.04678708 -0.04957639]
< returned_observation >
[ 0.4340731   0.52492555]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 674 #########################################
< action >
[-0.04780556 -0.04814929]
< returned_observation >
[ 0.38626754  0.47677626]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 675 #########################################
< action >
[-0.04649183 -0.04858288]
< returned_observation >
[ 0.33977571  0.42819339]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 676 #########################################
< action >
[-0.04729473 -0.04796821]
< returned_observation >
[ 0.29248098  0.38022517]
< reward >
3.8999999999999986
< running_reward >
1.1699999999999995
< done >
False
######################################### STEP 677 #########################################
< action >
[-0.0468317  -0.04787704]
< returned_observation >
[ 0.24564928  0.33234813]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 678 #########################################
< action >
[-0.04621102 -0.04825228]
< returned_observation >
[ 0.19943826  0.28409585]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 679 #########################################
< action >
[-0.04701789 -0.04831696]
< returned_observation >
[ 0.15242037  0.2357789 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 680 #########################################
< action >
[-0.04685005 -0.04767961]
< returned_observation >
[ 0.10557033  0.18809929]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 681 #########################################
< action >
[-0.04796919 -0.04744752]
< returned_observation >
[ 0.05760113  0.14065176]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 682 #########################################
< action >
[-0.04662164 -0.0469053 ]
< returned_observation >
[ 0.0109795   0.09374646]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 683 #########################################
< action >
[-0.04617811 -0.04721554]
< returned_observation >
[ 0.          0.04653093]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 684 #########################################
< action >
[-0.04460766 -0.04634553]
< returned_observation >
[ 0.          0.00018539]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 685 #########################################
< action >
[-0.04509533 -0.04660732]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 36 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.899999999999999, 'episode_reward': -83.0, 'ave_reward': -5.1875, 'nb_steps': 686, 'max_reward': 3.8999999999999986}
######################################### STEP 686 #########################################
< action >
[-0.04949234 -0.04905586]
< returned_observation >
[ 0.          0.54537602]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 687 #########################################
< action >
[-0.05       -0.04867888]
< returned_observation >
[ 0.          0.49669714]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 688 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.44669714]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 689 #########################################
< action >
[-0.05       -0.04917067]
< returned_observation >
[ 0.          0.39752647]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 690 #########################################
< action >
[-0.05       -0.04774486]
< returned_observation >
[ 0.          0.34978161]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 691 #########################################
< action >
[-0.05       -0.04783207]
< returned_observation >
[ 0.          0.30194954]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 692 #########################################
< action >
[-0.05       -0.04717728]
< returned_observation >
[ 0.          0.25477226]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 693 #########################################
< action >
[-0.05       -0.04709989]
< returned_observation >
[ 0.          0.20767237]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 694 #########################################
< action >
[-0.05       -0.04628375]
< returned_observation >
[ 0.          0.16138862]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 695 #########################################
< action >
[-0.04906649 -0.04828965]
< returned_observation >
[ 0.          0.11309897]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 696 #########################################
< action >
[-0.05       -0.04663985]
< returned_observation >
[ 0.          0.06645912]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 697 #########################################
< action >
[-0.05       -0.04374605]
< returned_observation >
[ 0.          0.02271307]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 698 #########################################
< action >
[-0.05     -0.042386]
< returned_observation >
[ 0.  0.]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
True
##################### episode 37 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.600000000000001, 'episode_reward': -118.5, 'ave_reward': -9.115384615384615, 'nb_steps': 699, 'max_reward': 3.5}
######################################### STEP 699 #########################################
< action >
[-0.05       -0.04948567]
< returned_observation >
[ 0.50678519  0.10947398]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 700 #########################################
< action >
[-0.05       -0.04903755]
< returned_observation >
[ 0.45678519  0.06043643]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 701 #########################################
< action >
[-0.05       -0.04851367]
< returned_observation >
[ 0.40678519  0.01192275]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 702 #########################################
< action >
[-0.05       -0.04726965]
< returned_observation >
[ 0.35678519  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 703 #########################################
< action >
[-0.05       -0.04797581]
< returned_observation >
[ 0.30678519  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 704 #########################################
< action >
[-0.05       -0.04781914]
< returned_observation >
[ 0.25678519  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 705 #########################################
< action >
[-0.05       -0.04731622]
< returned_observation >
[ 0.20678519  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 706 #########################################
< action >
[-0.05       -0.04503458]
< returned_observation >
[ 0.15678519  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 707 #########################################
< action >
[-0.04965922 -0.044741  ]
< returned_observation >
[ 0.10712597  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 708 #########################################
< action >
[-0.05       -0.04434158]
< returned_observation >
[ 0.05712597  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 709 #########################################
< action >
[-0.04990095 -0.04407089]
< returned_observation >
[ 0.00722502  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 710 #########################################
< action >
[-0.04939941 -0.0445444 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 38 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.2, 'episode_reward': -94.29999999999998, 'ave_reward': -7.858333333333332, 'nb_steps': 711, 'max_reward': 3.6000000000000014}
######################################### STEP 711 #########################################
< action >
[-0.05       -0.04701412]
< returned_observation >
[ 0.10307052  0.64851541]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 712 #########################################
< action >
[-0.05       -0.04711761]
< returned_observation >
[ 0.05307052  0.6013978 ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 713 #########################################
< action >
[-0.05       -0.04530499]
< returned_observation >
[ 0.00307052  0.55609281]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 714 #########################################
< action >
[-0.05       -0.04315207]
< returned_observation >
[ 0.          0.51294075]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 715 #########################################
< action >
[-0.05       -0.04275356]
< returned_observation >
[ 0.          0.47018718]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 716 #########################################
< action >
[-0.05       -0.04307478]
< returned_observation >
[ 0.         0.4271124]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 717 #########################################
< action >
[-0.05       -0.04211547]
< returned_observation >
[ 0.          0.38499694]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 718 #########################################
< action >
[-0.05       -0.03944468]
< returned_observation >
[ 0.          0.34555226]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 719 #########################################
< action >
[-0.05       -0.03791819]
< returned_observation >
[ 0.          0.30763407]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 720 #########################################
< action >
[-0.05       -0.03593147]
< returned_observation >
[ 0.         0.2717026]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 721 #########################################
< action >
[-0.04812789 -0.03560791]
< returned_observation >
[ 0.          0.23609469]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 722 #########################################
< action >
[-0.04711468 -0.03573283]
< returned_observation >
[ 0.          0.20036187]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 723 #########################################
< action >
[-0.04698301 -0.03478781]
< returned_observation >
[ 0.          0.16557406]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 724 #########################################
< action >
[-0.04653026 -0.03172601]
< returned_observation >
[ 0.          0.13384806]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 725 #########################################
< action >
[-0.04650169 -0.03143163]
< returned_observation >
[ 0.          0.10241643]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 726 #########################################
< action >
[-0.04561277 -0.03146684]
< returned_observation >
[ 0.          0.07094959]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 727 #########################################
< action >
[-0.04630492 -0.03125435]
< returned_observation >
[ 0.          0.03969524]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 728 #########################################
< action >
[-0.04601253 -0.03004842]
< returned_observation >
[ 0.          0.00964682]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 729 #########################################
< action >
[-0.04452002 -0.02806203]
< returned_observation >
[ 0.  0.]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
True
##################### episode 39 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -12.3, 'episode_reward': -160.4, 'ave_reward': -8.442105263157895, 'nb_steps': 730, 'max_reward': 3.5}
######################################### STEP 730 #########################################
< action >
[-0.04900203 -0.04606887]
< returned_observation >
[ 0.2697644   0.64590143]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 731 #########################################
< action >
[-0.04799624 -0.04482942]
< returned_observation >
[ 0.22176816  0.60107201]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 732 #########################################
< action >
[-0.04751156 -0.04219773]
< returned_observation >
[ 0.17425659  0.55887428]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 733 #########################################
< action >
[-0.04666105 -0.04216405]
< returned_observation >
[ 0.12759554  0.51671023]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 734 #########################################
< action >
[-0.04540296 -0.04081172]
< returned_observation >
[ 0.08219258  0.47589852]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 735 #########################################
< action >
[-0.04286614 -0.03962397]
< returned_observation >
[ 0.03932644  0.43627455]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 736 #########################################
< action >
[-0.04018527 -0.03766203]
< returned_observation >
[ 0.          0.39861252]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 737 #########################################
< action >
[-0.03645808 -0.03727091]
< returned_observation >
[ 0.          0.36134161]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 738 #########################################
< action >
[-0.03378205 -0.03567808]
< returned_observation >
[ 0.          0.32566353]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 739 #########################################
< action >
[-0.03328819 -0.03528321]
< returned_observation >
[ 0.          0.29038032]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 740 #########################################
< action >
[-0.03106356 -0.03424358]
< returned_observation >
[ 0.          0.25613674]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 741 #########################################
< action >
[-0.02929611 -0.03406125]
< returned_observation >
[ 0.         0.2220755]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 742 #########################################
< action >
[-0.02751215 -0.03249643]
< returned_observation >
[ 0.          0.18957906]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 743 #########################################
< action >
[-0.025748   -0.03059526]
< returned_observation >
[ 0.         0.1589838]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 744 #########################################
< action >
[-0.02443375 -0.03155906]
< returned_observation >
[ 0.          0.12742475]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 745 #########################################
< action >
[-0.02401458 -0.03056252]
< returned_observation >
[ 0.          0.09686223]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 746 #########################################
< action >
[-0.02102648 -0.02929578]
< returned_observation >
[ 0.          0.06756645]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 747 #########################################
< action >
[-0.02029588 -0.02791652]
< returned_observation >
[ 0.          0.03964993]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 748 #########################################
< action >
[-0.01845288 -0.02786963]
< returned_observation >
[ 0.         0.0117803]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 749 #########################################
< action >
[-0.0165245  -0.02908233]
< returned_observation >
[ 0.  0.]
< reward >
-11.7
< running_reward >
-3.51
< done >
True
##################### episode 40 infomation #####################
{'nb_episode_steps': 20, 'min_reward': -12.100000000000001, 'episode_reward': -155.4, 'ave_reward': -7.7700000000000005, 'nb_steps': 750, 'max_reward': 3.5}
######################################### STEP 750 #########################################
< action >
[-0.03020713 -0.0413406 ]
< returned_observation >
[ 0.52417612  0.34760997]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 751 #########################################
< action >
[-0.02885452 -0.03917832]
< returned_observation >
[ 0.4953216   0.30843166]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 752 #########################################
< action >
[-0.02673461 -0.03861958]
< returned_observation >
[ 0.46858699  0.26981208]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 753 #########################################
< action >
[-0.02561379 -0.03636637]
< returned_observation >
[ 0.44297321  0.23344571]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 754 #########################################
< action >
[-0.02656348 -0.0351364 ]
< returned_observation >
[ 0.41640973  0.19830931]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 755 #########################################
< action >
[-0.02430737 -0.03306573]
< returned_observation >
[ 0.39210236  0.16524358]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 756 #########################################
< action >
[-0.02304643 -0.03280147]
< returned_observation >
[ 0.36905592  0.13244211]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 757 #########################################
< action >
[-0.02044142 -0.03274609]
< returned_observation >
[ 0.3486145   0.09969602]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 758 #########################################
< action >
[-0.01751636 -0.03026296]
< returned_observation >
[ 0.33109814  0.06943306]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 759 #########################################
< action >
[-0.01745149 -0.02955681]
< returned_observation >
[ 0.31364665  0.03987625]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 760 #########################################
< action >
[-0.0160621  -0.03011885]
< returned_observation >
[ 0.29758456  0.0097574 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 761 #########################################
< action >
[-0.01306517 -0.02860265]
< returned_observation >
[ 0.28451939  0.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 762 #########################################
< action >
[-0.01123584 -0.02863943]
< returned_observation >
[ 0.27328355  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 763 #########################################
< action >
[-0.00942989 -0.02772432]
< returned_observation >
[ 0.26385366  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 764 #########################################
< action >
[-0.00814883 -0.02613228]
< returned_observation >
[ 0.25570483  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 765 #########################################
< action >
[-0.00684957 -0.02731778]
< returned_observation >
[ 0.24885526  0.        ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 766 #########################################
< action >
[-0.0063171  -0.02697617]
< returned_observation >
[ 0.24253816  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 767 #########################################
< action >
[-0.00549637 -0.02643966]
< returned_observation >
[ 0.2370418  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 768 #########################################
< action >
[-0.00683289 -0.02788878]
< returned_observation >
[ 0.23020891  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 769 #########################################
< action >
[-0.00624971 -0.0298005 ]
< returned_observation >
[ 0.2239592  0.       ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 770 #########################################
< action >
[-0.00534926 -0.02837338]
< returned_observation >
[ 0.21860994  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 771 #########################################
< action >
[-0.00479226 -0.02782747]
< returned_observation >
[ 0.21381768  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 772 #########################################
< action >
[-0.00376346 -0.02706252]
< returned_observation >
[ 0.21005422  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 773 #########################################
< action >
[-0.00323737 -0.02684927]
< returned_observation >
[ 0.20681685  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 774 #########################################
< action >
[-0.00480619 -0.02807157]
< returned_observation >
[ 0.20201066  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 775 #########################################
< action >
[-0.00316353 -0.02732073]
< returned_observation >
[ 0.19884713  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 776 #########################################
< action >
[-0.00365912 -0.02918489]
< returned_observation >
[ 0.19518801  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 777 #########################################
< action >
[-0.00227254 -0.0290871 ]
< returned_observation >
[ 0.19291547  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 778 #########################################
< action >
[-0.00192408 -0.02917606]
< returned_observation >
[ 0.19099139  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 779 #########################################
< action >
[-0.00242946 -0.03008017]
< returned_observation >
[ 0.18856194  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 780 #########################################
< action >
[-0.00313765 -0.03115522]
< returned_observation >
[ 0.18542428  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 781 #########################################
< action >
[-0.00238431 -0.0308276 ]
< returned_observation >
[ 0.18303997  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 782 #########################################
< action >
[-0.0015162  -0.03191629]
< returned_observation >
[ 0.18152377  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 783 #########################################
< action >
[-0.00063151 -0.03308875]
< returned_observation >
[ 0.18089227  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 784 #########################################
< action >
[-0.00045378 -0.03580194]
< returned_observation >
[ 0.18043848  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 785 #########################################
< action >
[-0.00116438 -0.03692698]
< returned_observation >
[ 0.1792741  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 786 #########################################
< action >
[-0.00197747 -0.03711119]
< returned_observation >
[ 0.17729663  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 787 #########################################
< action >
[ 0.00025484 -0.03699562]
< returned_observation >
[ 0.17755147  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 788 #########################################
< action >
[ 0.00121138 -0.03854079]
< returned_observation >
[ 0.17876285  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 789 #########################################
< action >
[ 0.00090243 -0.03828685]
< returned_observation >
[ 0.17966528  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 790 #########################################
< action >
[ 0.00199355 -0.03960772]
< returned_observation >
[ 0.18165883  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 791 #########################################
< action >
[ 0.00338467 -0.04189011]
< returned_observation >
[ 0.18504349  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 792 #########################################
< action >
[ 0.00172707 -0.04337619]
< returned_observation >
[ 0.18677056  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 793 #########################################
< action >
[ 0.00218455 -0.04390903]
< returned_observation >
[ 0.18895511  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 794 #########################################
< action >
[ 0.00192465 -0.04385392]
< returned_observation >
[ 0.19087975  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 795 #########################################
< action >
[ 0.00402831 -0.04301881]
< returned_observation >
[ 0.19490807  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 796 #########################################
< action >
[ 0.00459707 -0.04374746]
< returned_observation >
[ 0.19950514  0.        ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 797 #########################################
< action >
[ 0.00494468 -0.04407979]
< returned_observation >
[ 0.20444983  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 798 #########################################
< action >
[ 0.00534935 -0.04402099]
< returned_observation >
[ 0.20979918  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 799 #########################################
< action >
[ 0.00541572 -0.04255543]
< returned_observation >
[ 0.21521489  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 800 #########################################
< action >
[ 0.00531075 -0.0426998 ]
< returned_observation >
[ 0.22052564  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 801 #########################################
< action >
[ 0.00512578 -0.04247753]
< returned_observation >
[ 0.22565143  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 802 #########################################
< action >
[ 0.00541027 -0.04187077]
< returned_observation >
[ 0.2310617  0.       ]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 803 #########################################
< action >
[ 0.00449932 -0.041974  ]
< returned_observation >
[ 0.23556102  0.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 804 #########################################
< action >
[ 0.00472095 -0.04121858]
< returned_observation >
[ 0.24028197  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 805 #########################################
< action >
[ 0.00554408 -0.04312657]
< returned_observation >
[ 0.24582606  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 806 #########################################
< action >
[ 0.00463152 -0.04275309]
< returned_observation >
[ 0.25045758  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 807 #########################################
< action >
[ 0.00498101 -0.04215215]
< returned_observation >
[ 0.25543858  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 808 #########################################
< action >
[ 0.00613933 -0.04204196]
< returned_observation >
[ 0.26157791  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 809 #########################################
< action >
[ 0.00706418 -0.04016723]
< returned_observation >
[ 0.26864209  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 810 #########################################
< action >
[ 0.00688863 -0.03995407]
< returned_observation >
[ 0.27553072  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 811 #########################################
< action >
[ 0.0035619  -0.03916801]
< returned_observation >
[ 0.27909263  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 812 #########################################
< action >
[ 0.00551943 -0.04089753]
< returned_observation >
[ 0.28461206  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 813 #########################################
< action >
[ 0.0050809  -0.04090731]
< returned_observation >
[ 0.28969295  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 814 #########################################
< action >
[ 0.00576698 -0.04005162]
< returned_observation >
[ 0.29545994  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 815 #########################################
< action >
[ 0.00523753 -0.0406687 ]
< returned_observation >
[ 0.30069746  0.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 816 #########################################
< action >
[ 0.00408534 -0.0409726 ]
< returned_observation >
[ 0.30478281  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 817 #########################################
< action >
[ 0.004656   -0.03956063]
< returned_observation >
[ 0.30943881  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 818 #########################################
< action >
[ 0.0035188  -0.03924158]
< returned_observation >
[ 0.31295761  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 819 #########################################
< action >
[ 0.00512104 -0.03917191]
< returned_observation >
[ 0.31807865  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 820 #########################################
< action >
[ 0.00413707 -0.03955096]
< returned_observation >
[ 0.32221572  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 821 #########################################
< action >
[ 0.00410221 -0.03792273]
< returned_observation >
[ 0.32631793  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 822 #########################################
< action >
[ 0.00392954 -0.03869017]
< returned_observation >
[ 0.33024747  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 823 #########################################
< action >
[ 0.00529551 -0.03876469]
< returned_observation >
[ 0.33554298  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 824 #########################################
< action >
[ 0.00219316 -0.03952031]
< returned_observation >
[ 0.33773614  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 825 #########################################
< action >
[ 0.00077227 -0.03862773]
< returned_observation >
[ 0.33850841  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 826 #########################################
< action >
[-0.0001741 -0.0381867]
< returned_observation >
[ 0.33833432  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 827 #########################################
< action >
[-0.00101594 -0.03788038]
< returned_observation >
[ 0.33731838  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 828 #########################################
< action >
[-0.00071981 -0.03758321]
< returned_observation >
[ 0.33659857  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 829 #########################################
< action >
[-0.00080851 -0.03734939]
< returned_observation >
[ 0.33579006  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 830 #########################################
< action >
[-0.00109889 -0.03763687]
< returned_observation >
[ 0.33469117  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 831 #########################################
< action >
[-0.0006315  -0.03810456]
< returned_observation >
[ 0.33405968  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 832 #########################################
< action >
[ 0.00013812 -0.03848249]
< returned_observation >
[ 0.33419779  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 833 #########################################
< action >
[-0.00063516 -0.03770156]
< returned_observation >
[ 0.33356263  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 834 #########################################
< action >
[  9.63985920e-05  -3.78875472e-02]
< returned_observation >
[ 0.33365902  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 835 #########################################
< action >
[ 0.00185649 -0.03601823]
< returned_observation >
[ 0.33551551  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 836 #########################################
< action >
[ 0.00198241 -0.03611063]
< returned_observation >
[ 0.33749792  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 837 #########################################
< action >
[ 0.00203256 -0.03635608]
< returned_observation >
[ 0.33953048  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 838 #########################################
< action >
[ 0.0016592  -0.03781649]
< returned_observation >
[ 0.34118968  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 839 #########################################
< action >
[ 0.00111524 -0.03642851]
< returned_observation >
[ 0.34230492  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 840 #########################################
< action >
[ 0.00241634 -0.03682198]
< returned_observation >
[ 0.34472127  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 841 #########################################
< action >
[ 0.00042264 -0.03532146]
< returned_observation >
[ 0.3451439  0.       ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 842 #########################################
< action >
[ 0.0015002  -0.03496653]
< returned_observation >
[ 0.3466441  0.       ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 843 #########################################
< action >
[ 0.00029888 -0.03557465]
< returned_observation >
[ 0.34694298  0.        ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 844 #########################################
< action >
[-0.00042094 -0.03685736]
< returned_observation >
[ 0.34652204  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 845 #########################################
< action >
[-0.00071907 -0.03770089]
< returned_observation >
[ 0.34580297  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 846 #########################################
< action >
[-0.00080558 -0.03738409]
< returned_observation >
[ 0.34499739  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 847 #########################################
< action >
[-0.00124204 -0.03794737]
< returned_observation >
[ 0.34375535  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 848 #########################################
< action >
[ -1.16735697e-05  -3.67473781e-02]
< returned_observation >
[ 0.34374367  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 849 #########################################
< action >
[ -1.75327063e-05  -3.80581670e-02]
< returned_observation >
[ 0.34372614  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
True
##################### episode 41 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -12.7, 'episode_reward': -902.1000000000004, 'ave_reward': -9.021000000000004, 'nb_steps': 850, 'max_reward': 3.6000000000000014}
######################################### STEP 850 #########################################
< action >
[-0.0043874 -0.05     ]
< returned_observation >
[ 0.92074509  0.79167   ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 851 #########################################
< action >
[-0.00500462 -0.05      ]
< returned_observation >
[ 0.91574047  0.74167   ]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 852 #########################################
< action >
[-0.00558323 -0.05      ]
< returned_observation >
[ 0.91015723  0.69167   ]
< reward >
-45.0
< running_reward >
-13.5
< done >
True
##################### episode 42 infomation #####################
{'nb_episode_steps': 3, 'min_reward': -45.0, 'episode_reward': -41.7, 'ave_reward': -13.9, 'nb_steps': 853, 'max_reward': 2.3000000000000007}
######################################### STEP 853 #########################################
< action >
[ 0.00567626 -0.0493278 ]
< returned_observation >
[ 0.36307382  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 854 #########################################
< action >
[ 0.00513877 -0.04840811]
< returned_observation >
[ 0.36821259  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 855 #########################################
< action >
[ 0.00561072 -0.0492568 ]
< returned_observation >
[ 0.37382331  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 856 #########################################
< action >
[ 0.00523868 -0.04799387]
< returned_observation >
[ 0.37906199  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 857 #########################################
< action >
[ 0.00464766 -0.04965072]
< returned_observation >
[ 0.38370965  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 858 #########################################
< action >
[ 0.00298564 -0.05      ]
< returned_observation >
[ 0.38669529  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 859 #########################################
< action >
[ 0.00194002 -0.04907437]
< returned_observation >
[ 0.38863531  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 860 #########################################
< action >
[ 0.00147974 -0.04713902]
< returned_observation >
[ 0.39011504  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 861 #########################################
< action >
[ 0.00310306 -0.04867227]
< returned_observation >
[ 0.3932181  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 862 #########################################
< action >
[ 0.00415122 -0.04909458]
< returned_observation >
[ 0.39736932  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 863 #########################################
< action >
[ 0.00483589 -0.04869816]
< returned_observation >
[ 0.40220522  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 864 #########################################
< action >
[ 0.00459424 -0.04791298]
< returned_observation >
[ 0.40679946  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 865 #########################################
< action >
[ 0.00568581 -0.0477051 ]
< returned_observation >
[ 0.41248526  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 866 #########################################
< action >
[ 0.00666004 -0.0445303 ]
< returned_observation >
[ 0.4191453  0.       ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 867 #########################################
< action >
[ 0.00654418 -0.04419218]
< returned_observation >
[ 0.42568949  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 868 #########################################
< action >
[ 0.00642984 -0.04401792]
< returned_observation >
[ 0.43211933  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 869 #########################################
< action >
[ 0.00669984 -0.04358502]
< returned_observation >
[ 0.43881916  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 870 #########################################
< action >
[ 0.00563708 -0.04398032]
< returned_observation >
[ 0.44445624  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 871 #########################################
< action >
[ 0.00544665 -0.04456689]
< returned_observation >
[ 0.4499029  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 872 #########################################
< action >
[ 0.00576474 -0.04505005]
< returned_observation >
[ 0.45566764  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 873 #########################################
< action >
[ 0.00493383 -0.04659668]
< returned_observation >
[ 0.46060147  0.        ]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 874 #########################################
< action >
[ 0.00396909 -0.04724847]
< returned_observation >
[ 0.46457056  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 875 #########################################
< action >
[ 0.00375965 -0.04620373]
< returned_observation >
[ 0.46833021  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 876 #########################################
< action >
[ 0.00542339 -0.04487011]
< returned_observation >
[ 0.4737536  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 877 #########################################
< action >
[ 0.00553377 -0.04263336]
< returned_observation >
[ 0.47928737  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 878 #########################################
< action >
[ 0.00497752 -0.04342033]
< returned_observation >
[ 0.4842649  0.       ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 879 #########################################
< action >
[ 0.00436835 -0.04260833]
< returned_observation >
[ 0.48863324  0.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 880 #########################################
< action >
[ 0.00293331 -0.04137504]
< returned_observation >
[ 0.49156655  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 881 #########################################
< action >
[ 0.00064356 -0.04114038]
< returned_observation >
[ 0.49221011  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 882 #########################################
< action >
[-0.00055763 -0.04090271]
< returned_observation >
[ 0.49165248  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 883 #########################################
< action >
[-0.0021037  -0.04040833]
< returned_observation >
[ 0.48954878  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 884 #########################################
< action >
[-0.00406651 -0.04198688]
< returned_observation >
[ 0.48548227  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 885 #########################################
< action >
[-0.00630784 -0.04349171]
< returned_observation >
[ 0.47917443  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 886 #########################################
< action >
[-0.00745777 -0.04145481]
< returned_observation >
[ 0.47171666  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 887 #########################################
< action >
[-0.00695098 -0.04166047]
< returned_observation >
[ 0.46476568  0.        ]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 888 #########################################
< action >
[-0.00692283 -0.04093767]
< returned_observation >
[ 0.45784285  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 889 #########################################
< action >
[-0.00470245 -0.04004137]
< returned_observation >
[ 0.45314039  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 890 #########################################
< action >
[-0.00376273 -0.03954912]
< returned_observation >
[ 0.44937766  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 891 #########################################
< action >
[-0.00327313 -0.03811332]
< returned_observation >
[ 0.44610453  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 892 #########################################
< action >
[-0.0018188  -0.03912188]
< returned_observation >
[ 0.44428573  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 893 #########################################
< action >
[-0.00367452 -0.03908059]
< returned_observation >
[ 0.44061121  0.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 894 #########################################
< action >
[-0.004234   -0.03978678]
< returned_observation >
[ 0.4363772  0.       ]
< reward >
-14.3
< running_reward >
-4.29
< done >
False
######################################### STEP 895 #########################################
< action >
[-0.00668668 -0.03925885]
< returned_observation >
[ 0.42969053  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 896 #########################################
< action >
[-0.008167   -0.03766567]
< returned_observation >
[ 0.42152352  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 897 #########################################
< action >
[-0.00880232 -0.03685316]
< returned_observation >
[ 0.41272121  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 898 #########################################
< action >
[-0.00954441 -0.03701059]
< returned_observation >
[ 0.4031768  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 899 #########################################
< action >
[-0.00980346 -0.0373171 ]
< returned_observation >
[ 0.39337334  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 900 #########################################
< action >
[-0.00902489 -0.03738768]
< returned_observation >
[ 0.38434845  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 901 #########################################
< action >
[-0.00778882 -0.03581855]
< returned_observation >
[ 0.37655964  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 902 #########################################
< action >
[-0.0074628  -0.03573654]
< returned_observation >
[ 0.36909683  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 903 #########################################
< action >
[-0.00582648 -0.03579946]
< returned_observation >
[ 0.36327036  0.        ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 904 #########################################
< action >
[-0.00589139 -0.03481723]
< returned_observation >
[ 0.35737897  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 905 #########################################
< action >
[-0.00459666 -0.03545405]
< returned_observation >
[ 0.35278231  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 906 #########################################
< action >
[-0.00429123 -0.0349579 ]
< returned_observation >
[ 0.34849107  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 907 #########################################
< action >
[-0.00245964 -0.03599268]
< returned_observation >
[ 0.34603144  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 908 #########################################
< action >
[-0.00149437 -0.03756686]
< returned_observation >
[ 0.34453707  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 909 #########################################
< action >
[-0.0010643  -0.03435099]
< returned_observation >
[ 0.34347277  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 910 #########################################
< action >
[-0.00075661 -0.03288565]
< returned_observation >
[ 0.34271616  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 911 #########################################
< action >
[-0.00021499 -0.03496137]
< returned_observation >
[ 0.34250117  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 912 #########################################
< action >
[ 0.00012257 -0.03449138]
< returned_observation >
[ 0.34262374  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 913 #########################################
< action >
[ -4.36723232e-05  -3.41880918e-02]
< returned_observation >
[ 0.34258007  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 914 #########################################
< action >
[ 0.00098937 -0.0347753 ]
< returned_observation >
[ 0.34356944  0.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 915 #########################################
< action >
[ 0.00269986 -0.03369372]
< returned_observation >
[ 0.3462693  0.       ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 916 #########################################
< action >
[ 0.0024991  -0.03315003]
< returned_observation >
[ 0.34876841  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 917 #########################################
< action >
[ 0.00062439 -0.03219412]
< returned_observation >
[ 0.3493928  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 918 #########################################
< action >
[ 0.0005665  -0.03136021]
< returned_observation >
[ 0.3499593  0.       ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 919 #########################################
< action >
[ 0.00178419 -0.03138526]
< returned_observation >
[ 0.35174349  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 920 #########################################
< action >
[  2.54273415e-05  -3.07608172e-02]
< returned_observation >
[ 0.35176892  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 921 #########################################
< action >
[ 0.0005121  -0.03174088]
< returned_observation >
[ 0.35228102  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 922 #########################################
< action >
[ 0.0019109  -0.03240952]
< returned_observation >
[ 0.35419192  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 923 #########################################
< action >
[ 0.00276642 -0.03068648]
< returned_observation >
[ 0.35695835  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 924 #########################################
< action >
[ 0.00524106 -0.02959812]
< returned_observation >
[ 0.36219941  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 925 #########################################
< action >
[ 0.0047516  -0.03037262]
< returned_observation >
[ 0.36695101  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 926 #########################################
< action >
[ 0.00413556 -0.03134913]
< returned_observation >
[ 0.37108656  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 927 #########################################
< action >
[ 0.00285584 -0.03109695]
< returned_observation >
[ 0.3739424  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 928 #########################################
< action >
[ 0.00290322 -0.03093367]
< returned_observation >
[ 0.37684562  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 929 #########################################
< action >
[ 0.00302345 -0.03017407]
< returned_observation >
[ 0.37986907  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 930 #########################################
< action >
[ 0.00322174 -0.03023628]
< returned_observation >
[ 0.38309081  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 931 #########################################
< action >
[ 0.00311788 -0.03025627]
< returned_observation >
[ 0.38620869  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 932 #########################################
< action >
[ 0.00405678 -0.03164626]
< returned_observation >
[ 0.39026547  0.        ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 933 #########################################
< action >
[ 0.00165775 -0.03030684]
< returned_observation >
[ 0.39192322  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 934 #########################################
< action >
[ 0.00029294 -0.02991261]
< returned_observation >
[ 0.39221616  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 935 #########################################
< action >
[  3.86238098e-06  -2.89146930e-02]
< returned_observation >
[ 0.39222002  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 936 #########################################
< action >
[ 0.00206608 -0.02967821]
< returned_observation >
[ 0.39428611  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 937 #########################################
< action >
[ 0.00353284 -0.03105536]
< returned_observation >
[ 0.39781895  0.        ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 938 #########################################
< action >
[ 0.00437344 -0.03107364]
< returned_observation >
[ 0.40219239  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 939 #########################################
< action >
[ 0.00451843 -0.03148385]
< returned_observation >
[ 0.40671083  0.        ]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 940 #########################################
< action >
[ 0.00518146 -0.03036518]
< returned_observation >
[ 0.41189229  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 941 #########################################
< action >
[ 0.00410929 -0.03086436]
< returned_observation >
[ 0.41600158  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 942 #########################################
< action >
[ 0.00450122 -0.03119648]
< returned_observation >
[ 0.4205028  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 943 #########################################
< action >
[ 0.0051573  -0.03069983]
< returned_observation >
[ 0.4256601  0.       ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 944 #########################################
< action >
[ 0.00551891 -0.03191863]
< returned_observation >
[ 0.43117902  0.        ]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 945 #########################################
< action >
[ 0.0064328  -0.03134748]
< returned_observation >
[ 0.43761181  0.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 946 #########################################
< action >
[ 0.00611683 -0.03051408]
< returned_observation >
[ 0.44372864  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 947 #########################################
< action >
[ 0.00359849 -0.02965246]
< returned_observation >
[ 0.44732713  0.        ]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 948 #########################################
< action >
[ 0.00174227 -0.03018709]
< returned_observation >
[ 0.4490694  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 949 #########################################
< action >
[ 0.00053656 -0.03057525]
< returned_observation >
[ 0.44960596  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 950 #########################################
< action >
[ 0.00195079 -0.03085129]
< returned_observation >
[ 0.45155675  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 951 #########################################
< action >
[ 0.00217137 -0.03182883]
< returned_observation >
[ 0.45372811  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 952 #########################################
< action >
[ 0.00240054 -0.03284061]
< returned_observation >
[ 0.45612866  0.        ]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
True
##################### episode 43 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -14.3, 'episode_reward': -805.9999999999999, 'ave_reward': -8.059999999999999, 'nb_steps': 953, 'max_reward': 3.6999999999999993}
######################################### STEP 953 #########################################
< action >
[-0.00082582 -0.04911341]
< returned_observation >
[ 0.30394225  0.34907227]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 954 #########################################
< action >
[ 0.0017861  -0.04843737]
< returned_observation >
[ 0.30572835  0.3006349 ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 955 #########################################
< action >
[ 0.00259125 -0.05      ]
< returned_observation >
[ 0.3083196  0.2506349]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 956 #########################################
< action >
[ 0.00220587 -0.04799076]
< returned_observation >
[ 0.31052547  0.20264414]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 957 #########################################
< action >
[ 0.00314744 -0.04922286]
< returned_observation >
[ 0.31367291  0.15342128]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 958 #########################################
< action >
[ 0.00412765 -0.04850082]
< returned_observation >
[ 0.31780056  0.10492045]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 959 #########################################
< action >
[ 0.006346   -0.04862153]
< returned_observation >
[ 0.32414656  0.05629892]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 960 #########################################
< action >
[ 0.00853632 -0.04899752]
< returned_observation >
[ 0.33268288  0.0073014 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 961 #########################################
< action >
[ 0.00911221 -0.05      ]
< returned_observation >
[ 0.34179509  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 962 #########################################
< action >
[ 0.00788565 -0.05      ]
< returned_observation >
[ 0.34968073  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 963 #########################################
< action >
[ 0.00687671 -0.05      ]
< returned_observation >
[ 0.35655745  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 964 #########################################
< action >
[ 0.00555397 -0.05      ]
< returned_observation >
[ 0.36211142  0.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 965 #########################################
< action >
[ 0.00631122 -0.05      ]
< returned_observation >
[ 0.36842264  0.        ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 966 #########################################
< action >
[ 0.00686166 -0.05      ]
< returned_observation >
[ 0.3752843  0.       ]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 967 #########################################
< action >
[ 0.00682318 -0.05      ]
< returned_observation >
[ 0.38210748  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 968 #########################################
< action >
[ 0.00777526 -0.05      ]
< returned_observation >
[ 0.38988274  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 969 #########################################
< action >
[ 0.0081974 -0.05     ]
< returned_observation >
[ 0.39808014  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 970 #########################################
< action >
[ 0.00663915 -0.05      ]
< returned_observation >
[ 0.40471929  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 971 #########################################
< action >
[ 0.00392662 -0.05      ]
< returned_observation >
[ 0.40864592  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 972 #########################################
< action >
[ 0.00398897 -0.05      ]
< returned_observation >
[ 0.41263489  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 973 #########################################
< action >
[ 0.00329607 -0.05      ]
< returned_observation >
[ 0.41593095  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 974 #########################################
< action >
[ 0.00313945 -0.05      ]
< returned_observation >
[ 0.4190704  0.       ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 975 #########################################
< action >
[ 0.00290927 -0.05      ]
< returned_observation >
[ 0.42197967  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 976 #########################################
< action >
[ 0.0027721 -0.05     ]
< returned_observation >
[ 0.42475178  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 977 #########################################
< action >
[ 0.00262529 -0.05      ]
< returned_observation >
[ 0.42737706  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 978 #########################################
< action >
[ 0.00333565 -0.05      ]
< returned_observation >
[ 0.43071272  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 979 #########################################
< action >
[ 0.00295234 -0.05      ]
< returned_observation >
[ 0.43366506  0.        ]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 980 #########################################
< action >
[ 0.00262999 -0.05      ]
< returned_observation >
[ 0.43629505  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 981 #########################################
< action >
[ 0.00158198 -0.05      ]
< returned_observation >
[ 0.43787703  0.        ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 982 #########################################
< action >
[ 0.00063663 -0.05      ]
< returned_observation >
[ 0.43851366  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 983 #########################################
< action >
[-0.00127201 -0.05      ]
< returned_observation >
[ 0.43724165  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 984 #########################################
< action >
[-0.00232354 -0.05      ]
< returned_observation >
[ 0.43491811  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 985 #########################################
< action >
[-0.00336587 -0.05      ]
< returned_observation >
[ 0.43155223  0.        ]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 986 #########################################
< action >
[-0.00271569 -0.05      ]
< returned_observation >
[ 0.42883654  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 987 #########################################
< action >
[-0.00350127 -0.05      ]
< returned_observation >
[ 0.42533527  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 988 #########################################
< action >
[-0.00374709 -0.05      ]
< returned_observation >
[ 0.42158818  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 989 #########################################
< action >
[-0.00511899 -0.05      ]
< returned_observation >
[ 0.41646919  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 990 #########################################
< action >
[-0.00473121 -0.05      ]
< returned_observation >
[ 0.41173798  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 991 #########################################
< action >
[-0.00536253 -0.05      ]
< returned_observation >
[ 0.40637545  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 992 #########################################
< action >
[-0.0031996 -0.05     ]
< returned_observation >
[ 0.40317585  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 993 #########################################
< action >
[-0.00219454 -0.05      ]
< returned_observation >
[ 0.40098132  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 994 #########################################
< action >
[-0.00244719 -0.05      ]
< returned_observation >
[ 0.39853413  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 995 #########################################
< action >
[-0.00193267 -0.05      ]
< returned_observation >
[ 0.39660146  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 996 #########################################
< action >
[-0.00228023 -0.05      ]
< returned_observation >
[ 0.39432123  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 997 #########################################
< action >
[-0.0005155 -0.05     ]
< returned_observation >
[ 0.39380573  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 998 #########################################
< action >
[-0.00158178 -0.05      ]
< returned_observation >
[ 0.39222395  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 999 #########################################
< action >
[-0.00263802 -0.04947857]
< returned_observation >
[ 0.38958592  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1000 #########################################
< action >
[-0.00488435 -0.05      ]
< returned_observation >
[ 0.38470157  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1001 #########################################
< action >
[-0.0052377 -0.05     ]
< returned_observation >
[ 0.37946387  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1002 #########################################
< action >
[-0.0066507 -0.05     ]
< returned_observation >
[ 0.37281317  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1003 #########################################
< action >
[-0.00618553 -0.05      ]
< returned_observation >
[ 0.36662763  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1004 #########################################
< action >
[-0.00681102 -0.05      ]
< returned_observation >
[ 0.35981661  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1005 #########################################
< action >
[-0.00599948 -0.05      ]
< returned_observation >
[ 0.35381713  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1006 #########################################
< action >
[-0.00731055 -0.05      ]
< returned_observation >
[ 0.34650659  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1007 #########################################
< action >
[-0.00751429 -0.05      ]
< returned_observation >
[ 0.3389923  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1008 #########################################
< action >
[-0.01017921 -0.05      ]
< returned_observation >
[ 0.32881309  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1009 #########################################
< action >
[-0.01056887 -0.05      ]
< returned_observation >
[ 0.31824422  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1010 #########################################
< action >
[-0.00970961 -0.05      ]
< returned_observation >
[ 0.30853461  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1011 #########################################
< action >
[-0.0096144 -0.05     ]
< returned_observation >
[ 0.29892021  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1012 #########################################
< action >
[-0.00913624 -0.05      ]
< returned_observation >
[ 0.28978397  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1013 #########################################
< action >
[-0.00996519 -0.05      ]
< returned_observation >
[ 0.27981878  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1014 #########################################
< action >
[-0.01100213 -0.05      ]
< returned_observation >
[ 0.26881666  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1015 #########################################
< action >
[-0.00965213 -0.05      ]
< returned_observation >
[ 0.25916453  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1016 #########################################
< action >
[-0.01096443 -0.05      ]
< returned_observation >
[ 0.2482001  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1017 #########################################
< action >
[-0.01279928 -0.05      ]
< returned_observation >
[ 0.23540082  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1018 #########################################
< action >
[-0.01290816 -0.05      ]
< returned_observation >
[ 0.22249266  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1019 #########################################
< action >
[-0.01137042 -0.05      ]
< returned_observation >
[ 0.21112224  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1020 #########################################
< action >
[-0.01278116 -0.05      ]
< returned_observation >
[ 0.19834108  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1021 #########################################
< action >
[-0.01181979 -0.05      ]
< returned_observation >
[ 0.18652129  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1022 #########################################
< action >
[-0.0104162  -0.04931945]
< returned_observation >
[ 0.17610509  0.        ]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1023 #########################################
< action >
[-0.01013342 -0.04886514]
< returned_observation >
[ 0.16597167  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1024 #########################################
< action >
[-0.00927904 -0.04828196]
< returned_observation >
[ 0.15669263  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1025 #########################################
< action >
[-0.00776404 -0.04711699]
< returned_observation >
[ 0.14892859  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1026 #########################################
< action >
[-0.00718716 -0.04722072]
< returned_observation >
[ 0.14174142  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1027 #########################################
< action >
[-0.00536992 -0.04729129]
< returned_observation >
[ 0.13637151  0.        ]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 1028 #########################################
< action >
[-0.00402416 -0.04778708]
< returned_observation >
[ 0.13234735  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1029 #########################################
< action >
[-0.00511496 -0.04679462]
< returned_observation >
[ 0.12723239  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1030 #########################################
< action >
[-0.00287622 -0.04621797]
< returned_observation >
[ 0.12435617  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1031 #########################################
< action >
[-0.00378305 -0.04626301]
< returned_observation >
[ 0.12057311  0.        ]
< reward >
3.8000000000000007
< running_reward >
1.1400000000000001
< done >
False
######################################### STEP 1032 #########################################
< action >
[-0.00320443 -0.0447143 ]
< returned_observation >
[ 0.11736868  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1033 #########################################
< action >
[-0.00228805 -0.04409088]
< returned_observation >
[ 0.11508063  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1034 #########################################
< action >
[-0.00126737 -0.0436479 ]
< returned_observation >
[ 0.11381327  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1035 #########################################
< action >
[-0.00091625 -0.0436028 ]
< returned_observation >
[ 0.11289701  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1036 #########################################
< action >
[-0.0018941  -0.04265745]
< returned_observation >
[ 0.11100291  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1037 #########################################
< action >
[-0.00127728 -0.04408547]
< returned_observation >
[ 0.10972564  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1038 #########################################
< action >
[-0.00183451 -0.04454573]
< returned_observation >
[ 0.10789113  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1039 #########################################
< action >
[-0.00070758 -0.04306878]
< returned_observation >
[ 0.10718355  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1040 #########################################
< action >
[-0.00084694 -0.04058767]
< returned_observation >
[ 0.10633661  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1041 #########################################
< action >
[-0.00261737 -0.0401092 ]
< returned_observation >
[ 0.10371923  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1042 #########################################
< action >
[-0.00265791 -0.04094757]
< returned_observation >
[ 0.10106132  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1043 #########################################
< action >
[-0.00417551 -0.04052181]
< returned_observation >
[ 0.09688582  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1044 #########################################
< action >
[-0.00514138 -0.03997888]
< returned_observation >
[ 0.09174444  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1045 #########################################
< action >
[-0.00525267 -0.03971165]
< returned_observation >
[ 0.08649177  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1046 #########################################
< action >
[-0.00581955 -0.03993891]
< returned_observation >
[ 0.08067221  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1047 #########################################
< action >
[-0.00654781 -0.04002118]
< returned_observation >
[ 0.0741244  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1048 #########################################
< action >
[-0.00401818 -0.04069912]
< returned_observation >
[ 0.07010622  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1049 #########################################
< action >
[-0.00442911 -0.03837749]
< returned_observation >
[ 0.06567712  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1050 #########################################
< action >
[-0.00434685 -0.03671157]
< returned_observation >
[ 0.06133026  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1051 #########################################
< action >
[-0.00299147 -0.0370238 ]
< returned_observation >
[ 0.05833879  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1052 #########################################
< action >
[-0.00297822 -0.03707128]
< returned_observation >
[ 0.05536057  0.        ]
< reward >
-10.8
< running_reward >
-3.24
< done >
True
##################### episode 44 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -12.7, 'episode_reward': -898.5999999999996, 'ave_reward': -8.985999999999995, 'nb_steps': 1053, 'max_reward': 3.8000000000000007}
######################################### STEP 1053 #########################################
< action >
[-0.02140358 -0.04940059]
< returned_observation >
[ 0.68355525  0.94595789]
< reward >
-45.0
< running_reward >
-13.5
< done >
True
##################### episode 45 infomation #####################
{'nb_episode_steps': 1, 'min_reward': -45.0, 'episode_reward': -45.0, 'ave_reward': -45.0, 'nb_steps': 1054, 'max_reward': -45.0}
######################################### STEP 1054 #########################################
< action >
[ 0.00054981 -0.04953245]
< returned_observation >
[ 0.35646467  0.71301536]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1055 #########################################
< action >
[ 0.0001678 -0.05     ]
< returned_observation >
[ 0.35663247  0.66301536]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 1056 #########################################
< action >
[ 0.00025611 -0.05      ]
< returned_observation >
[ 0.35688858  0.61301536]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1057 #########################################
< action >
[-0.00096485 -0.05      ]
< returned_observation >
[ 0.35592373  0.56301536]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1058 #########################################
< action >
[-0.00168297 -0.05      ]
< returned_observation >
[ 0.35424076  0.51301536]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1059 #########################################
< action >
[-0.00178684 -0.05      ]
< returned_observation >
[ 0.35245392  0.46301536]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1060 #########################################
< action >
[-0.00147231 -0.05      ]
< returned_observation >
[ 0.3509816   0.41301536]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1061 #########################################
< action >
[-0.00125036 -0.05      ]
< returned_observation >
[ 0.34973124  0.36301536]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1062 #########################################
< action >
[-0.0025516 -0.05     ]
< returned_observation >
[ 0.34717965  0.31301536]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1063 #########################################
< action >
[-0.00505871 -0.05      ]
< returned_observation >
[ 0.34212094  0.26301536]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1064 #########################################
< action >
[-0.00680197 -0.05      ]
< returned_observation >
[ 0.33531898  0.21301536]
< reward >
-10.3
< running_reward >
-3.0900000000000003
< done >
False
######################################### STEP 1065 #########################################
< action >
[-0.0094043 -0.05     ]
< returned_observation >
[ 0.32591467  0.16301536]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1066 #########################################
< action >
[-0.01111772 -0.05      ]
< returned_observation >
[ 0.31479695  0.11301536]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1067 #########################################
< action >
[-0.01560279 -0.05      ]
< returned_observation >
[ 0.29919416  0.06301536]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1068 #########################################
< action >
[-0.01755117 -0.05      ]
< returned_observation >
[ 0.281643    0.01301536]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1069 #########################################
< action >
[-0.0187062 -0.05     ]
< returned_observation >
[ 0.26293679  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1070 #########################################
< action >
[-0.01874997 -0.05      ]
< returned_observation >
[ 0.24418683  0.        ]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 1071 #########################################
< action >
[-0.01721703 -0.05      ]
< returned_observation >
[ 0.2269698  0.       ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1072 #########################################
< action >
[-0.01692438 -0.05      ]
< returned_observation >
[ 0.21004542  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1073 #########################################
< action >
[-0.01529702 -0.05      ]
< returned_observation >
[ 0.1947484  0.       ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1074 #########################################
< action >
[-0.01532037 -0.05      ]
< returned_observation >
[ 0.17942803  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1075 #########################################
< action >
[-0.0152472 -0.05     ]
< returned_observation >
[ 0.16418083  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1076 #########################################
< action >
[-0.01485586 -0.05      ]
< returned_observation >
[ 0.14932498  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1077 #########################################
< action >
[-0.01553014 -0.05      ]
< returned_observation >
[ 0.13379483  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1078 #########################################
< action >
[-0.01316845 -0.05      ]
< returned_observation >
[ 0.12062639  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1079 #########################################
< action >
[-0.01207972 -0.05      ]
< returned_observation >
[ 0.10854667  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1080 #########################################
< action >
[-0.0115348 -0.05     ]
< returned_observation >
[ 0.09701187  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1081 #########################################
< action >
[-0.01397667 -0.05      ]
< returned_observation >
[ 0.0830352  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1082 #########################################
< action >
[-0.01401672 -0.05      ]
< returned_observation >
[ 0.06901848  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1083 #########################################
< action >
[-0.01345062 -0.05      ]
< returned_observation >
[ 0.05556786  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1084 #########################################
< action >
[-0.01355816 -0.05      ]
< returned_observation >
[ 0.0420097  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1085 #########################################
< action >
[-0.01414346 -0.05      ]
< returned_observation >
[ 0.02786623  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1086 #########################################
< action >
[-0.01407968 -0.05      ]
< returned_observation >
[ 0.01378655  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1087 #########################################
< action >
[-0.01220269 -0.05      ]
< returned_observation >
[ 0.00158386  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1088 #########################################
< action >
[-0.01224722 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 46 infomation #####################
{'nb_episode_steps': 35, 'min_reward': -13.899999999999999, 'episode_reward': -234.2, 'ave_reward': -6.691428571428571, 'nb_steps': 1089, 'max_reward': 3.6000000000000014}
######################################### STEP 1089 #########################################
< action >
[-0.03467263 -0.05      ]
< returned_observation >
[ 0.55850429  0.6417018 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1090 #########################################
< action >
[-0.03440081 -0.05      ]
< returned_observation >
[ 0.52410348  0.5917018 ]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 1091 #########################################
< action >
[-0.03458706 -0.05      ]
< returned_observation >
[ 0.48951642  0.5417018 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1092 #########################################
< action >
[-0.03226483 -0.04907808]
< returned_observation >
[ 0.45725159  0.49262372]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1093 #########################################
< action >
[-0.03101504 -0.04792992]
< returned_observation >
[ 0.42623655  0.4446938 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1094 #########################################
< action >
[-0.03101635 -0.04959139]
< returned_observation >
[ 0.3952202   0.39510242]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1095 #########################################
< action >
[-0.02948108 -0.05      ]
< returned_observation >
[ 0.36573912  0.34510242]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1096 #########################################
< action >
[-0.02915121 -0.05      ]
< returned_observation >
[ 0.33658791  0.29510242]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1097 #########################################
< action >
[-0.03028501 -0.05      ]
< returned_observation >
[ 0.3063029   0.24510242]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1098 #########################################
< action >
[-0.02991344 -0.05      ]
< returned_observation >
[ 0.27638947  0.19510242]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1099 #########################################
< action >
[-0.02926592 -0.05      ]
< returned_observation >
[ 0.24712354  0.14510242]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1100 #########################################
< action >
[-0.02920633 -0.05      ]
< returned_observation >
[ 0.21791721  0.09510242]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1101 #########################################
< action >
[-0.03082635 -0.05      ]
< returned_observation >
[ 0.18709087  0.04510242]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1102 #########################################
< action >
[-0.03318396 -0.05      ]
< returned_observation >
[ 0.1539069  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1103 #########################################
< action >
[-0.03503064 -0.05      ]
< returned_observation >
[ 0.11887626  0.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1104 #########################################
< action >
[-0.03197976 -0.05      ]
< returned_observation >
[ 0.0868965  0.       ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1105 #########################################
< action >
[-0.02754952 -0.05      ]
< returned_observation >
[ 0.05934698  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1106 #########################################
< action >
[-0.02430284 -0.05      ]
< returned_observation >
[ 0.03504414  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1107 #########################################
< action >
[-0.02145967 -0.05      ]
< returned_observation >
[ 0.01358446  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1108 #########################################
< action >
[-0.01799545 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 47 infomation #####################
{'nb_episode_steps': 20, 'min_reward': -12.399999999999999, 'episode_reward': -201.69999999999996, 'ave_reward': -10.084999999999997, 'nb_steps': 1109, 'max_reward': 2.1000000000000014}
######################################### STEP 1109 #########################################
< action >
[ 0.00895414 -0.05      ]
< returned_observation >
[ 0.1600816   0.34887629]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1110 #########################################
< action >
[ 0.00569997 -0.05      ]
< returned_observation >
[ 0.16578156  0.29887629]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1111 #########################################
< action >
[-0.00145739 -0.05      ]
< returned_observation >
[ 0.16432417  0.24887629]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1112 #########################################
< action >
[-0.00964601 -0.05      ]
< returned_observation >
[ 0.15467817  0.19887629]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1113 #########################################
< action >
[-0.01551069 -0.05      ]
< returned_observation >
[ 0.13916748  0.14887629]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1114 #########################################
< action >
[-0.01948588 -0.05      ]
< returned_observation >
[ 0.11968159  0.09887629]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1115 #########################################
< action >
[-0.02454852 -0.05      ]
< returned_observation >
[ 0.09513308  0.04887629]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1116 #########################################
< action >
[-0.02625018 -0.05      ]
< returned_observation >
[ 0.0688829  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1117 #########################################
< action >
[-0.02809102 -0.05      ]
< returned_observation >
[ 0.04079189  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1118 #########################################
< action >
[-0.0251754 -0.05     ]
< returned_observation >
[ 0.01561649  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1119 #########################################
< action >
[-0.02375257 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
True
##################### episode 48 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -11.7, 'episode_reward': -81.69999999999999, 'ave_reward': -7.427272727272726, 'nb_steps': 1120, 'max_reward': 3.3000000000000007}
######################################### STEP 1120 #########################################
< action >
[-0.00576169 -0.04953619]
< returned_observation >
[ 0.23509421  0.29391983]
< reward >
3.8999999999999986
< running_reward >
1.1699999999999995
< done >
False
######################################### STEP 1121 #########################################
< action >
[-0.01216765 -0.05      ]
< returned_observation >
[ 0.22292655  0.24391983]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1122 #########################################
< action >
[-0.01959472 -0.05      ]
< returned_observation >
[ 0.20333183  0.19391983]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1123 #########################################
< action >
[-0.02396474 -0.05      ]
< returned_observation >
[ 0.17936709  0.14391983]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1124 #########################################
< action >
[-0.02798488 -0.04932491]
< returned_observation >
[ 0.15138221  0.09459492]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1125 #########################################
< action >
[-0.03108784 -0.04955586]
< returned_observation >
[ 0.12029437  0.04503906]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1126 #########################################
< action >
[-0.0344659  -0.04829617]
< returned_observation >
[ 0.08582848  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1127 #########################################
< action >
[-0.03612049 -0.04743384]
< returned_observation >
[ 0.04970798  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1128 #########################################
< action >
[-0.03263247 -0.04879895]
< returned_observation >
[ 0.01707551  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1129 #########################################
< action >
[-0.02867298 -0.0486103 ]
< returned_observation >
[ 0.  0.]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
True
##################### episode 49 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -12.2, 'episode_reward': -84.50000000000001, 'ave_reward': -8.450000000000001, 'nb_steps': 1130, 'max_reward': 3.8999999999999986}
######################################### STEP 1130 #########################################
< action >
[-0.00473455 -0.05      ]
< returned_observation >
[ 0.50839361  0.61662455]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1131 #########################################
< action >
[-0.00777649 -0.05      ]
< returned_observation >
[ 0.50061712  0.56662455]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1132 #########################################
< action >
[-0.00939833 -0.05      ]
< returned_observation >
[ 0.49121879  0.51662455]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1133 #########################################
< action >
[-0.01318448 -0.05      ]
< returned_observation >
[ 0.47803431  0.46662455]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1134 #########################################
< action >
[-0.01471358 -0.05      ]
< returned_observation >
[ 0.46332073  0.41662455]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1135 #########################################
< action >
[-0.01932122 -0.05      ]
< returned_observation >
[ 0.44399951  0.36662455]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1136 #########################################
< action >
[-0.02357693 -0.05      ]
< returned_observation >
[ 0.42042258  0.31662455]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1137 #########################################
< action >
[-0.02731989 -0.05      ]
< returned_observation >
[ 0.39310269  0.26662455]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1138 #########################################
< action >
[-0.02986035 -0.05      ]
< returned_observation >
[ 0.36324234  0.21662455]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1139 #########################################
< action >
[-0.03192837 -0.05      ]
< returned_observation >
[ 0.33131397  0.16662455]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1140 #########################################
< action >
[-0.03570942 -0.05      ]
< returned_observation >
[ 0.29560455  0.11662455]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1141 #########################################
< action >
[-0.03614292 -0.05      ]
< returned_observation >
[ 0.25946162  0.06662455]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1142 #########################################
< action >
[-0.03805784 -0.05      ]
< returned_observation >
[ 0.22140379  0.01662455]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1143 #########################################
< action >
[-0.04049625 -0.05      ]
< returned_observation >
[ 0.18090753  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1144 #########################################
< action >
[-0.04008612 -0.05      ]
< returned_observation >
[ 0.14082141  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1145 #########################################
< action >
[-0.03794882 -0.05      ]
< returned_observation >
[ 0.10287259  0.        ]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1146 #########################################
< action >
[-0.03524207 -0.05      ]
< returned_observation >
[ 0.06763052  0.        ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1147 #########################################
< action >
[-0.03411974 -0.05      ]
< returned_observation >
[ 0.03351078  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1148 #########################################
< action >
[-0.03121022 -0.05      ]
< returned_observation >
[ 0.00230056  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1149 #########################################
< action >
[-0.02715571 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 50 infomation #####################
{'nb_episode_steps': 20, 'min_reward': -12.399999999999999, 'episode_reward': -169.39999999999998, 'ave_reward': -8.469999999999999, 'nb_steps': 1150, 'max_reward': 3.6000000000000014}
######################################### STEP 1150 #########################################
< action >
[-0.02144029 -0.04997231]
< returned_observation >
[ 0.08446819  0.08092264]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1151 #########################################
< action >
[-0.02882161 -0.05      ]
< returned_observation >
[ 0.05564659  0.03092264]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1152 #########################################
< action >
[-0.03304553 -0.05      ]
< returned_observation >
[ 0.02260105  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1153 #########################################
< action >
[-0.03483256 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 51 infomation #####################
{'nb_episode_steps': 4, 'min_reward': -11.5, 'episode_reward': -30.7, 'ave_reward': -7.675, 'nb_steps': 1154, 'max_reward': 2.8000000000000007}
######################################### STEP 1154 #########################################
< action >
[ 0.01546161 -0.05      ]
< returned_observation >
[ 0.33744222  0.61156434]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1155 #########################################
< action >
[ 0.01232062 -0.04861078]
< returned_observation >
[ 0.34976284  0.56295356]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1156 #########################################
< action >
[ 0.01059768 -0.04880778]
< returned_observation >
[ 0.36036052  0.51414578]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1157 #########################################
< action >
[ 0.00618062 -0.04859251]
< returned_observation >
[ 0.36654114  0.46555327]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1158 #########################################
< action >
[ 0.00201774 -0.04757234]
< returned_observation >
[ 0.36855888  0.41798093]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1159 #########################################
< action >
[-0.00296081 -0.04582811]
< returned_observation >
[ 0.36559807  0.37215282]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1160 #########################################
< action >
[-0.00900679 -0.04452435]
< returned_observation >
[ 0.35659128  0.32762847]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1161 #########################################
< action >
[-0.01724656 -0.04319423]
< returned_observation >
[ 0.33934472  0.28443424]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1162 #########################################
< action >
[-0.02380398 -0.04286023]
< returned_observation >
[ 0.31554074  0.24157401]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1163 #########################################
< action >
[-0.02877231 -0.04152664]
< returned_observation >
[ 0.28676843  0.20004737]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 1164 #########################################
< action >
[-0.03133768 -0.04020068]
< returned_observation >
[ 0.25543075  0.15984669]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1165 #########################################
< action >
[-0.03425302 -0.0392073 ]
< returned_observation >
[ 0.22117773  0.12063939]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1166 #########################################
< action >
[-0.03601789 -0.03787312]
< returned_observation >
[ 0.18515984  0.08276627]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1167 #########################################
< action >
[-0.03809143 -0.03815202]
< returned_observation >
[ 0.14706841  0.04461425]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1168 #########################################
< action >
[-0.03981974 -0.03668247]
< returned_observation >
[ 0.10724868  0.00793178]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1169 #########################################
< action >
[-0.04154569 -0.03771365]
< returned_observation >
[ 0.06570299  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1170 #########################################
< action >
[-0.04005123 -0.03910094]
< returned_observation >
[ 0.02565176  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1171 #########################################
< action >
[-0.03907187 -0.03912063]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 52 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -11.5, 'episode_reward': -130.09999999999997, 'ave_reward': -7.227777777777776, 'nb_steps': 1172, 'max_reward': 3.6999999999999993}
######################################### STEP 1172 #########################################
< action >
[-0.03361999 -0.04883446]
< returned_observation >
[ 0.81288623  0.50442288]
< reward >
-14.0
< running_reward >
-4.2
< done >
False
######################################### STEP 1173 #########################################
< action >
[-0.03752734 -0.04870708]
< returned_observation >
[ 0.7753589   0.45571581]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1174 #########################################
< action >
[-0.03887631 -0.04769051]
< returned_observation >
[ 0.73648258  0.4080253 ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1175 #########################################
< action >
[-0.03984175 -0.04777998]
< returned_observation >
[ 0.69664083  0.36024532]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1176 #########################################
< action >
[-0.04018217 -0.04562011]
< returned_observation >
[ 0.65645866  0.31462522]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1177 #########################################
< action >
[-0.04001066 -0.04533133]
< returned_observation >
[ 0.616448    0.26929389]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1178 #########################################
< action >
[-0.0419081  -0.04527265]
< returned_observation >
[ 0.5745399   0.22402124]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1179 #########################################
< action >
[-0.04277505 -0.04466525]
< returned_observation >
[ 0.53176486  0.17935598]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1180 #########################################
< action >
[-0.04315668 -0.04503385]
< returned_observation >
[ 0.48860817  0.13432213]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1181 #########################################
< action >
[-0.0451379  -0.04600702]
< returned_observation >
[ 0.44347027  0.08831512]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1182 #########################################
< action >
[-0.04532055 -0.04691123]
< returned_observation >
[ 0.39814972  0.04140389]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1183 #########################################
< action >
[-0.04646024 -0.04716608]
< returned_observation >
[ 0.35168948  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1184 #########################################
< action >
[-0.0464397  -0.04847971]
< returned_observation >
[ 0.30524978  0.        ]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1185 #########################################
< action >
[-0.04655953 -0.05      ]
< returned_observation >
[ 0.25869025  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1186 #########################################
< action >
[-0.04507908 -0.05      ]
< returned_observation >
[ 0.21361118  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1187 #########################################
< action >
[-0.04400004 -0.05      ]
< returned_observation >
[ 0.16961114  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1188 #########################################
< action >
[-0.04439919 -0.05      ]
< returned_observation >
[ 0.12521195  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1189 #########################################
< action >
[-0.0426393 -0.05     ]
< returned_observation >
[ 0.08257265  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1190 #########################################
< action >
[-0.04062739 -0.05      ]
< returned_observation >
[ 0.04194526  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1191 #########################################
< action >
[-0.03833385 -0.05      ]
< returned_observation >
[ 0.00361141  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1192 #########################################
< action >
[-0.03707339 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 53 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -14.0, 'episode_reward': -191.3, 'ave_reward': -9.109523809523811, 'nb_steps': 1193, 'max_reward': 3.5}
######################################### STEP 1193 #########################################
< action >
[-0.03598505 -0.05      ]
< returned_observation >
[ 0.81846744  0.33483781]
< reward >
-13.2
< running_reward >
-3.9599999999999995
< done >
False
######################################### STEP 1194 #########################################
< action >
[-0.04013886 -0.05      ]
< returned_observation >
[ 0.77832858  0.28483781]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 1195 #########################################
< action >
[-0.04355651 -0.05      ]
< returned_observation >
[ 0.73477207  0.23483781]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1196 #########################################
< action >
[-0.04740721 -0.05      ]
< returned_observation >
[ 0.68736486  0.18483781]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1197 #########################################
< action >
[-0.04667424 -0.05      ]
< returned_observation >
[ 0.64069062  0.13483781]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1198 #########################################
< action >
[-0.04686061 -0.05      ]
< returned_observation >
[ 0.59383     0.08483781]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1199 #########################################
< action >
[-0.04733479 -0.05      ]
< returned_observation >
[ 0.54649521  0.03483781]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1200 #########################################
< action >
[-0.04820199 -0.05      ]
< returned_observation >
[ 0.49829322  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1201 #########################################
< action >
[-0.04745814 -0.05      ]
< returned_observation >
[ 0.45083509  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1202 #########################################
< action >
[-0.04627829 -0.04972732]
< returned_observation >
[ 0.4045568  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1203 #########################################
< action >
[-0.04689189 -0.04979228]
< returned_observation >
[ 0.35766491  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1204 #########################################
< action >
[-0.04750251 -0.05      ]
< returned_observation >
[ 0.3101624  0.       ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1205 #########################################
< action >
[-0.04774376 -0.05      ]
< returned_observation >
[ 0.26241864  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1206 #########################################
< action >
[-0.04877095 -0.05      ]
< returned_observation >
[ 0.21364769  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1207 #########################################
< action >
[-0.04895666 -0.05      ]
< returned_observation >
[ 0.16469102  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1208 #########################################
< action >
[-0.04674367 -0.05      ]
< returned_observation >
[ 0.11794736  0.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1209 #########################################
< action >
[-0.04593017 -0.04995267]
< returned_observation >
[ 0.07201718  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1210 #########################################
< action >
[-0.04519516 -0.04972966]
< returned_observation >
[ 0.02682202  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1211 #########################################
< action >
[-0.04270042 -0.0497708 ]
< returned_observation >
[ 0.  0.]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
True
##################### episode 54 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -13.2, 'episode_reward': -162.29999999999995, 'ave_reward': -8.542105263157893, 'nb_steps': 1212, 'max_reward': 3.1999999999999993}
######################################### STEP 1212 #########################################
< action >
[ 0.00533256 -0.04949515]
< returned_observation >
[ 0.32212046  0.30476953]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1213 #########################################
< action >
[ 0.00140395 -0.0496332 ]
< returned_observation >
[ 0.3235244   0.25513633]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1214 #########################################
< action >
[-0.00482969 -0.04865259]
< returned_observation >
[ 0.31869471  0.20648374]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1215 #########################################
< action >
[-0.01917016 -0.04632639]
< returned_observation >
[ 0.29952455  0.16015735]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1216 #########################################
< action >
[-0.02862932 -0.04638761]
< returned_observation >
[ 0.27089523  0.11376974]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1217 #########################################
< action >
[-0.03432836 -0.04677827]
< returned_observation >
[ 0.23656687  0.06699147]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1218 #########################################
< action >
[-0.04023646 -0.04836132]
< returned_observation >
[ 0.19633041  0.01863015]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1219 #########################################
< action >
[-0.04360205 -0.05      ]
< returned_observation >
[ 0.15272836  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1220 #########################################
< action >
[-0.0443802 -0.05     ]
< returned_observation >
[ 0.10834817  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1221 #########################################
< action >
[-0.04287824 -0.04979995]
< returned_observation >
[ 0.06546993  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1222 #########################################
< action >
[-0.04274988 -0.04970076]
< returned_observation >
[ 0.02272005  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1223 #########################################
< action >
[-0.04045416 -0.04963007]
< returned_observation >
[ 0.  0.]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
True
##################### episode 55 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.600000000000001, 'episode_reward': -106.79999999999998, 'ave_reward': -8.899999999999999, 'nb_steps': 1224, 'max_reward': 3.5}
######################################### STEP 1224 #########################################
< action >
[ 0.02214746 -0.04915224]
< returned_observation >
[ 0.19322929  0.77996039]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1225 #########################################
< action >
[ 0.0201557 -0.05     ]
< returned_observation >
[ 0.21338499  0.72996039]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1226 #########################################
< action >
[ 0.01802477 -0.05      ]
< returned_observation >
[ 0.23140975  0.67996039]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1227 #########################################
< action >
[ 0.01407543 -0.05      ]
< returned_observation >
[ 0.24548518  0.62996039]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1228 #########################################
< action >
[ 0.0125835 -0.05     ]
< returned_observation >
[ 0.25806868  0.57996039]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1229 #########################################
< action >
[ 0.00983305 -0.04833038]
< returned_observation >
[ 0.26790173  0.53163001]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1230 #########################################
< action >
[ 0.00588408 -0.04804387]
< returned_observation >
[ 0.27378581  0.48358614]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1231 #########################################
< action >
[ 0.00433252 -0.04584934]
< returned_observation >
[ 0.27811833  0.4377368 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1232 #########################################
< action >
[ 0.00083509 -0.04721119]
< returned_observation >
[ 0.27895342  0.3905256 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1233 #########################################
< action >
[-0.00313673 -0.05      ]
< returned_observation >
[ 0.27581669  0.3405256 ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1234 #########################################
< action >
[-0.00489719 -0.05      ]
< returned_observation >
[ 0.2709195  0.2905256]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1235 #########################################
< action >
[-0.01031101 -0.05      ]
< returned_observation >
[ 0.26060849  0.2405256 ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1236 #########################################
< action >
[-0.02215973 -0.05      ]
< returned_observation >
[ 0.23844877  0.1905256 ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1237 #########################################
< action >
[-0.03339157 -0.05      ]
< returned_observation >
[ 0.2050572  0.1405256]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1238 #########################################
< action >
[-0.03957897 -0.04944623]
< returned_observation >
[ 0.16547823  0.09107937]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1239 #########################################
< action >
[-0.04454752 -0.05      ]
< returned_observation >
[ 0.12093071  0.04107937]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1240 #########################################
< action >
[-0.04851027 -0.04994594]
< returned_observation >
[ 0.07242043  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1241 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.02242043  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1242 #########################################
< action >
[-0.0498889 -0.05     ]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 56 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -12.100000000000001, 'episode_reward': -74.8, 'ave_reward': -3.9368421052631577, 'nb_steps': 1243, 'max_reward': 3.5}
######################################### STEP 1243 #########################################
< action >
[ 0.01100322 -0.05      ]
< returned_observation >
[ 0.34967407  0.50237008]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1244 #########################################
< action >
[ 0.00878871 -0.04914615]
< returned_observation >
[ 0.35846278  0.45322393]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1245 #########################################
< action >
[ 0.00530671 -0.04840775]
< returned_observation >
[ 0.36376949  0.40481618]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1246 #########################################
< action >
[ 0.00280653 -0.04724178]
< returned_observation >
[ 0.36657602  0.3575744 ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1247 #########################################
< action >
[-0.00148348 -0.04635516]
< returned_observation >
[ 0.36509254  0.31121924]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1248 #########################################
< action >
[-0.0065588  -0.04582159]
< returned_observation >
[ 0.35853373  0.26539764]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1249 #########################################
< action >
[-0.01787683 -0.04682264]
< returned_observation >
[ 0.34065691  0.218575  ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1250 #########################################
< action >
[-0.03244634 -0.04708144]
< returned_observation >
[ 0.30821056  0.17149357]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1251 #########################################
< action >
[-0.04038806 -0.04719502]
< returned_observation >
[ 0.2678225   0.12429855]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1252 #########################################
< action >
[-0.04580917 -0.0470918 ]
< returned_observation >
[ 0.22201333  0.07720675]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1253 #########################################
< action >
[-0.04837185 -0.04798494]
< returned_observation >
[ 0.17364148  0.02922181]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1254 #########################################
< action >
[-0.04896871 -0.05      ]
< returned_observation >
[ 0.12467277  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1255 #########################################
< action >
[-0.05       -0.04963897]
< returned_observation >
[ 0.07467277  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1256 #########################################
< action >
[-0.05       -0.04960023]
< returned_observation >
[ 0.02467277  0.        ]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1257 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
True
##################### episode 57 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -12.600000000000001, 'episode_reward': -103.9, 'ave_reward': -6.926666666666667, 'nb_steps': 1258, 'max_reward': 3.5}
######################################### STEP 1258 #########################################
< action >
[  2.45332718e-05  -5.00000000e-02]
< returned_observation >
[ 0.578576    0.47153306]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 1259 #########################################
< action >
[-0.00448377 -0.05      ]
< returned_observation >
[ 0.57409223  0.42153306]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1260 #########################################
< action >
[-0.00965707 -0.05      ]
< returned_observation >
[ 0.56443517  0.37153306]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1261 #########################################
< action >
[-0.01638951 -0.05      ]
< returned_observation >
[ 0.54804566  0.32153306]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1262 #########################################
< action >
[-0.02537621 -0.05      ]
< returned_observation >
[ 0.52266945  0.27153306]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1263 #########################################
< action >
[-0.0381824 -0.05     ]
< returned_observation >
[ 0.48448705  0.22153306]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1264 #########################################
< action >
[-0.04495266 -0.05      ]
< returned_observation >
[ 0.43953439  0.17153306]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1265 #########################################
< action >
[-0.04986846 -0.05      ]
< returned_observation >
[ 0.38966593  0.12153306]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 1266 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.33966593  0.07153306]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1267 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.28966593  0.02153306]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1268 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.23966593  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1269 #########################################
< action >
[-0.05       -0.04983112]
< returned_observation >
[ 0.18966593  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1270 #########################################
< action >
[-0.05       -0.04923945]
< returned_observation >
[ 0.13966593  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1271 #########################################
< action >
[-0.05      -0.0491143]
< returned_observation >
[ 0.08966593  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1272 #########################################
< action >
[-0.05      -0.0473402]
< returned_observation >
[ 0.03966593  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1273 #########################################
< action >
[-0.05       -0.04858619]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 58 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -13.899999999999999, 'episode_reward': -136.2, 'ave_reward': -8.5125, 'nb_steps': 1274, 'max_reward': 1.6000000000000014}
######################################### STEP 1274 #########################################
< action >
[ 0.02884083 -0.05      ]
< returned_observation >
[ 0.03152889  0.93834542]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1275 #########################################
< action >
[ 0.02691323 -0.04941145]
< returned_observation >
[ 0.05844212  0.88893397]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1276 #########################################
< action >
[ 0.027339 -0.05    ]
< returned_observation >
[ 0.08578112  0.83893397]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1277 #########################################
< action >
[ 0.02604618 -0.05      ]
< returned_observation >
[ 0.1118273   0.78893397]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1278 #########################################
< action >
[ 0.0244854 -0.05     ]
< returned_observation >
[ 0.13631271  0.73893397]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1279 #########################################
< action >
[ 0.02401191 -0.05      ]
< returned_observation >
[ 0.16032462  0.68893397]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1280 #########################################
< action >
[ 0.02261235 -0.05      ]
< returned_observation >
[ 0.18293697  0.63893397]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1281 #########################################
< action >
[ 0.02033772 -0.05      ]
< returned_observation >
[ 0.20327469  0.58893397]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1282 #########################################
< action >
[ 0.01860297 -0.05      ]
< returned_observation >
[ 0.22187766  0.53893397]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1283 #########################################
< action >
[ 0.01736625 -0.05      ]
< returned_observation >
[ 0.23924391  0.48893397]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1284 #########################################
< action >
[ 0.01535632 -0.05      ]
< returned_observation >
[ 0.25460023  0.43893397]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1285 #########################################
< action >
[ 0.01322187 -0.05      ]
< returned_observation >
[ 0.2678221   0.38893397]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1286 #########################################
< action >
[ 0.0114069 -0.05     ]
< returned_observation >
[ 0.279229    0.33893397]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1287 #########################################
< action >
[ 0.00831214 -0.05      ]
< returned_observation >
[ 0.28754114  0.28893397]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1288 #########################################
< action >
[ 0.00329905 -0.05      ]
< returned_observation >
[ 0.29084019  0.23893397]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1289 #########################################
< action >
[-0.00859406 -0.05      ]
< returned_observation >
[ 0.28224613  0.18893397]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1290 #########################################
< action >
[-0.02640163 -0.05      ]
< returned_observation >
[ 0.25584451  0.13893397]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1291 #########################################
< action >
[-0.03522981 -0.05      ]
< returned_observation >
[ 0.22061469  0.08893397]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1292 #########################################
< action >
[-0.03835761 -0.05      ]
< returned_observation >
[ 0.18225709  0.03893397]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1293 #########################################
< action >
[-0.04121442 -0.05      ]
< returned_observation >
[ 0.14104267  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1294 #########################################
< action >
[-0.04188547 -0.05      ]
< returned_observation >
[ 0.0991572  0.       ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1295 #########################################
< action >
[-0.04222894 -0.05      ]
< returned_observation >
[ 0.05692826  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1296 #########################################
< action >
[-0.04112785 -0.05      ]
< returned_observation >
[ 0.01580041  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1297 #########################################
< action >
[-0.03990152 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 59 infomation #####################
{'nb_episode_steps': 24, 'min_reward': -12.2, 'episode_reward': -161.20000000000002, 'ave_reward': -6.716666666666668, 'nb_steps': 1298, 'max_reward': 3.5}
######################################### STEP 1298 #########################################
< action >
[-0.04611038 -0.05      ]
< returned_observation >
[ 0.8592312   0.15763586]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1299 #########################################
< action >
[-0.04855796 -0.05      ]
< returned_observation >
[ 0.81067324  0.10763586]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1300 #########################################
< action >
[-0.04912923 -0.05      ]
< returned_observation >
[ 0.76154401  0.05763586]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1301 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.71154401  0.00763586]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1302 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.66154401  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1303 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.61154401  0.        ]
< reward >
-14.399999999999999
< running_reward >
-4.319999999999999
< done >
False
######################################### STEP 1304 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.56154401  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1305 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.51154401  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1306 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.46154401  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1307 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.41154401  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1308 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.36154401  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1309 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.31154401  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1310 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.26154401  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1311 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.21154401  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1312 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.16154401  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1313 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.11154401  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1314 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.06154401  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1315 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.01154401  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1316 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.7
< running_reward >
-3.51
< done >
True
##################### episode 60 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -14.399999999999999, 'episode_reward': -193.5, 'ave_reward': -10.18421052631579, 'nb_steps': 1317, 'max_reward': 3.6000000000000014}
######################################### STEP 1317 #########################################
< action >
[ 0.0053856  -0.04900363]
< returned_observation >
[ 0.29787501  0.47100652]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1318 #########################################
< action >
[ 0.00498965 -0.04885249]
< returned_observation >
[ 0.30286466  0.42215403]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1319 #########################################
< action >
[ 0.00079359 -0.04959436]
< returned_observation >
[ 0.30365826  0.37255968]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1320 #########################################
< action >
[-0.00309924 -0.05      ]
< returned_observation >
[ 0.30055902  0.32255968]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1321 #########################################
< action >
[-0.00861192 -0.04868832]
< returned_observation >
[ 0.2919471   0.27387136]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1322 #########################################
< action >
[-0.01823317 -0.05      ]
< returned_observation >
[ 0.27371393  0.22387136]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1323 #########################################
< action >
[-0.03468172 -0.05      ]
< returned_observation >
[ 0.23903221  0.17387136]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 1324 #########################################
< action >
[-0.04392035 -0.05      ]
< returned_observation >
[ 0.19511186  0.12387136]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1325 #########################################
< action >
[-0.0484414 -0.05     ]
< returned_observation >
[ 0.14667046  0.07387136]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1326 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.09667046  0.02387136]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1327 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.04667046  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1328 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
2.5
< running_reward >
0.75
< done >
True
##################### episode 61 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -13.399999999999999, 'episode_reward': -121.89999999999998, 'ave_reward': -10.158333333333331, 'nb_steps': 1329, 'max_reward': 2.5}
######################################### STEP 1329 #########################################
< action >
[ 0.0053286  -0.04929916]
< returned_observation >
[ 0.90723997  0.93433172]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 1330 #########################################
< action >
[ 0.00479497 -0.05      ]
< returned_observation >
[ 0.91203495  0.88433172]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1331 #########################################
< action >
[ 0.00402219 -0.05      ]
< returned_observation >
[ 0.91605714  0.83433172]
< reward >
0.10000000000000142
< running_reward >
0.030000000000000426
< done >
False
######################################### STEP 1332 #########################################
< action >
[ 0.00080184 -0.05      ]
< returned_observation >
[ 0.91685898  0.78433172]
< reward >
-1.3999999999999986
< running_reward >
-0.41999999999999954
< done >
False
######################################### STEP 1333 #########################################
< action >
[-0.00094194 -0.04955625]
< returned_observation >
[ 0.91591704  0.73477547]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1334 #########################################
< action >
[-0.00394813 -0.05      ]
< returned_observation >
[ 0.91196891  0.68477547]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1335 #########################################
< action >
[-0.00423996 -0.05      ]
< returned_observation >
[ 0.90772895  0.63477547]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1336 #########################################
< action >
[-0.00673806 -0.04952353]
< returned_observation >
[ 0.90099089  0.58525195]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1337 #########################################
< action >
[-0.01072217 -0.04772546]
< returned_observation >
[ 0.89026871  0.53752649]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1338 #########################################
< action >
[-0.01601081 -0.04797009]
< returned_observation >
[ 0.87425791  0.4895564 ]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1339 #########################################
< action >
[-0.01939358 -0.04712473]
< returned_observation >
[ 0.85486432  0.44243167]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1340 #########################################
< action >
[-0.02354037 -0.04580828]
< returned_observation >
[ 0.83132395  0.39662339]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1341 #########################################
< action >
[-0.03085978 -0.0455098 ]
< returned_observation >
[ 0.80046417  0.35111359]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1342 #########################################
< action >
[-0.03837048 -0.04567081]
< returned_observation >
[ 0.76209369  0.30544278]
< reward >
-13.8
< running_reward >
-4.14
< done >
False
######################################### STEP 1343 #########################################
< action >
[-0.04406924 -0.04665282]
< returned_observation >
[ 0.71802444  0.25878996]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1344 #########################################
< action >
[-0.04661255 -0.04617476]
< returned_observation >
[ 0.67141189  0.2126152 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1345 #########################################
< action >
[-0.0487666  -0.04793816]
< returned_observation >
[ 0.62264529  0.16467704]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1346 #########################################
< action >
[-0.05       -0.04819548]
< returned_observation >
[ 0.57264529  0.11648156]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1347 #########################################
< action >
[-0.05      -0.0477908]
< returned_observation >
[ 0.52264529  0.06869075]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1348 #########################################
< action >
[-0.05       -0.04821701]
< returned_observation >
[ 0.47264529  0.02047375]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1349 #########################################
< action >
[-0.05       -0.04791566]
< returned_observation >
[ 0.42264529  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1350 #########################################
< action >
[-0.05      -0.0479998]
< returned_observation >
[ 0.37264529  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1351 #########################################
< action >
[-0.05       -0.04836668]
< returned_observation >
[ 0.32264529  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1352 #########################################
< action >
[-0.05       -0.04822022]
< returned_observation >
[ 0.27264529  0.        ]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 1353 #########################################
< action >
[-0.05       -0.04722511]
< returned_observation >
[ 0.22264529  0.        ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1354 #########################################
< action >
[-0.05       -0.04685975]
< returned_observation >
[ 0.17264529  0.        ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1355 #########################################
< action >
[-0.05       -0.04934907]
< returned_observation >
[ 0.12264529  0.        ]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1356 #########################################
< action >
[-0.05       -0.04795391]
< returned_observation >
[ 0.07264529  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1357 #########################################
< action >
[-0.05       -0.04598108]
< returned_observation >
[ 0.02264529  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1358 #########################################
< action >
[-0.05       -0.04501056]
< returned_observation >
[ 0.  0.]
< reward >
-11.7
< running_reward >
-3.51
< done >
True
##################### episode 62 infomation #####################
{'nb_episode_steps': 30, 'min_reward': -13.8, 'episode_reward': -195.29999999999998, 'ave_reward': -6.51, 'nb_steps': 1359, 'max_reward': 3.6000000000000014}
######################################### STEP 1359 #########################################
< action >
[ 0.01033067 -0.05      ]
< returned_observation >
[ 0.26787274  0.51435904]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1360 #########################################
< action >
[ 0.00894888 -0.05      ]
< returned_observation >
[ 0.27682162  0.46435904]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1361 #########################################
< action >
[ 0.00792696 -0.05      ]
< returned_observation >
[ 0.28474858  0.41435904]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1362 #########################################
< action >
[ 0.00658876 -0.05      ]
< returned_observation >
[ 0.29133734  0.36435904]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1363 #########################################
< action >
[ 0.00460308 -0.05      ]
< returned_observation >
[ 0.29594042  0.31435904]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1364 #########################################
< action >
[ 0.00032946 -0.05      ]
< returned_observation >
[ 0.29626988  0.26435904]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1365 #########################################
< action >
[-0.0214147 -0.05     ]
< returned_observation >
[ 0.27485518  0.21435904]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1366 #########################################
< action >
[-0.03533158 -0.05      ]
< returned_observation >
[ 0.2395236   0.16435904]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1367 #########################################
< action >
[-0.04075867 -0.05      ]
< returned_observation >
[ 0.19876493  0.11435904]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1368 #########################################
< action >
[-0.04208095 -0.05      ]
< returned_observation >
[ 0.15668398  0.06435904]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1369 #########################################
< action >
[-0.04218949 -0.05      ]
< returned_observation >
[ 0.11449449  0.01435904]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1370 #########################################
< action >
[-0.04252486 -0.05      ]
< returned_observation >
[ 0.07196964  0.        ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1371 #########################################
< action >
[-0.04360914 -0.05      ]
< returned_observation >
[ 0.02836049  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1372 #########################################
< action >
[-0.04319249 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
True
##################### episode 63 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.100000000000001, 'episode_reward': -89.2, 'ave_reward': -6.371428571428572, 'nb_steps': 1373, 'max_reward': 3.3000000000000007}
######################################### STEP 1373 #########################################
< action >
[-0.0159637 -0.05     ]
< returned_observation >
[ 0.79100498  0.34437005]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1374 #########################################
< action >
[-0.02682783 -0.05      ]
< returned_observation >
[ 0.76417715  0.29437005]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1375 #########################################
< action >
[-0.03947871 -0.05      ]
< returned_observation >
[ 0.72469844  0.24437005]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1376 #########################################
< action >
[-0.04445139 -0.05      ]
< returned_observation >
[ 0.68024705  0.19437005]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1377 #########################################
< action >
[-0.0468069 -0.05     ]
< returned_observation >
[ 0.63344015  0.14437005]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1378 #########################################
< action >
[-0.04596381 -0.05      ]
< returned_observation >
[ 0.58747634  0.09437005]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1379 #########################################
< action >
[-0.0473349 -0.05     ]
< returned_observation >
[ 0.54014145  0.04437005]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1380 #########################################
< action >
[-0.0466154 -0.05     ]
< returned_observation >
[ 0.49352604  0.        ]
< reward >
-13.0
< running_reward >
-3.9
< done >
False
######################################### STEP 1381 #########################################
< action >
[-0.04779106 -0.05      ]
< returned_observation >
[ 0.44573499  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1382 #########################################
< action >
[-0.04656341 -0.05      ]
< returned_observation >
[ 0.39917158  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1383 #########################################
< action >
[-0.04864403 -0.04906049]
< returned_observation >
[ 0.35052755  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1384 #########################################
< action >
[-0.05       -0.04916981]
< returned_observation >
[ 0.30052755  0.        ]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1385 #########################################
< action >
[-0.05       -0.04754692]
< returned_observation >
[ 0.25052755  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1386 #########################################
< action >
[-0.05       -0.04762015]
< returned_observation >
[ 0.20052755  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1387 #########################################
< action >
[-0.04937822 -0.04729727]
< returned_observation >
[ 0.15114932  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1388 #########################################
< action >
[-0.04878266 -0.04776457]
< returned_observation >
[ 0.10236666  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1389 #########################################
< action >
[-0.04858226 -0.04703735]
< returned_observation >
[ 0.0537844  0.       ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1390 #########################################
< action >
[-0.04856764 -0.04540399]
< returned_observation >
[ 0.00521676  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1391 #########################################
< action >
[-0.04632063 -0.0457475 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
True
##################### episode 64 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -13.0, 'episode_reward': -165.1, 'ave_reward': -8.689473684210526, 'nb_steps': 1392, 'max_reward': 3.6000000000000014}
######################################### STEP 1392 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.68107304  0.11106901]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1393 #########################################
< action >
[-0.04982756 -0.05      ]
< returned_observation >
[ 0.63124548  0.06106901]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1394 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.58124548  0.01106901]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1395 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.53124548  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1396 #########################################
< action >
[-0.04860476 -0.05      ]
< returned_observation >
[ 0.48264072  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1397 #########################################
< action >
[-0.04866283 -0.05      ]
< returned_observation >
[ 0.4339779  0.       ]
< reward >
-14.3
< running_reward >
-4.29
< done >
False
######################################### STEP 1398 #########################################
< action >
[-0.04936413 -0.05      ]
< returned_observation >
[ 0.38461377  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1399 #########################################
< action >
[-0.04860931 -0.05      ]
< returned_observation >
[ 0.33600446  0.        ]
< reward >
0.0
< running_reward >
0.0
< done >
False
######################################### STEP 1400 #########################################
< action >
[-0.04844109 -0.05      ]
< returned_observation >
[ 0.28756337  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1401 #########################################
< action >
[-0.0493085 -0.05     ]
< returned_observation >
[ 0.23825487  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1402 #########################################
< action >
[-0.04704179 -0.05      ]
< returned_observation >
[ 0.19121308  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1403 #########################################
< action >
[-0.04669607 -0.05      ]
< returned_observation >
[ 0.14451701  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1404 #########################################
< action >
[-0.04886833 -0.05      ]
< returned_observation >
[ 0.09564869  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1405 #########################################
< action >
[-0.04938064 -0.05      ]
< returned_observation >
[ 0.04626805  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1406 #########################################
< action >
[-0.0487171 -0.05     ]
< returned_observation >
[ 0.  0.]
< reward >
-11.8
< running_reward >
-3.54
< done >
True
##################### episode 65 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -14.3, 'episode_reward': -164.2, 'ave_reward': -10.946666666666665, 'nb_steps': 1407, 'max_reward': 0.0}
######################################### STEP 1407 #########################################
< action >
[ 0.02038747 -0.04993438]
< returned_observation >
[ 0.62108604  0.81593008]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1408 #########################################
< action >
[ 0.01833061 -0.04988013]
< returned_observation >
[ 0.63941665  0.76604995]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1409 #########################################
< action >
[ 0.01825997 -0.04860177]
< returned_observation >
[ 0.65767662  0.71744817]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1410 #########################################
< action >
[ 0.01765289 -0.04840225]
< returned_observation >
[ 0.67532951  0.66904592]
< reward >
-14.100000000000001
< running_reward >
-4.23
< done >
False
######################################### STEP 1411 #########################################
< action >
[ 0.01767508 -0.04790359]
< returned_observation >
[ 0.69300459  0.62114232]
< reward >
-0.6000000000000014
< running_reward >
-0.1800000000000004
< done >
False
######################################### STEP 1412 #########################################
< action >
[ 0.01639515 -0.04879955]
< returned_observation >
[ 0.70939974  0.57234277]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 1413 #########################################
< action >
[ 0.01483234 -0.04842348]
< returned_observation >
[ 0.72423208  0.5239193 ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1414 #########################################
< action >
[ 0.01064767 -0.04701112]
< returned_observation >
[ 0.73487975  0.47690818]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1415 #########################################
< action >
[ 0.00973352 -0.04645806]
< returned_observation >
[ 0.74461327  0.43045012]
< reward >
-0.1999999999999993
< running_reward >
-0.05999999999999978
< done >
False
######################################### STEP 1416 #########################################
< action >
[ 0.0073184  -0.04648988]
< returned_observation >
[ 0.75193167  0.38396024]
< reward >
-0.3999999999999986
< running_reward >
-0.11999999999999957
< done >
False
######################################### STEP 1417 #########################################
< action >
[ 0.00246626 -0.0468512 ]
< returned_observation >
[ 0.75439792  0.33710903]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1418 #########################################
< action >
[-0.00293629 -0.04669919]
< returned_observation >
[ 0.75146164  0.29040984]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1419 #########################################
< action >
[-0.01030834 -0.04772998]
< returned_observation >
[ 0.74115329  0.24267986]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1420 #########################################
< action >
[-0.02528713 -0.04719647]
< returned_observation >
[ 0.71586616  0.19548339]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1421 #########################################
< action >
[-0.04113376 -0.04714927]
< returned_observation >
[ 0.6747324   0.14833412]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1422 #########################################
< action >
[-0.04760936 -0.04548276]
< returned_observation >
[ 0.62712305  0.10285136]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1423 #########################################
< action >
[-0.04988662 -0.04528098]
< returned_observation >
[ 0.57723643  0.05757038]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1424 #########################################
< action >
[-0.05       -0.04390727]
< returned_observation >
[ 0.52723643  0.01366311]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1425 #########################################
< action >
[-0.05       -0.04322636]
< returned_observation >
[ 0.47723643  0.        ]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 1426 #########################################
< action >
[-0.05       -0.04241308]
< returned_observation >
[ 0.42723643  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1427 #########################################
< action >
[-0.05       -0.04243003]
< returned_observation >
[ 0.37723643  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1428 #########################################
< action >
[-0.05      -0.0438887]
< returned_observation >
[ 0.32723643  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1429 #########################################
< action >
[-0.05       -0.04303751]
< returned_observation >
[ 0.27723643  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1430 #########################################
< action >
[-0.05       -0.04331466]
< returned_observation >
[ 0.22723643  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1431 #########################################
< action >
[-0.05       -0.04284632]
< returned_observation >
[ 0.17723643  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1432 #########################################
< action >
[-0.05       -0.04221086]
< returned_observation >
[ 0.12723643  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1433 #########################################
< action >
[-0.05       -0.04155337]
< returned_observation >
[ 0.07723643  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1434 #########################################
< action >
[-0.05       -0.04086362]
< returned_observation >
[ 0.02723643  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1435 #########################################
< action >
[-0.05       -0.04076293]
< returned_observation >
[ 0.  0.]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
True
##################### episode 66 infomation #####################
{'nb_episode_steps': 29, 'min_reward': -14.100000000000001, 'episode_reward': -269.79999999999995, 'ave_reward': -9.303448275862067, 'nb_steps': 1436, 'max_reward': 3.5}
######################################### STEP 1436 #########################################
< action >
[-0.05      -0.0481713]
< returned_observation >
[ 0.93352161  0.03119449]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 1437 #########################################
< action >
[-0.04938522 -0.04933108]
< returned_observation >
[ 0.88413639  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1438 #########################################
< action >
[-0.04850372 -0.04861743]
< returned_observation >
[ 0.83563267  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1439 #########################################
< action >
[-0.04712409 -0.04885583]
< returned_observation >
[ 0.78850858  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1440 #########################################
< action >
[-0.04717893 -0.05      ]
< returned_observation >
[ 0.74132965  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1441 #########################################
< action >
[-0.04944503 -0.05      ]
< returned_observation >
[ 0.69188463  0.        ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 1442 #########################################
< action >
[-0.0493205 -0.05     ]
< returned_observation >
[ 0.64256412  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1443 #########################################
< action >
[-0.04988601 -0.05      ]
< returned_observation >
[ 0.59267811  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1444 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.54267811  0.        ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1445 #########################################
< action >
[-0.04914592 -0.0490655 ]
< returned_observation >
[ 0.49353219  0.        ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1446 #########################################
< action >
[-0.04987975 -0.04638276]
< returned_observation >
[ 0.44365245  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1447 #########################################
< action >
[-0.0488219  -0.04630791]
< returned_observation >
[ 0.39483054  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1448 #########################################
< action >
[-0.04871693 -0.0443388 ]
< returned_observation >
[ 0.34611362  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1449 #########################################
< action >
[-0.04841993 -0.03970462]
< returned_observation >
[ 0.29769369  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1450 #########################################
< action >
[-0.04776536 -0.03621188]
< returned_observation >
[ 0.24992832  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1451 #########################################
< action >
[-0.04862434 -0.03265991]
< returned_observation >
[ 0.20130398  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1452 #########################################
< action >
[-0.04668639 -0.0291688 ]
< returned_observation >
[ 0.15461759  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1453 #########################################
< action >
[-0.04677686 -0.02577984]
< returned_observation >
[ 0.10784073  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1454 #########################################
< action >
[-0.04619013 -0.02080269]
< returned_observation >
[ 0.0616506  0.       ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1455 #########################################
< action >
[-0.04587305 -0.01673829]
< returned_observation >
[ 0.01577755  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1456 #########################################
< action >
[-0.04481126 -0.01267357]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 67 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -12.600000000000001, 'episode_reward': -176.4, 'ave_reward': -8.4, 'nb_steps': 1457, 'max_reward': 3.6000000000000014}
######################################### STEP 1457 #########################################
< action >
[-0.04133661 -0.04429715]
< returned_observation >
[ 0.38701066  0.16024571]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1458 #########################################
< action >
[-0.04706824 -0.03878504]
< returned_observation >
[ 0.33994242  0.12146067]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1459 #########################################
< action >
[-0.04758107 -0.02809721]
< returned_observation >
[ 0.29236135  0.09336345]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1460 #########################################
< action >
[-0.04895266 -0.0163626 ]
< returned_observation >
[ 0.24340869  0.07700085]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1461 #########################################
< action >
[-0.05      -0.0060378]
< returned_observation >
[ 0.19340869  0.07096305]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1462 #########################################
< action >
[-0.05        0.00186293]
< returned_observation >
[ 0.14340869  0.07282598]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1463 #########################################
< action >
[-0.04893492  0.0050501 ]
< returned_observation >
[ 0.09447377  0.07787607]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1464 #########################################
< action >
[-0.04916776  0.00615653]
< returned_observation >
[ 0.04530601  0.0840326 ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 1465 #########################################
< action >
[-0.04962772  0.00932053]
< returned_observation >
[ 0.          0.09335314]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1466 #########################################
< action >
[-0.0498316   0.00937414]
< returned_observation >
[ 0.          0.10272727]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1467 #########################################
< action >
[-0.04808702  0.01078138]
< returned_observation >
[ 0.          0.11350865]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1468 #########################################
< action >
[-0.04791943  0.01165614]
< returned_observation >
[ 0.          0.12516478]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1469 #########################################
< action >
[-0.04883582  0.0113265 ]
< returned_observation >
[ 0.          0.13649129]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1470 #########################################
< action >
[-0.04753992  0.010977  ]
< returned_observation >
[ 0.          0.14746829]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1471 #########################################
< action >
[-0.04616463  0.01137975]
< returned_observation >
[ 0.          0.15884804]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1472 #########################################
< action >
[-0.04472452  0.01000187]
< returned_observation >
[ 0.          0.16884992]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1473 #########################################
< action >
[-0.0449346   0.00900669]
< returned_observation >
[ 0.          0.17785661]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1474 #########################################
< action >
[-0.04446874  0.00939001]
< returned_observation >
[ 0.          0.18724662]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1475 #########################################
< action >
[-0.04329835  0.01050051]
< returned_observation >
[ 0.          0.19774713]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1476 #########################################
< action >
[-0.04204178  0.01031412]
< returned_observation >
[ 0.          0.20806126]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1477 #########################################
< action >
[-0.04299491  0.01056049]
< returned_observation >
[ 0.          0.21862174]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1478 #########################################
< action >
[-0.04366997  0.01042781]
< returned_observation >
[ 0.          0.22904956]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1479 #########################################
< action >
[-0.04499452  0.01036102]
< returned_observation >
[ 0.          0.23941058]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1480 #########################################
< action >
[-0.04497868  0.00950959]
< returned_observation >
[ 0.          0.24892017]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1481 #########################################
< action >
[-0.04238011  0.01060579]
< returned_observation >
[ 0.          0.25952596]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1482 #########################################
< action >
[-0.04132709  0.00972787]
< returned_observation >
[ 0.          0.26925383]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1483 #########################################
< action >
[-0.04092173  0.00751624]
< returned_observation >
[ 0.          0.27677006]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1484 #########################################
< action >
[-0.04028475  0.00794562]
< returned_observation >
[ 0.          0.28471568]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1485 #########################################
< action >
[-0.03988241  0.00871   ]
< returned_observation >
[ 0.          0.29342568]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1486 #########################################
< action >
[-0.0390768   0.00913091]
< returned_observation >
[ 0.          0.30255659]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1487 #########################################
< action >
[-0.03930523  0.0103998 ]
< returned_observation >
[ 0.          0.31295639]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1488 #########################################
< action >
[-0.03944114  0.00974562]
< returned_observation >
[ 0.          0.32270201]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1489 #########################################
< action >
[-0.03732353  0.0077683 ]
< returned_observation >
[ 0.          0.33047031]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1490 #########################################
< action >
[-0.03650205  0.00668877]
< returned_observation >
[ 0.          0.33715908]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1491 #########################################
< action >
[-0.03637645  0.00673129]
< returned_observation >
[ 0.          0.34389036]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1492 #########################################
< action >
[-0.03840288  0.00515103]
< returned_observation >
[ 0.          0.34904139]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1493 #########################################
< action >
[-0.03780136  0.00409412]
< returned_observation >
[ 0.          0.35313551]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1494 #########################################
< action >
[-0.03952025  0.00537513]
< returned_observation >
[ 0.          0.35851065]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1495 #########################################
< action >
[-0.03779044  0.00632384]
< returned_observation >
[ 0.          0.36483448]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1496 #########################################
< action >
[-0.03626058  0.00544725]
< returned_observation >
[ 0.          0.37028173]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1497 #########################################
< action >
[-0.03738243  0.00486662]
< returned_observation >
[ 0.          0.37514835]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1498 #########################################
< action >
[-0.03821985  0.00403749]
< returned_observation >
[ 0.          0.37918585]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1499 #########################################
< action >
[-0.03790227  0.0040656 ]
< returned_observation >
[ 0.          0.38325145]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1500 #########################################
< action >
[-0.03861803  0.00336177]
< returned_observation >
[ 0.          0.38661322]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1501 #########################################
< action >
[-0.0391349   0.00255187]
< returned_observation >
[ 0.          0.38916509]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1502 #########################################
< action >
[-0.03797093  0.00250351]
< returned_observation >
[ 0.         0.3916686]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1503 #########################################
< action >
[-0.03823976  0.0015263 ]
< returned_observation >
[ 0.         0.3931949]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1504 #########################################
< action >
[-0.03734932 -0.00168076]
< returned_observation >
[ 0.          0.39151414]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1505 #########################################
< action >
[-0.0365387  -0.00263711]
< returned_observation >
[ 0.          0.38887703]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1506 #########################################
< action >
[-0.03638297 -0.00240398]
< returned_observation >
[ 0.          0.38647305]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1507 #########################################
< action >
[-0.03542521 -0.00453992]
< returned_observation >
[ 0.          0.38193313]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 1508 #########################################
< action >
[-0.03344372 -0.00477977]
< returned_observation >
[ 0.          0.37715335]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1509 #########################################
< action >
[-0.03475832 -0.00214075]
< returned_observation >
[ 0.          0.37501261]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1510 #########################################
< action >
[-0.03593865  0.00140121]
< returned_observation >
[ 0.          0.37641381]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1511 #########################################
< action >
[-0.03368157  0.0004817 ]
< returned_observation >
[ 0.          0.37689552]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1512 #########################################
< action >
[-0.03356287 -0.00206629]
< returned_observation >
[ 0.          0.37482923]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1513 #########################################
< action >
[-0.03535837 -0.00192816]
< returned_observation >
[ 0.          0.37290107]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1514 #########################################
< action >
[-0.03659263 -0.00036414]
< returned_observation >
[ 0.          0.37253692]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1515 #########################################
< action >
[-0.03694554  0.00118786]
< returned_observation >
[ 0.          0.37372478]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1516 #########################################
< action >
[-0.03658005  0.00141327]
< returned_observation >
[ 0.          0.37513805]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1517 #########################################
< action >
[-0.03661722  0.00345646]
< returned_observation >
[ 0.          0.37859451]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1518 #########################################
< action >
[-0.03532711  0.00224372]
< returned_observation >
[ 0.          0.38083823]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1519 #########################################
< action >
[-0.0331868   0.00114128]
< returned_observation >
[ 0.          0.38197951]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1520 #########################################
< action >
[-0.03257149 -0.00110696]
< returned_observation >
[ 0.          0.38087256]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1521 #########################################
< action >
[-0.03512429  0.00157284]
< returned_observation >
[ 0.          0.38244539]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1522 #########################################
< action >
[ -3.73926476e-02   1.42872334e-05]
< returned_observation >
[ 0.          0.38245968]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1523 #########################################
< action >
[-0.03770681  0.00225641]
< returned_observation >
[ 0.          0.38471609]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1524 #########################################
< action >
[-0.03595858  0.00349998]
< returned_observation >
[ 0.          0.38821608]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1525 #########################################
< action >
[-0.03667798  0.00355222]
< returned_observation >
[ 0.          0.39176829]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1526 #########################################
< action >
[-0.03671295  0.003706  ]
< returned_observation >
[ 0.          0.39547429]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1527 #########################################
< action >
[-0.03693039  0.00403847]
< returned_observation >
[ 0.          0.39951275]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1528 #########################################
< action >
[-0.03694659  0.00506516]
< returned_observation >
[ 0.          0.40457792]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1529 #########################################
< action >
[-0.03630002  0.0038325 ]
< returned_observation >
[ 0.          0.40841042]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1530 #########################################
< action >
[-0.03659461  0.00152981]
< returned_observation >
[ 0.          0.40994022]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1531 #########################################
< action >
[-0.03661972  0.001137  ]
< returned_observation >
[ 0.          0.41107722]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 1532 #########################################
< action >
[-0.03700764  0.00210314]
< returned_observation >
[ 0.          0.41318036]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1533 #########################################
< action >
[-0.0367753   0.00311055]
< returned_observation >
[ 0.          0.41629091]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1534 #########################################
< action >
[-0.03632209  0.00153989]
< returned_observation >
[ 0.          0.41783079]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1535 #########################################
< action >
[-0.03506262  0.00221071]
< returned_observation >
[ 0.          0.42004151]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1536 #########################################
< action >
[-0.03407996  0.00302896]
< returned_observation >
[ 0.          0.42307047]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1537 #########################################
< action >
[-0.03216642  0.001171  ]
< returned_observation >
[ 0.          0.42424148]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1538 #########################################
< action >
[-0.03133211  0.00062483]
< returned_observation >
[ 0.          0.42486631]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1539 #########################################
< action >
[-0.03138618 -0.00045614]
< returned_observation >
[ 0.          0.42441016]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1540 #########################################
< action >
[-0.03238557 -0.00156104]
< returned_observation >
[ 0.          0.42284912]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1541 #########################################
< action >
[ -3.47058833e-02   3.91244888e-05]
< returned_observation >
[ 0.          0.42288824]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1542 #########################################
< action >
[ -3.54291961e-02   6.57558441e-05]
< returned_observation >
[ 0.        0.422954]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1543 #########################################
< action >
[-0.03765133  0.00122741]
< returned_observation >
[ 0.          0.42418142]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1544 #########################################
< action >
[-0.03498727 -0.00034462]
< returned_observation >
[ 0.         0.4238368]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1545 #########################################
< action >
[-0.03601203  0.00085816]
< returned_observation >
[ 0.          0.42469496]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1546 #########################################
< action >
[-0.0361658  -0.00057425]
< returned_observation >
[ 0.          0.42412071]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 1547 #########################################
< action >
[-0.03733955  0.00151055]
< returned_observation >
[ 0.          0.42563126]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1548 #########################################
< action >
[-0.03656636 -0.00174046]
< returned_observation >
[ 0.         0.4238908]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1549 #########################################
< action >
[-0.03646334 -0.00203449]
< returned_observation >
[ 0.         0.4218563]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1550 #########################################
< action >
[-0.03613042 -0.00147957]
< returned_observation >
[ 0.          0.42037674]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1551 #########################################
< action >
[-0.03618007 -0.00206852]
< returned_observation >
[ 0.          0.41830822]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1552 #########################################
< action >
[-0.03588806 -0.00021695]
< returned_observation >
[ 0.          0.41809127]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1553 #########################################
< action >
[-0.03422514 -0.00194687]
< returned_observation >
[ 0.         0.4161444]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 1554 #########################################
< action >
[-0.03640638 -0.00144979]
< returned_observation >
[ 0.          0.41469461]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1555 #########################################
< action >
[-0.03645337 -0.00090849]
< returned_observation >
[ 0.          0.41378613]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1556 #########################################
< action >
[-0.03578569 -0.00068593]
< returned_observation >
[ 0.         0.4131002]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 68 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -13.3, 'episode_reward': -779.3, 'ave_reward': -7.792999999999999, 'nb_steps': 1557, 'max_reward': 3.6999999999999993}
######################################### STEP 1557 #########################################
< action >
[ 0.02130811 -0.04539353]
< returned_observation >
[ 0.4719446   0.50237004]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1558 #########################################
< action >
[ 0.01255773 -0.04233637]
< returned_observation >
[ 0.48450232  0.46003368]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1559 #########################################
< action >
[-0.01582115 -0.02316077]
< returned_observation >
[ 0.46868117  0.43687291]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 1560 #########################################
< action >
[-0.02951065 -0.00566125]
< returned_observation >
[ 0.43917052  0.43121166]
< reward >
-14.100000000000001
< running_reward >
-4.23
< done >
False
######################################### STEP 1561 #########################################
< action >
[-0.02926503 -0.00384625]
< returned_observation >
[ 0.40990549  0.42736541]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1562 #########################################
< action >
[-0.02860942 -0.00278227]
< returned_observation >
[ 0.38129607  0.42458314]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1563 #########################################
< action >
[-0.02806921 -0.00279086]
< returned_observation >
[ 0.35322686  0.42179228]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1564 #########################################
< action >
[-0.02725318 -0.0016114 ]
< returned_observation >
[ 0.32597368  0.42018088]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1565 #########################################
< action >
[-0.02647949 -0.0021082 ]
< returned_observation >
[ 0.29949418  0.41807268]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1566 #########################################
< action >
[-0.02495861 -0.00162974]
< returned_observation >
[ 0.27453557  0.41644294]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1567 #########################################
< action >
[-0.02358959 -0.00082178]
< returned_observation >
[ 0.25094598  0.41562116]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1568 #########################################
< action >
[-0.02361753 -0.00205928]
< returned_observation >
[ 0.22732845  0.41356188]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1569 #########################################
< action >
[-0.02422568 -0.00108292]
< returned_observation >
[ 0.20310277  0.41247897]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1570 #########################################
< action >
[-0.02365859 -0.00108702]
< returned_observation >
[ 0.17944419  0.41139195]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1571 #########################################
< action >
[-0.0215416  -0.00077832]
< returned_observation >
[ 0.15790259  0.41061363]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1572 #########################################
< action >
[ -2.18896091e-02  -4.95553017e-05]
< returned_observation >
[ 0.13601298  0.41056408]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1573 #########################################
< action >
[-0.01987337  0.00131596]
< returned_observation >
[ 0.11613961  0.41188004]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1574 #########################################
< action >
[-0.01937152 -0.000106  ]
< returned_observation >
[ 0.09676809  0.41177404]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1575 #########################################
< action >
[-0.01802231 -0.00046555]
< returned_observation >
[ 0.07874579  0.41130849]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1576 #########################################
< action >
[-0.01891027  0.00024338]
< returned_observation >
[ 0.05983551  0.41155188]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1577 #########################################
< action >
[-0.01816774  0.00107971]
< returned_observation >
[ 0.04166778  0.41263159]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1578 #########################################
< action >
[-0.01872769  0.00225589]
< returned_observation >
[ 0.02294008  0.41488748]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1579 #########################################
< action >
[-0.01849568  0.00063725]
< returned_observation >
[ 0.0044444   0.41552473]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1580 #########################################
< action >
[-0.01750966  0.00060779]
< returned_observation >
[ 0.          0.41613252]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1581 #########################################
< action >
[-0.01660465  0.00173992]
< returned_observation >
[ 0.          0.41787244]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1582 #########################################
< action >
[-0.01668605 -0.00057845]
< returned_observation >
[ 0.        0.417294]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1583 #########################################
< action >
[-0.01967484  0.00119997]
< returned_observation >
[ 0.          0.41849397]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1584 #########################################
< action >
[-0.02025676  0.0030869 ]
< returned_observation >
[ 0.          0.42158087]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1585 #########################################
< action >
[-0.02072128  0.00262767]
< returned_observation >
[ 0.          0.42420854]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1586 #########################################
< action >
[-0.02015284  0.00205954]
< returned_observation >
[ 0.          0.42626808]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1587 #########################################
< action >
[-0.02126426  0.00405692]
< returned_observation >
[ 0.          0.43032501]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1588 #########################################
< action >
[-0.02317401  0.00362735]
< returned_observation >
[ 0.          0.43395236]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1589 #########################################
< action >
[-0.02434823  0.00374956]
< returned_observation >
[ 0.          0.43770192]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1590 #########################################
< action >
[-0.02485107  0.00303168]
< returned_observation >
[ 0.         0.4407336]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1591 #########################################
< action >
[-0.02583708  0.00336816]
< returned_observation >
[ 0.          0.44410176]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1592 #########################################
< action >
[-0.02583765  0.00157357]
< returned_observation >
[ 0.          0.44567534]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1593 #########################################
< action >
[-0.02584929  0.0012287 ]
< returned_observation >
[ 0.          0.44690403]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1594 #########################################
< action >
[-0.02480752 -0.00043053]
< returned_observation >
[ 0.          0.44647351]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1595 #########################################
< action >
[ -2.66009584e-02   5.81562519e-05]
< returned_observation >
[ 0.          0.44653166]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1596 #########################################
< action >
[-0.0278026   0.00137071]
< returned_observation >
[ 0.          0.44790237]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1597 #########################################
< action >
[-0.02649923 -0.00076296]
< returned_observation >
[ 0.          0.44713941]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1598 #########################################
< action >
[-0.02911133 -0.00037752]
< returned_observation >
[ 0.          0.44676189]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1599 #########################################
< action >
[-0.02842515 -0.00095976]
< returned_observation >
[ 0.          0.44580213]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1600 #########################################
< action >
[-0.02935883  0.00054736]
< returned_observation >
[ 0.          0.44634949]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1601 #########################################
< action >
[-0.03017315  0.00131247]
< returned_observation >
[ 0.          0.44766196]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1602 #########################################
< action >
[-0.02980768  0.00040705]
< returned_observation >
[ 0.        0.448069]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1603 #########################################
< action >
[-0.02982722  0.00155039]
< returned_observation >
[ 0.          0.44961939]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1604 #########################################
< action >
[-0.02970109 -0.00025894]
< returned_observation >
[ 0.          0.44936045]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1605 #########################################
< action >
[-0.03171861  0.00076638]
< returned_observation >
[ 0.          0.45012684]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1606 #########################################
< action >
[-0.03262103  0.00305223]
< returned_observation >
[ 0.          0.45317907]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1607 #########################################
< action >
[-0.0323839   0.00082996]
< returned_observation >
[ 0.          0.45400904]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1608 #########################################
< action >
[-0.03182005  0.00129119]
< returned_observation >
[ 0.          0.45530022]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1609 #########################################
< action >
[-0.03250325  0.00190485]
< returned_observation >
[ 0.          0.45720507]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 1610 #########################################
< action >
[-0.03203529  0.00119043]
< returned_observation >
[ 0.         0.4583955]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 1611 #########################################
< action >
[-0.03173377 -0.00186583]
< returned_observation >
[ 0.          0.45652966]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1612 #########################################
< action >
[-0.03286452 -0.00281428]
< returned_observation >
[ 0.          0.45371539]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1613 #########################################
< action >
[-0.03387478  0.00057494]
< returned_observation >
[ 0.          0.45429033]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1614 #########################################
< action >
[-0.03327841 -0.00280085]
< returned_observation >
[ 0.          0.45148947]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1615 #########################################
< action >
[-0.03588303  0.00224786]
< returned_observation >
[ 0.          0.45373734]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1616 #########################################
< action >
[-0.03367204 -0.00303711]
< returned_observation >
[ 0.          0.45070023]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1617 #########################################
< action >
[-0.03425042 -0.00258915]
< returned_observation >
[ 0.          0.44811108]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1618 #########################################
< action >
[-0.03438268 -0.00249062]
< returned_observation >
[ 0.          0.44562046]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1619 #########################################
< action >
[-0.03502406 -0.0004546 ]
< returned_observation >
[ 0.          0.44516586]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1620 #########################################
< action >
[-0.03490166 -0.00222969]
< returned_observation >
[ 0.          0.44293616]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1621 #########################################
< action >
[-0.03475161 -0.00383936]
< returned_observation >
[ 0.         0.4390968]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 1622 #########################################
< action >
[-0.03418237 -0.0025516 ]
< returned_observation >
[ 0.         0.4365452]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1623 #########################################
< action >
[-0.03367973 -0.00234388]
< returned_observation >
[ 0.          0.43420132]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1624 #########################################
< action >
[-0.0339216  -0.00286037]
< returned_observation >
[ 0.          0.43134095]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1625 #########################################
< action >
[-0.03544093 -0.00242696]
< returned_observation >
[ 0.          0.42891399]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1626 #########################################
< action >
[-0.03536851 -0.00184078]
< returned_observation >
[ 0.          0.42707321]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1627 #########################################
< action >
[-0.03570574 -0.00248548]
< returned_observation >
[ 0.          0.42458774]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1628 #########################################
< action >
[-0.03735645 -0.00299125]
< returned_observation >
[ 0.          0.42159648]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1629 #########################################
< action >
[-0.03588219 -0.00216931]
< returned_observation >
[ 0.          0.41942718]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1630 #########################################
< action >
[ -3.90424505e-02   6.91652298e-05]
< returned_observation >
[ 0.          0.41949635]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1631 #########################################
< action >
[-0.03864898 -0.00113052]
< returned_observation >
[ 0.          0.41836582]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1632 #########################################
< action >
[-0.03732103 -0.0026502 ]
< returned_observation >
[ 0.          0.41571562]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1633 #########################################
< action >
[-0.03755766 -0.00117179]
< returned_observation >
[ 0.          0.41454383]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1634 #########################################
< action >
[-0.03797414 -0.00022043]
< returned_observation >
[ 0.         0.4143234]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1635 #########################################
< action >
[-0.03826415 -0.00176039]
< returned_observation >
[ 0.          0.41256301]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1636 #########################################
< action >
[-0.03735445 -0.00245925]
< returned_observation >
[ 0.          0.41010376]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1637 #########################################
< action >
[-0.03918368 -0.00168675]
< returned_observation >
[ 0.        0.408417]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1638 #########################################
< action >
[-0.03881277 -0.00189989]
< returned_observation >
[ 0.          0.40651711]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1639 #########################################
< action >
[-0.03781719 -0.00289172]
< returned_observation >
[ 0.         0.4036254]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1640 #########################################
< action >
[-0.03768624 -0.00303882]
< returned_observation >
[ 0.          0.40058658]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1641 #########################################
< action >
[-0.03678848 -0.00415729]
< returned_observation >
[ 0.          0.39642929]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1642 #########################################
< action >
[-0.03761062 -0.00397763]
< returned_observation >
[ 0.          0.39245166]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1643 #########################################
< action >
[-0.03628467 -0.00533649]
< returned_observation >
[ 0.          0.38711517]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1644 #########################################
< action >
[-0.03783966 -0.00327944]
< returned_observation >
[ 0.          0.38383573]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1645 #########################################
< action >
[-0.03787759 -0.00295612]
< returned_observation >
[ 0.          0.38087962]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1646 #########################################
< action >
[-0.0362372  -0.00344873]
< returned_observation >
[ 0.          0.37743088]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1647 #########################################
< action >
[-0.03607469 -0.00438745]
< returned_observation >
[ 0.          0.37304344]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1648 #########################################
< action >
[-0.03552798 -0.00489641]
< returned_observation >
[ 0.          0.36814703]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1649 #########################################
< action >
[-0.03567156 -0.00617713]
< returned_observation >
[ 0.         0.3619699]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1650 #########################################
< action >
[-0.03587068 -0.00579071]
< returned_observation >
[ 0.          0.35617919]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1651 #########################################
< action >
[-0.03536816 -0.00410961]
< returned_observation >
[ 0.          0.35206958]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1652 #########################################
< action >
[-0.03523965 -0.00462554]
< returned_observation >
[ 0.          0.34744404]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1653 #########################################
< action >
[-0.03593127 -0.00466595]
< returned_observation >
[ 0.          0.34277809]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1654 #########################################
< action >
[-0.03614813 -0.00575601]
< returned_observation >
[ 0.          0.33702208]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1655 #########################################
< action >
[-0.03756563 -0.00480267]
< returned_observation >
[ 0.          0.33221942]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1656 #########################################
< action >
[-0.03817118 -0.00460112]
< returned_observation >
[ 0.          0.32761829]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 69 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -14.100000000000001, 'episode_reward': -568.3999999999999, 'ave_reward': -5.683999999999998, 'nb_steps': 1657, 'max_reward': 3.6000000000000014}
######################################### STEP 1657 #########################################
< action >
[-0.04372062  0.02480163]
< returned_observation >
[ 0.04960609  0.32166241]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1658 #########################################
< action >
[-0.03119466 -0.0077277 ]
< returned_observation >
[ 0.01841142  0.3139347 ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1659 #########################################
< action >
[-0.03179403 -0.00121616]
< returned_observation >
[ 0.          0.31271854]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1660 #########################################
< action >
[-0.03087094 -0.00343671]
< returned_observation >
[ 0.          0.30928183]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1661 #########################################
< action >
[-0.02898193 -0.00349578]
< returned_observation >
[ 0.          0.30578605]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1662 #########################################
< action >
[-0.02933548 -0.00488028]
< returned_observation >
[ 0.          0.30090577]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1663 #########################################
< action >
[-0.03035263 -0.00236592]
< returned_observation >
[ 0.          0.29853985]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1664 #########################################
< action >
[ -2.82071158e-02  -8.42034817e-05]
< returned_observation >
[ 0.          0.29845564]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1665 #########################################
< action >
[-0.02614965 -0.00429238]
< returned_observation >
[ 0.          0.29416326]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1666 #########################################
< action >
[-0.02757732 -0.00576925]
< returned_observation >
[ 0.          0.28839401]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1667 #########################################
< action >
[-0.02741123 -0.0023346 ]
< returned_observation >
[ 0.          0.28605942]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1668 #########################################
< action >
[-0.02776676 -0.00512808]
< returned_observation >
[ 0.          0.28093134]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1669 #########################################
< action >
[-0.02810037 -0.0035727 ]
< returned_observation >
[ 0.          0.27735864]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1670 #########################################
< action >
[-0.02926867 -0.00285853]
< returned_observation >
[ 0.          0.27450012]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1671 #########################################
< action >
[-0.02941099 -0.00337346]
< returned_observation >
[ 0.          0.27112665]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1672 #########################################
< action >
[-0.02909543 -0.0044605 ]
< returned_observation >
[ 0.          0.26666615]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1673 #########################################
< action >
[-0.02931763 -0.00421338]
< returned_observation >
[ 0.          0.26245277]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1674 #########################################
< action >
[-0.02905743 -0.00267975]
< returned_observation >
[ 0.          0.25977302]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1675 #########################################
< action >
[-0.02768083 -0.00333101]
< returned_observation >
[ 0.          0.25644201]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1676 #########################################
< action >
[-0.02816956 -0.00389437]
< returned_observation >
[ 0.          0.25254763]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1677 #########################################
< action >
[-0.03049952 -0.00051987]
< returned_observation >
[ 0.          0.25202777]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1678 #########################################
< action >
[-0.03164391 -0.00163506]
< returned_observation >
[ 0.         0.2503927]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1679 #########################################
< action >
[-0.03120245 -0.00363664]
< returned_observation >
[ 0.          0.24675606]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1680 #########################################
< action >
[-0.03209524 -0.00162857]
< returned_observation >
[ 0.          0.24512749]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1681 #########################################
< action >
[-0.03152985 -0.00229528]
< returned_observation >
[ 0.          0.24283221]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1682 #########################################
< action >
[-0.03251106 -0.00010877]
< returned_observation >
[ 0.          0.24272345]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1683 #########################################
< action >
[-0.03083638 -0.00146965]
< returned_observation >
[ 0.         0.2412538]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1684 #########################################
< action >
[-0.0327424  -0.00083654]
< returned_observation >
[ 0.          0.24041726]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1685 #########################################
< action >
[ -3.40357363e-02  -1.04099512e-05]
< returned_observation >
[ 0.          0.24040685]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1686 #########################################
< action >
[-0.03363197  0.00218982]
< returned_observation >
[ 0.          0.24259667]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1687 #########################################
< action >
[-0.03326372 -0.00123671]
< returned_observation >
[ 0.          0.24135996]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1688 #########################################
< action >
[-0.03153191 -0.00015801]
< returned_observation >
[ 0.          0.24120194]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1689 #########################################
< action >
[-0.0325317  0.0009398]
< returned_observation >
[ 0.          0.24214174]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1690 #########################################
< action >
[-0.03097076 -0.00214423]
< returned_observation >
[ 0.          0.23999751]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1691 #########################################
< action >
[-0.031993    0.00082842]
< returned_observation >
[ 0.          0.24082593]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1692 #########################################
< action >
[-0.03056827  0.00117555]
< returned_observation >
[ 0.          0.24200148]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1693 #########################################
< action >
[-0.03027177  0.00081885]
< returned_observation >
[ 0.          0.24282033]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1694 #########################################
< action >
[-0.03119874  0.00254897]
< returned_observation >
[ 0.         0.2453693]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1695 #########################################
< action >
[ -3.24103475e-02   3.93092632e-05]
< returned_observation >
[ 0.          0.24540861]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1696 #########################################
< action >
[-0.03393087  0.00245089]
< returned_observation >
[ 0.         0.2478595]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1697 #########################################
< action >
[-0.0335606   0.00201483]
< returned_observation >
[ 0.          0.24987434]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1698 #########################################
< action >
[-0.03212526  0.00284267]
< returned_observation >
[ 0.          0.25271701]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1699 #########################################
< action >
[-0.03221147  0.00246851]
< returned_observation >
[ 0.          0.25518552]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1700 #########################################
< action >
[-0.03253198  0.00294984]
< returned_observation >
[ 0.          0.25813536]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1701 #########################################
< action >
[-0.03257497  0.00387424]
< returned_observation >
[ 0.         0.2620096]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1702 #########################################
< action >
[-0.03053386  0.00251336]
< returned_observation >
[ 0.          0.26452296]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1703 #########################################
< action >
[-0.02917908  0.00357015]
< returned_observation >
[ 0.         0.2680931]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1704 #########################################
< action >
[-0.03046293  0.0041156 ]
< returned_observation >
[ 0.         0.2722087]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1705 #########################################
< action >
[-0.02916635  0.00074077]
< returned_observation >
[ 0.          0.27294947]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1706 #########################################
< action >
[-0.02877158  0.00265577]
< returned_observation >
[ 0.          0.27560524]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1707 #########################################
< action >
[-0.02971692  0.00356675]
< returned_observation >
[ 0.        0.279172]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1708 #########################################
< action >
[-0.03109075  0.00206501]
< returned_observation >
[ 0.          0.28123701]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1709 #########################################
< action >
[-0.03166164  0.00333182]
< returned_observation >
[ 0.          0.28456883]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1710 #########################################
< action >
[-0.03119795  0.00161942]
< returned_observation >
[ 0.          0.28618824]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1711 #########################################
< action >
[-0.03053656  0.00321374]
< returned_observation >
[ 0.          0.28940198]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1712 #########################################
< action >
[-0.02996923  0.00060514]
< returned_observation >
[ 0.          0.29000713]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1713 #########################################
< action >
[-0.02986146  0.00180448]
< returned_observation >
[ 0.         0.2918116]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1714 #########################################
< action >
[-0.03042303  0.00212241]
< returned_observation >
[ 0.          0.29393402]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1715 #########################################
< action >
[-0.02996364  0.00119662]
< returned_observation >
[ 0.          0.29513063]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1716 #########################################
< action >
[-0.02915704 -0.00012591]
< returned_observation >
[ 0.          0.29500473]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1717 #########################################
< action >
[-0.02972061  0.00125026]
< returned_observation >
[ 0.          0.29625498]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1718 #########################################
< action >
[-0.03057304  0.00065618]
< returned_observation >
[ 0.          0.29691116]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1719 #########################################
< action >
[-0.02993997 -0.00023815]
< returned_observation >
[ 0.          0.29667301]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1720 #########################################
< action >
[-0.03156817 -0.00113069]
< returned_observation >
[ 0.          0.29554232]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1721 #########################################
< action >
[-0.03092711 -0.0007139 ]
< returned_observation >
[ 0.          0.29482843]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1722 #########################################
< action >
[-0.03173998  0.00140203]
< returned_observation >
[ 0.          0.29623045]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1723 #########################################
< action >
[-0.03147276  0.00213496]
< returned_observation >
[ 0.          0.29836541]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1724 #########################################
< action >
[-0.03139521  0.00013445]
< returned_observation >
[ 0.          0.29849986]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1725 #########################################
< action >
[-0.03167031  0.00293792]
< returned_observation >
[ 0.          0.30143778]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1726 #########################################
< action >
[-0.03054412  0.00180994]
< returned_observation >
[ 0.          0.30324773]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1727 #########################################
< action >
[-0.02870905  0.00036474]
< returned_observation >
[ 0.          0.30361246]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1728 #########################################
< action >
[-0.02968459  0.0008128 ]
< returned_observation >
[ 0.          0.30442526]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1729 #########################################
< action >
[-0.02917224  0.00168644]
< returned_observation >
[ 0.          0.30611171]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1730 #########################################
< action >
[-0.02972642  0.00108057]
< returned_observation >
[ 0.          0.30719227]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1731 #########################################
< action >
[-0.02852612  0.00044217]
< returned_observation >
[ 0.          0.30763444]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1732 #########################################
< action >
[-0.03007147 -0.00034386]
< returned_observation >
[ 0.          0.30729059]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1733 #########################################
< action >
[-0.0297507   0.00196852]
< returned_observation >
[ 0.          0.30925911]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 1734 #########################################
< action >
[-0.02912671 -0.00066693]
< returned_observation >
[ 0.          0.30859217]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 1735 #########################################
< action >
[-0.02832422  0.00240994]
< returned_observation >
[ 0.          0.31100211]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1736 #########################################
< action >
[-0.02711224 -0.00101861]
< returned_observation >
[ 0.         0.3099835]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1737 #########################################
< action >
[-0.02598538  0.00141829]
< returned_observation >
[ 0.          0.31140179]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1738 #########################################
< action >
[-0.02594988 -0.00151931]
< returned_observation >
[ 0.          0.30988249]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1739 #########################################
< action >
[-0.02696835  0.00014042]
< returned_observation >
[ 0.          0.31002291]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1740 #########################################
< action >
[-0.02686355 -0.0005161 ]
< returned_observation >
[ 0.          0.30950681]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1741 #########################################
< action >
[-0.02729802  0.00085087]
< returned_observation >
[ 0.          0.31035768]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1742 #########################################
< action >
[-0.02605989 -0.00120667]
< returned_observation >
[ 0.          0.30915101]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1743 #########################################
< action >
[-0.02771013 -0.00032592]
< returned_observation >
[ 0.          0.30882509]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1744 #########################################
< action >
[-0.02819617 -0.00093131]
< returned_observation >
[ 0.          0.30789378]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1745 #########################################
< action >
[-0.02796986 -0.00074326]
< returned_observation >
[ 0.          0.30715052]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1746 #########################################
< action >
[ -2.76468650e-02   2.29299068e-05]
< returned_observation >
[ 0.          0.30717345]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1747 #########################################
< action >
[-0.02766457 -0.0023349 ]
< returned_observation >
[ 0.          0.30483856]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1748 #########################################
< action >
[-0.0281958 -0.0018967]
< returned_observation >
[ 0.          0.30294185]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1749 #########################################
< action >
[-0.02832066 -0.0011335 ]
< returned_observation >
[ 0.          0.30180835]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1750 #########################################
< action >
[-0.02836462 -0.0012621 ]
< returned_observation >
[ 0.          0.30054626]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1751 #########################################
< action >
[-0.02911439 -0.00273532]
< returned_observation >
[ 0.          0.29781093]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1752 #########################################
< action >
[-0.02990348 -0.00101003]
< returned_observation >
[ 0.         0.2968009]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1753 #########################################
< action >
[-0.02896804 -0.00286413]
< returned_observation >
[ 0.          0.29393677]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 1754 #########################################
< action >
[-0.0299555   0.00065951]
< returned_observation >
[ 0.          0.29459628]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1755 #########################################
< action >
[-0.02990945 -0.00176519]
< returned_observation >
[ 0.          0.29283109]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1756 #########################################
< action >
[-0.02942501 -0.00024361]
< returned_observation >
[ 0.          0.29258749]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
True
##################### episode 70 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -13.100000000000001, 'episode_reward': -625.3, 'ave_reward': -6.252999999999999, 'nb_steps': 1757, 'max_reward': 3.6999999999999993}
######################################### STEP 1757 #########################################
< action >
[-0.00333725 -0.04966486]
< returned_observation >
[ 0.92424699  0.51933887]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1758 #########################################
< action >
[-0.00528264 -0.05      ]
< returned_observation >
[ 0.91896435  0.46933887]
< reward >
-14.100000000000001
< running_reward >
-4.23
< done >
False
######################################### STEP 1759 #########################################
< action >
[-0.00665084 -0.05      ]
< returned_observation >
[ 0.91231351  0.41933887]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 1760 #########################################
< action >
[-0.0093288  -0.04961213]
< returned_observation >
[ 0.90298471  0.36972675]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 1761 #########################################
< action >
[-0.0135757 -0.05     ]
< returned_observation >
[ 0.88940901  0.31972675]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 1762 #########################################
< action >
[-0.01900134 -0.05      ]
< returned_observation >
[ 0.87040767  0.26972675]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1763 #########################################
< action >
[-0.04546085 -0.05      ]
< returned_observation >
[ 0.82494682  0.21972675]
< reward >
-15.3
< running_reward >
-4.59
< done >
False
######################################### STEP 1764 #########################################
< action >
[-0.05       -0.02716361]
< returned_observation >
[ 0.77494682  0.19256314]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1765 #########################################
< action >
[-0.05        0.01426453]
< returned_observation >
[ 0.72494682  0.20682767]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1766 #########################################
< action >
[-0.05       -0.00377617]
< returned_observation >
[ 0.67494682  0.2030515 ]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 1767 #########################################
< action >
[-0.05      0.003494]
< returned_observation >
[ 0.62494682  0.2065455 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1768 #########################################
< action >
[-0.05        0.00138444]
< returned_observation >
[ 0.57494682  0.20792994]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 1769 #########################################
< action >
[-0.05        0.00172789]
< returned_observation >
[ 0.52494682  0.20965782]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1770 #########################################
< action >
[-0.05        0.00504692]
< returned_observation >
[ 0.47494682  0.21470474]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1771 #########################################
< action >
[-0.04927943  0.00218567]
< returned_observation >
[ 0.42566739  0.21689041]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1772 #########################################
< action >
[-0.04942819  0.00518768]
< returned_observation >
[ 0.3762392   0.22207809]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1773 #########################################
< action >
[-0.04957944  0.0027073 ]
< returned_observation >
[ 0.32665976  0.22478539]
< reward >
-13.2
< running_reward >
-3.9599999999999995
< done >
False
######################################### STEP 1774 #########################################
< action >
[-0.05        0.00427163]
< returned_observation >
[ 0.27665976  0.22905702]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1775 #########################################
< action >
[-0.04858692  0.00269142]
< returned_observation >
[ 0.22807284  0.23174844]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1776 #########################################
< action >
[-0.04792108  0.00648026]
< returned_observation >
[ 0.18015176  0.23822871]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1777 #########################################
< action >
[-0.0482478   0.00052083]
< returned_observation >
[ 0.13190396  0.23874954]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1778 #########################################
< action >
[-0.04955903  0.00615473]
< returned_observation >
[ 0.08234493  0.24490427]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1779 #########################################
< action >
[-0.04831839 -0.00070355]
< returned_observation >
[ 0.03402654  0.24420073]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1780 #########################################
< action >
[-0.04832259  0.00544583]
< returned_observation >
[ 0.          0.24964655]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1781 #########################################
< action >
[-0.04665656  0.00110541]
< returned_observation >
[ 0.          0.25075196]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1782 #########################################
< action >
[-0.046108   -0.00118921]
< returned_observation >
[ 0.          0.24956276]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1783 #########################################
< action >
[-0.04744745  0.00068358]
< returned_observation >
[ 0.          0.25024634]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1784 #########################################
< action >
[ -4.82809637e-02   2.54154205e-05]
< returned_observation >
[ 0.          0.25027175]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1785 #########################################
< action >
[-0.04760202 -0.00057053]
< returned_observation >
[ 0.          0.24970122]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1786 #########################################
< action >
[-0.04691496  0.00091115]
< returned_observation >
[ 0.          0.25061237]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1787 #########################################
< action >
[-0.04560576 -0.00219398]
< returned_observation >
[ 0.          0.24841839]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1788 #########################################
< action >
[-0.04869701  0.00240775]
< returned_observation >
[ 0.          0.25082615]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1789 #########################################
< action >
[-0.04770467 -0.00169117]
< returned_observation >
[ 0.          0.24913498]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1790 #########################################
< action >
[-0.04941827  0.00394121]
< returned_observation >
[ 0.          0.25307619]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1791 #########################################
< action >
[ -5.00000000e-02  -2.09599733e-05]
< returned_observation >
[ 0.          0.25305523]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1792 #########################################
< action >
[-0.04952294  0.00137169]
< returned_observation >
[ 0.          0.25442692]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1793 #########################################
< action >
[-0.04865023  0.00033809]
< returned_observation >
[ 0.          0.25476501]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1794 #########################################
< action >
[-0.0495369   0.00270922]
< returned_observation >
[ 0.          0.25747423]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1795 #########################################
< action >
[-0.04848152 -0.00042517]
< returned_observation >
[ 0.          0.25704906]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1796 #########################################
< action >
[-0.04840065  0.00138167]
< returned_observation >
[ 0.          0.25843072]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1797 #########################################
< action >
[-0.05        0.00035836]
< returned_observation >
[ 0.          0.25878908]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1798 #########################################
< action >
[-0.05        0.00127742]
< returned_observation >
[ 0.         0.2600665]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1799 #########################################
< action >
[-0.05       0.0026518]
< returned_observation >
[ 0.         0.2627183]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1800 #########################################
< action >
[-0.05       0.0026558]
< returned_observation >
[ 0.         0.2653741]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1801 #########################################
< action >
[-0.05        0.00211801]
< returned_observation >
[ 0.          0.26749211]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1802 #########################################
< action >
[-0.04992859  0.00246686]
< returned_observation >
[ 0.          0.26995896]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1803 #########################################
< action >
[-0.05        0.00294371]
< returned_observation >
[ 0.          0.27290267]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1804 #########################################
< action >
[-0.04984193  0.002119  ]
< returned_observation >
[ 0.          0.27502167]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1805 #########################################
< action >
[-0.04990781  0.00281537]
< returned_observation >
[ 0.          0.27783704]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1806 #########################################
< action >
[-0.05        0.00220903]
< returned_observation >
[ 0.          0.28004607]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1807 #########################################
< action >
[-0.05        0.00240831]
< returned_observation >
[ 0.          0.28245438]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1808 #########################################
< action >
[-0.05        0.00280256]
< returned_observation >
[ 0.          0.28525694]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1809 #########################################
< action >
[-0.05        0.00165701]
< returned_observation >
[ 0.          0.28691395]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1810 #########################################
< action >
[-0.05        0.00215737]
< returned_observation >
[ 0.          0.28907132]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 1811 #########################################
< action >
[-0.05        0.00138671]
< returned_observation >
[ 0.          0.29045804]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1812 #########################################
< action >
[-0.05        0.00392381]
< returned_observation >
[ 0.          0.29438185]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1813 #########################################
< action >
[-0.05        0.00257331]
< returned_observation >
[ 0.          0.29695516]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1814 #########################################
< action >
[-0.05        0.00330167]
< returned_observation >
[ 0.          0.30025683]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1815 #########################################
< action >
[-0.05        0.00184875]
< returned_observation >
[ 0.          0.30210558]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1816 #########################################
< action >
[-0.05        0.00300159]
< returned_observation >
[ 0.          0.30510717]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1817 #########################################
< action >
[-0.05        0.00201402]
< returned_observation >
[ 0.          0.30712119]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1818 #########################################
< action >
[-0.05       0.0049548]
< returned_observation >
[ 0.          0.31207599]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1819 #########################################
< action >
[-0.05        0.00165095]
< returned_observation >
[ 0.          0.31372694]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1820 #########################################
< action >
[-0.04903517  0.00344657]
< returned_observation >
[ 0.          0.31717351]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1821 #########################################
< action >
[-0.04923845  0.0024623 ]
< returned_observation >
[ 0.         0.3196358]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1822 #########################################
< action >
[-0.04906706  0.00346671]
< returned_observation >
[ 0.          0.32310252]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1823 #########################################
< action >
[ -4.77782777e-02   5.85317612e-05]
< returned_observation >
[ 0.          0.32316105]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1824 #########################################
< action >
[-0.04910907  0.00193759]
< returned_observation >
[ 0.          0.32509864]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1825 #########################################
< action >
[-0.05        0.00099154]
< returned_observation >
[ 0.          0.32609018]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1826 #########################################
< action >
[-0.05        0.00045511]
< returned_observation >
[ 0.          0.32654528]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1827 #########################################
< action >
[ -4.93570378e-02  -1.95831060e-05]
< returned_observation >
[ 0.         0.3265257]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1828 #########################################
< action >
[ -4.98276175e-02   1.74582005e-05]
< returned_observation >
[ 0.          0.32654316]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1829 #########################################
< action >
[-0.04933692 -0.00236405]
< returned_observation >
[ 0.          0.32417911]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1830 #########################################
< action >
[ -4.99003200e-02   7.48395920e-05]
< returned_observation >
[ 0.          0.32425395]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1831 #########################################
< action >
[-0.05       -0.00171412]
< returned_observation >
[ 0.          0.32253983]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1832 #########################################
< action >
[-0.04949109  0.00086508]
< returned_observation >
[ 0.          0.32340491]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1833 #########################################
< action >
[-0.04713538 -0.00390425]
< returned_observation >
[ 0.          0.31950066]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1834 #########################################
< action >
[-0.04713137  0.00058165]
< returned_observation >
[ 0.          0.32008231]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1835 #########################################
< action >
[-0.04591539 -0.00257665]
< returned_observation >
[ 0.          0.31750566]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1836 #########################################
< action >
[-0.04698193 -0.00142037]
< returned_observation >
[ 0.          0.31608529]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1837 #########################################
< action >
[-0.04666246 -0.00039435]
< returned_observation >
[ 0.          0.31569093]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 1838 #########################################
< action >
[-0.04612105 -0.00255808]
< returned_observation >
[ 0.          0.31313285]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1839 #########################################
< action >
[-0.04702563 -0.00149352]
< returned_observation >
[ 0.          0.31163933]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 1840 #########################################
< action >
[-0.04701896 -0.00369497]
< returned_observation >
[ 0.          0.30794436]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1841 #########################################
< action >
[-0.04677224 -0.00093179]
< returned_observation >
[ 0.          0.30701257]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1842 #########################################
< action >
[-0.04549463 -0.0043413 ]
< returned_observation >
[ 0.          0.30267127]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 1843 #########################################
< action >
[ -4.65893373e-02   6.20484352e-06]
< returned_observation >
[ 0.          0.30267748]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1844 #########################################
< action >
[-0.04742211 -0.00274465]
< returned_observation >
[ 0.          0.29993283]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1845 #########################################
< action >
[-0.04907639 -0.00143206]
< returned_observation >
[ 0.          0.29850077]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 1846 #########################################
< action >
[-0.0476214  -0.00214624]
< returned_observation >
[ 0.          0.29635453]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1847 #########################################
< action >
[-0.04705754 -0.00319252]
< returned_observation >
[ 0.          0.29316201]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1848 #########################################
< action >
[-0.04728361 -0.0013815 ]
< returned_observation >
[ 0.          0.29178051]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1849 #########################################
< action >
[-0.04648718 -0.0047163 ]
< returned_observation >
[ 0.          0.28706421]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1850 #########################################
< action >
[-0.0470509  -0.00117367]
< returned_observation >
[ 0.          0.28589054]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1851 #########################################
< action >
[-0.04743629 -0.00451345]
< returned_observation >
[ 0.          0.28137709]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1852 #########################################
< action >
[-0.0479273  -0.00117675]
< returned_observation >
[ 0.          0.28020033]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1853 #########################################
< action >
[-0.04692969 -0.00403813]
< returned_observation >
[ 0.         0.2761622]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1854 #########################################
< action >
[-0.04568813 -0.00250965]
< returned_observation >
[ 0.          0.27365255]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1855 #########################################
< action >
[-0.04558877 -0.0020431 ]
< returned_observation >
[ 0.          0.27160945]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1856 #########################################
< action >
[-0.04600697 -0.00252615]
< returned_observation >
[ 0.         0.2690833]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 71 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -15.3, 'episode_reward': -687.0000000000003, 'ave_reward': -6.870000000000004, 'nb_steps': 1857, 'max_reward': 3.5}
######################################### STEP 1857 #########################################
< action >
[-0.00053036 -0.04859197]
< returned_observation >
[ 0.45688164  0.70493402]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1858 #########################################
< action >
[-0.00228685 -0.04928127]
< returned_observation >
[ 0.45459479  0.65565275]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 1859 #########################################
< action >
[-0.00171416 -0.04941668]
< returned_observation >
[ 0.45288063  0.60623607]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1860 #########################################
< action >
[-0.00046437 -0.05      ]
< returned_observation >
[ 0.45241626  0.55623607]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1861 #########################################
< action >
[-0.0005801 -0.05     ]
< returned_observation >
[ 0.45183616  0.50623607]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1862 #########################################
< action >
[ 0.00043006 -0.04948575]
< returned_observation >
[ 0.45226622  0.45675032]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1863 #########################################
< action >
[-0.00105049 -0.05      ]
< returned_observation >
[ 0.45121572  0.40675032]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1864 #########################################
< action >
[-0.00065188 -0.05      ]
< returned_observation >
[ 0.45056384  0.35675032]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1865 #########################################
< action >
[-0.00086142 -0.05      ]
< returned_observation >
[ 0.44970242  0.30675032]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1866 #########################################
< action >
[-0.02530212 -0.04958585]
< returned_observation >
[ 0.4244003   0.25716446]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1867 #########################################
< action >
[-0.05       -0.01468438]
< returned_observation >
[ 0.3744003   0.24248008]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1868 #########################################
< action >
[-0.05        0.00855901]
< returned_observation >
[ 0.3244003   0.25103909]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1869 #########################################
< action >
[-0.04772289 -0.00967015]
< returned_observation >
[ 0.27667741  0.24136894]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1870 #########################################
< action >
[-0.04740266  0.00345358]
< returned_observation >
[ 0.22927475  0.24482251]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1871 #########################################
< action >
[-0.04529907 -0.00436559]
< returned_observation >
[ 0.18397568  0.24045693]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 1872 #########################################
< action >
[-0.04621404  0.00247474]
< returned_observation >
[ 0.13776163  0.24293167]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1873 #########################################
< action >
[-0.0439962  -0.00389376]
< returned_observation >
[ 0.09376543  0.23903791]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1874 #########################################
< action >
[-0.04470085  0.00048825]
< returned_observation >
[ 0.04906458  0.23952616]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1875 #########################################
< action >
[-0.04374061 -0.00212607]
< returned_observation >
[ 0.00532397  0.23740009]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1876 #########################################
< action >
[ -4.48620569e-02  -8.23140144e-06]
< returned_observation >
[ 0.          0.23739186]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1877 #########################################
< action >
[-0.04491045 -0.00288688]
< returned_observation >
[ 0.          0.23450498]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1878 #########################################
< action >
[-0.04439184 -0.00022011]
< returned_observation >
[ 0.          0.23428487]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1879 #########################################
< action >
[-0.0442996  -0.00174132]
< returned_observation >
[ 0.          0.23254355]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1880 #########################################
< action >
[-0.04486882  0.00053753]
< returned_observation >
[ 0.          0.23308108]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1881 #########################################
< action >
[-0.04531698 -0.00287405]
< returned_observation >
[ 0.          0.23020703]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1882 #########################################
< action >
[-0.04680657 -0.00063669]
< returned_observation >
[ 0.          0.22957034]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1883 #########################################
< action >
[-0.04606793 -0.0011144 ]
< returned_observation >
[ 0.          0.22845594]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1884 #########################################
< action >
[-0.04767896  0.00117009]
< returned_observation >
[ 0.          0.22962603]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1885 #########################################
< action >
[-0.04711717 -0.00029553]
< returned_observation >
[ 0.         0.2293305]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1886 #########################################
< action >
[-0.04799514  0.00165731]
< returned_observation >
[ 0.          0.23098781]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1887 #########################################
< action >
[-0.04694171 -0.00173211]
< returned_observation >
[ 0.         0.2292557]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1888 #########################################
< action >
[-0.046893    0.00121412]
< returned_observation >
[ 0.          0.23046982]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 1889 #########################################
< action >
[-0.04581006 -0.00020764]
< returned_observation >
[ 0.          0.23026218]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1890 #########################################
< action >
[-0.04765127  0.00140299]
< returned_observation >
[ 0.          0.23166518]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1891 #########################################
< action >
[-0.04676282 -0.00112315]
< returned_observation >
[ 0.          0.23054203]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1892 #########################################
< action >
[-0.04826433  0.00334799]
< returned_observation >
[ 0.          0.23389002]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1893 #########################################
< action >
[ -4.84880176e-02   7.91490078e-05]
< returned_observation >
[ 0.          0.23396917]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1894 #########################################
< action >
[-0.04820799 -0.00025335]
< returned_observation >
[ 0.          0.23371582]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1895 #########################################
< action >
[-0.04979917  0.00035774]
< returned_observation >
[ 0.          0.23407356]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1896 #########################################
< action >
[-0.04994687 -0.0004783 ]
< returned_observation >
[ 0.          0.23359525]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 1897 #########################################
< action >
[-0.05        0.00121287]
< returned_observation >
[ 0.          0.23480812]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1898 #########################################
< action >
[-0.05        0.00054216]
< returned_observation >
[ 0.          0.23535028]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1899 #########################################
< action >
[-0.04995041  0.00027176]
< returned_observation >
[ 0.          0.23562204]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1900 #########################################
< action >
[-0.05        0.00017762]
< returned_observation >
[ 0.          0.23579966]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1901 #########################################
< action >
[-0.05        0.00112374]
< returned_observation >
[ 0.         0.2369234]
< reward >
-10.399999999999999
< running_reward >
-3.1199999999999997
< done >
False
######################################### STEP 1902 #########################################
< action >
[-0.05        0.00023669]
< returned_observation >
[ 0.          0.23716009]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1903 #########################################
< action >
[-0.05        0.00094973]
< returned_observation >
[ 0.          0.23810982]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1904 #########################################
< action >
[-0.05      -0.0008309]
< returned_observation >
[ 0.          0.23727891]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1905 #########################################
< action >
[-0.05       0.0023038]
< returned_observation >
[ 0.          0.23958271]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1906 #########################################
< action >
[-0.05        0.00050113]
< returned_observation >
[ 0.          0.24008384]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1907 #########################################
< action >
[-0.05        0.00213466]
< returned_observation >
[ 0.         0.2422185]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 1908 #########################################
< action >
[-0.05       -0.00076806]
< returned_observation >
[ 0.          0.24145045]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 1909 #########################################
< action >
[-0.05       -0.00074429]
< returned_observation >
[ 0.          0.24070615]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1910 #########################################
< action >
[-0.05        0.00024806]
< returned_observation >
[ 0.          0.24095422]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1911 #########################################
< action >
[-0.05        0.00164305]
< returned_observation >
[ 0.          0.24259727]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1912 #########################################
< action >
[-0.05       -0.00067907]
< returned_observation >
[ 0.          0.24191819]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1913 #########################################
< action >
[-0.05        0.00062382]
< returned_observation >
[ 0.          0.24254202]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1914 #########################################
< action >
[-0.05       -0.00138666]
< returned_observation >
[ 0.          0.24115535]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1915 #########################################
< action >
[-0.05        0.00080456]
< returned_observation >
[ 0.          0.24195991]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1916 #########################################
< action >
[-0.05       -0.00089484]
< returned_observation >
[ 0.          0.24106508]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1917 #########################################
< action >
[-0.05        0.00072136]
< returned_observation >
[ 0.          0.24178644]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1918 #########################################
< action >
[-0.05       -0.00030454]
< returned_observation >
[ 0.         0.2414819]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1919 #########################################
< action >
[-0.05       -0.00073637]
< returned_observation >
[ 0.          0.24074553]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1920 #########################################
< action >
[-0.05       -0.00113246]
< returned_observation >
[ 0.          0.23961307]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1921 #########################################
< action >
[-0.05        0.00122916]
< returned_observation >
[ 0.          0.24084223]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1922 #########################################
< action >
[-0.05       -0.00372405]
< returned_observation >
[ 0.          0.23711818]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1923 #########################################
< action >
[-0.05        0.00101179]
< returned_observation >
[ 0.          0.23812996]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 1924 #########################################
< action >
[-0.05       -0.00353444]
< returned_observation >
[ 0.          0.23459552]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1925 #########################################
< action >
[-0.05        0.00045675]
< returned_observation >
[ 0.          0.23505227]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1926 #########################################
< action >
[-0.05       -0.00251805]
< returned_observation >
[ 0.          0.23253422]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1927 #########################################
< action >
[-0.05       -0.00085896]
< returned_observation >
[ 0.          0.23167526]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1928 #########################################
< action >
[-0.05       -0.00044755]
< returned_observation >
[ 0.          0.23122771]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1929 #########################################
< action >
[-0.05      -0.0006343]
< returned_observation >
[ 0.         0.2305934]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1930 #########################################
< action >
[-0.05        0.00048215]
< returned_observation >
[ 0.          0.23107556]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1931 #########################################
< action >
[-0.05       -0.00136663]
< returned_observation >
[ 0.          0.22970892]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1932 #########################################
< action >
[-0.05       -0.00068507]
< returned_observation >
[ 0.          0.22902385]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1933 #########################################
< action >
[-0.05       -0.00171936]
< returned_observation >
[ 0.          0.22730449]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1934 #########################################
< action >
[-0.05        0.00128397]
< returned_observation >
[ 0.          0.22858846]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 1935 #########################################
< action >
[-0.05      -0.0033312]
< returned_observation >
[ 0.          0.22525726]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1936 #########################################
< action >
[-0.05        0.00185394]
< returned_observation >
[ 0.         0.2271112]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1937 #########################################
< action >
[-0.05       -0.00297437]
< returned_observation >
[ 0.          0.22413683]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1938 #########################################
< action >
[ -5.00000000e-02   2.30431557e-05]
< returned_observation >
[ 0.          0.22415988]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1939 #########################################
< action >
[-0.05       -0.00276381]
< returned_observation >
[ 0.          0.22139606]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 1940 #########################################
< action >
[-0.05        0.00042407]
< returned_observation >
[ 0.          0.22182013]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 1941 #########################################
< action >
[-0.05       -0.00389949]
< returned_observation >
[ 0.          0.21792065]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1942 #########################################
< action >
[ -5.00000000e-02  -6.05821609e-05]
< returned_observation >
[ 0.          0.21786006]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 1943 #########################################
< action >
[-0.05      -0.0053036]
< returned_observation >
[ 0.          0.21255646]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1944 #########################################
< action >
[-0.05       0.0014959]
< returned_observation >
[ 0.          0.21405236]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1945 #########################################
< action >
[-0.05       -0.00621941]
< returned_observation >
[ 0.          0.20783295]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 1946 #########################################
< action >
[-0.05        0.00249017]
< returned_observation >
[ 0.          0.21032312]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 1947 #########################################
< action >
[-0.05       -0.00607857]
< returned_observation >
[ 0.          0.20424455]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1948 #########################################
< action >
[-0.05        0.00234995]
< returned_observation >
[ 0.         0.2065945]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1949 #########################################
< action >
[-0.05       -0.00476907]
< returned_observation >
[ 0.          0.20182544]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1950 #########################################
< action >
[-0.05        0.00111532]
< returned_observation >
[ 0.          0.20294076]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1951 #########################################
< action >
[-0.05       -0.00529847]
< returned_observation >
[ 0.          0.19764228]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1952 #########################################
< action >
[-0.05        0.00315368]
< returned_observation >
[ 0.          0.20079597]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1953 #########################################
< action >
[-0.05      -0.0063592]
< returned_observation >
[ 0.          0.19443676]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1954 #########################################
< action >
[-0.05        0.00484588]
< returned_observation >
[ 0.          0.19928264]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1955 #########################################
< action >
[-0.05       -0.00670485]
< returned_observation >
[ 0.          0.19257779]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1956 #########################################
< action >
[-0.05       0.0039995]
< returned_observation >
[ 0.          0.19657729]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 72 infomation #####################
{'nb_episode_steps': 100, 'min_reward': -12.600000000000001, 'episode_reward': -780.0999999999998, 'ave_reward': -7.800999999999998, 'nb_steps': 1957, 'max_reward': 3.6000000000000014}
######################################### STEP 1957 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.69186215  0.09857903]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 1958 #########################################
< action >
[-0.04982901  0.04928941]
< returned_observation >
[ 0.64203314  0.14786844]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1959 #########################################
< action >
[-0.04970407  0.0488036 ]
< returned_observation >
[ 0.59232906  0.19667205]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 1960 #########################################
< action >
[-0.05        0.02022818]
< returned_observation >
[ 0.54232906  0.21690023]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1961 #########################################
< action >
[-0.05       -0.02139437]
< returned_observation >
[ 0.49232906  0.19550586]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1962 #########################################
< action >
[-0.05        0.01562905]
< returned_observation >
[ 0.44232906  0.21113492]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1963 #########################################
< action >
[-0.04920245 -0.01930267]
< returned_observation >
[ 0.39312661  0.19183225]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 1964 #########################################
< action >
[-0.04884687  0.01337292]
< returned_observation >
[ 0.34427974  0.20520516]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1965 #########################################
< action >
[-0.0490146  -0.01782161]
< returned_observation >
[ 0.29526515  0.18738355]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1966 #########################################
< action >
[-0.04892089  0.01422652]
< returned_observation >
[ 0.24634426  0.20161007]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1967 #########################################
< action >
[-0.04667673 -0.0173974 ]
< returned_observation >
[ 0.19966753  0.18421267]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1968 #########################################
< action >
[-0.04733989  0.0123428 ]
< returned_observation >
[ 0.15232764  0.19655548]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1969 #########################################
< action >
[-0.04660729 -0.01670936]
< returned_observation >
[ 0.10572034  0.17984612]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 1970 #########################################
< action >
[-0.04857892  0.01288677]
< returned_observation >
[ 0.05714142  0.19273289]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1971 #########################################
< action >
[-0.04538372 -0.01863765]
< returned_observation >
[ 0.0117577   0.17409524]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1972 #########################################
< action >
[-0.04843666  0.01193064]
< returned_observation >
[ 0.          0.18602589]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1973 #########################################
< action >
[-0.04669426 -0.01358157]
< returned_observation >
[ 0.          0.17244431]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1974 #########################################
< action >
[-0.04901347  0.01070397]
< returned_observation >
[ 0.          0.18314828]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 1975 #########################################
< action >
[-0.04766084 -0.01071711]
< returned_observation >
[ 0.          0.17243117]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 1976 #########################################
< action >
[-0.04867992  0.01102483]
< returned_observation >
[ 0.        0.183456]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1977 #########################################
< action >
[-0.04680057 -0.01280526]
< returned_observation >
[ 0.          0.17065074]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1978 #########################################
< action >
[-0.05        0.01283302]
< returned_observation >
[ 0.          0.18348375]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 1979 #########################################
< action >
[-0.04723899 -0.01412853]
< returned_observation >
[ 0.          0.16935522]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 1980 #########################################
< action >
[-0.04964019  0.01398827]
< returned_observation >
[ 0.          0.18334349]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 1981 #########################################
< action >
[-0.04808691 -0.01494088]
< returned_observation >
[ 0.          0.16840261]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1982 #########################################
< action >
[-0.05        0.01377468]
< returned_observation >
[ 0.          0.18217729]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 1983 #########################################
< action >
[-0.04680946 -0.01567252]
< returned_observation >
[ 0.          0.16650477]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 1984 #########################################
< action >
[-0.0490403   0.01295993]
< returned_observation >
[ 0.         0.1794647]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 1985 #########################################
< action >
[-0.04723506 -0.0148809 ]
< returned_observation >
[ 0.          0.16458381]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 1986 #########################################
< action >
[-0.04937559  0.01452259]
< returned_observation >
[ 0.         0.1791064]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 1987 #########################################
< action >
[-0.04465864 -0.02020695]
< returned_observation >
[ 0.          0.15889944]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 1988 #########################################
< action >
[-0.04674367  0.01901368]
< returned_observation >
[ 0.          0.17791312]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 1989 #########################################
< action >
[-0.04341    -0.01985022]
< returned_observation >
[ 0.         0.1580629]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 1990 #########################################
< action >
[-0.04670975  0.01846177]
< returned_observation >
[ 0.          0.17652467]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1991 #########################################
< action >
[-0.04359163 -0.02102272]
< returned_observation >
[ 0.          0.15550195]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 1992 #########################################
< action >
[-0.04659745  0.02067846]
< returned_observation >
[ 0.          0.17618041]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 1993 #########################################
< action >
[-0.04118118 -0.02108781]
< returned_observation >
[ 0.         0.1550926]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1994 #########################################
< action >
[-0.0449406   0.02132724]
< returned_observation >
[ 0.          0.17641984]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 1995 #########################################
< action >
[-0.04042094 -0.01999127]
< returned_observation >
[ 0.          0.15642857]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 1996 #########################################
< action >
[-0.04481873  0.01677783]
< returned_observation >
[ 0.         0.1732064]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 1997 #########################################
< action >
[-0.04164868 -0.01828803]
< returned_observation >
[ 0.          0.15491837]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 1998 #########################################
< action >
[-0.04494892  0.01876907]
< returned_observation >
[ 0.          0.17368743]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 1999 #########################################
< action >
[-0.0417782  -0.02118333]
< returned_observation >
[ 0.         0.1525041]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2000 #########################################
< action >
[-0.04475987  0.01860384]
< returned_observation >
[ 0.          0.17110794]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2001 #########################################
< action >
[-0.04135512 -0.02049415]
< returned_observation >
[ 0.          0.15061379]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2002 #########################################
< action >
[-0.04507287  0.01675535]
< returned_observation >
[ 0.          0.16736914]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2003 #########################################
< action >
[-0.04369432 -0.02022131]
< returned_observation >
[ 0.          0.14714782]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2004 #########################################
< action >
[-0.04704136  0.01758214]
< returned_observation >
[ 0.          0.16472997]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2005 #########################################
< action >
[-0.04444411 -0.02057793]
< returned_observation >
[ 0.          0.14415203]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2006 #########################################
< action >
[-0.04880583  0.01505635]
< returned_observation >
[ 0.          0.15920838]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2007 #########################################
< action >
[-0.04655506 -0.01874297]
< returned_observation >
[ 0.          0.14046541]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2008 #########################################
< action >
[-0.05        0.01468673]
< returned_observation >
[ 0.          0.15515214]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2009 #########################################
< action >
[-0.05       -0.02095239]
< returned_observation >
[ 0.          0.13419975]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2010 #########################################
< action >
[-0.05       0.0155957]
< returned_observation >
[ 0.          0.14979545]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2011 #########################################
< action >
[-0.05      -0.0215014]
< returned_observation >
[ 0.          0.12829406]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2012 #########################################
< action >
[-0.05        0.01742412]
< returned_observation >
[ 0.          0.14571818]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 2013 #########################################
< action >
[-0.05       -0.02424737]
< returned_observation >
[ 0.          0.12147081]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 2014 #########################################
< action >
[-0.05        0.01854914]
< returned_observation >
[ 0.          0.14001995]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2015 #########################################
< action >
[-0.04880455 -0.0219771 ]
< returned_observation >
[ 0.          0.11804285]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2016 #########################################
< action >
[-0.05        0.01888664]
< returned_observation >
[ 0.          0.13692949]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2017 #########################################
< action >
[-0.04884111 -0.02206884]
< returned_observation >
[ 0.          0.11486065]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2018 #########################################
< action >
[-0.04891335  0.0185868 ]
< returned_observation >
[ 0.          0.13344745]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2019 #########################################
< action >
[-0.047034  -0.0232766]
< returned_observation >
[ 0.          0.11017085]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2020 #########################################
< action >
[-0.04866693  0.01695555]
< returned_observation >
[ 0.          0.12712641]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2021 #########################################
< action >
[-0.04795511 -0.02317474]
< returned_observation >
[ 0.          0.10395167]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2022 #########################################
< action >
[-0.05        0.01713567]
< returned_observation >
[ 0.          0.12108734]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2023 #########################################
< action >
[-0.04863386 -0.02208704]
< returned_observation >
[ 0.          0.09900029]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2024 #########################################
< action >
[-0.04955537  0.01674938]
< returned_observation >
[ 0.          0.11574968]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2025 #########################################
< action >
[-0.04790251 -0.02325994]
< returned_observation >
[ 0.          0.09248974]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2026 #########################################
< action >
[-0.05        0.01659412]
< returned_observation >
[ 0.          0.10908386]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2027 #########################################
< action >
[-0.04929375 -0.02259791]
< returned_observation >
[ 0.          0.08648595]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2028 #########################################
< action >
[-0.05        0.01733251]
< returned_observation >
[ 0.          0.10381846]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 2029 #########################################
< action >
[-0.05       -0.02290604]
< returned_observation >
[ 0.          0.08091242]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2030 #########################################
< action >
[-0.05        0.01725591]
< returned_observation >
[ 0.          0.09816833]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2031 #########################################
< action >
[-0.05       -0.02148847]
< returned_observation >
[ 0.          0.07667986]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2032 #########################################
< action >
[-0.05        0.01024722]
< returned_observation >
[ 0.          0.08692708]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2033 #########################################
< action >
[-0.05       -0.01839449]
< returned_observation >
[ 0.          0.06853258]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2034 #########################################
< action >
[-0.0499628   0.01207213]
< returned_observation >
[ 0.          0.08060472]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2035 #########################################
< action >
[-0.04909434 -0.01834034]
< returned_observation >
[ 0.          0.06226438]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2036 #########################################
< action >
[-0.05        0.01207821]
< returned_observation >
[ 0.          0.07434259]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2037 #########################################
< action >
[-0.05      -0.0202861]
< returned_observation >
[ 0.          0.05405649]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2038 #########################################
< action >
[-0.05        0.01444421]
< returned_observation >
[ 0.          0.06850069]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2039 #########################################
< action >
[-0.0498191  -0.02051899]
< returned_observation >
[ 0.          0.04798171]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2040 #########################################
< action >
[-0.05        0.01258436]
< returned_observation >
[ 0.          0.06056607]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2041 #########################################
< action >
[-0.05       -0.01900207]
< returned_observation >
[ 0.        0.041564]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2042 #########################################
< action >
[-0.05        0.01213941]
< returned_observation >
[ 0.          0.05370341]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2043 #########################################
< action >
[-0.05       -0.01852305]
< returned_observation >
[ 0.          0.03518036]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2044 #########################################
< action >
[-0.05        0.01079627]
< returned_observation >
[ 0.          0.04597663]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2045 #########################################
< action >
[-0.05       -0.01540004]
< returned_observation >
[ 0.          0.03057659]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2046 #########################################
< action >
[-0.05        0.00750192]
< returned_observation >
[ 0.          0.03807851]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2047 #########################################
< action >
[-0.05       -0.01206591]
< returned_observation >
[ 0.         0.0260126]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2048 #########################################
< action >
[-0.04874879  0.0020654 ]
< returned_observation >
[ 0.        0.028078]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2049 #########################################
< action >
[-0.04838249 -0.00905392]
< returned_observation >
[ 0.          0.01902408]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2050 #########################################
< action >
[-0.04893206  0.00013426]
< returned_observation >
[ 0.          0.01915834]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2051 #########################################
< action >
[-0.04918572 -0.00582394]
< returned_observation >
[ 0.         0.0133344]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2052 #########################################
< action >
[-0.04904449 -0.00170614]
< returned_observation >
[ 0.          0.01162827]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2053 #########################################
< action >
[-0.05       -0.00426963]
< returned_observation >
[ 0.          0.00735864]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2054 #########################################
< action >
[-0.05       -0.00152861]
< returned_observation >
[ 0.          0.00583002]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 2055 #########################################
< action >
[-0.05       -0.00663671]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 73 infomation #####################
{'nb_episode_steps': 99, 'min_reward': -13.5, 'episode_reward': -869.3000000000002, 'ave_reward': -8.780808080808082, 'nb_steps': 2056, 'max_reward': 3.6000000000000014}
######################################### STEP 2056 #########################################
< action >
[-0.00408421 -0.05      ]
< returned_observation >
[ 0.70461319  0.78924335]
< reward >
-2.0
< running_reward >
-0.6
< done >
False
######################################### STEP 2057 #########################################
< action >
[-0.00220263 -0.04888776]
< returned_observation >
[ 0.70241055  0.74035558]
< reward >
-1.1000000000000014
< running_reward >
-0.3300000000000004
< done >
False
######################################### STEP 2058 #########################################
< action >
[-0.0011069 -0.05     ]
< returned_observation >
[ 0.70130365  0.69035558]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 2059 #########################################
< action >
[ 0.00076762 -0.05      ]
< returned_observation >
[ 0.70207128  0.64035558]
< reward >
-0.6999999999999993
< running_reward >
-0.20999999999999977
< done >
False
######################################### STEP 2060 #########################################
< action >
[ 0.00145648 -0.05      ]
< returned_observation >
[ 0.70352776  0.59035558]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2061 #########################################
< action >
[ 0.00136034 -0.05      ]
< returned_observation >
[ 0.7048881   0.54035558]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2062 #########################################
< action >
[ 0.00142021 -0.05      ]
< returned_observation >
[ 0.70630831  0.49035558]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2063 #########################################
< action >
[ 0.00027719 -0.05      ]
< returned_observation >
[ 0.7065855   0.44035558]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2064 #########################################
< action >
[-0.00214955 -0.05      ]
< returned_observation >
[ 0.70443595  0.39035558]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 2065 #########################################
< action >
[-0.00555872 -0.05      ]
< returned_observation >
[ 0.69887723  0.34035558]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2066 #########################################
< action >
[-0.00554442 -0.05      ]
< returned_observation >
[ 0.6933328   0.29035558]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2067 #########################################
< action >
[-0.00559115 -0.05      ]
< returned_observation >
[ 0.68774166  0.24035558]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2068 #########################################
< action >
[-0.00364944 -0.05      ]
< returned_observation >
[ 0.68409221  0.19035558]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 2069 #########################################
< action >
[-0.00373147 -0.05      ]
< returned_observation >
[ 0.68036075  0.14035558]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2070 #########################################
< action >
[-0.00592392 -0.05      ]
< returned_observation >
[ 0.67443682  0.09035558]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2071 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.62443682  0.04035558]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2072 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.57443682  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2073 #########################################
< action >
[-0.05       -0.04915399]
< returned_observation >
[ 0.52443682  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2074 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.47443682  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2075 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.42443682  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2076 #########################################
< action >
[-0.05       -0.04940427]
< returned_observation >
[ 0.37443682  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2077 #########################################
< action >
[-0.05       -0.04988003]
< returned_observation >
[ 0.32443682  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2078 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.27443682  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2079 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.22443682  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2080 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.17443682  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2081 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.12443682  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2082 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.07443682  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2083 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.02443682  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2084 #########################################
< action >
[-0.04915649 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
True
##################### episode 74 infomation #####################
{'nb_episode_steps': 29, 'min_reward': -13.5, 'episode_reward': -234.69999999999996, 'ave_reward': -8.09310344827586, 'nb_steps': 2085, 'max_reward': 3.6000000000000014}
######################################### STEP 2085 #########################################
< action >
[ 0.01065367 -0.05      ]
< returned_observation >
[ 0.17659155  0.73099794]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2086 #########################################
< action >
[ 0.0121126 -0.05     ]
< returned_observation >
[ 0.18870415  0.68099794]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2087 #########################################
< action >
[ 0.01216516 -0.05      ]
< returned_observation >
[ 0.20086931  0.63099794]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2088 #########################################
< action >
[ 0.01078348 -0.05      ]
< returned_observation >
[ 0.21165279  0.58099794]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2089 #########################################
< action >
[ 0.01058506 -0.05      ]
< returned_observation >
[ 0.22223785  0.53099794]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2090 #########################################
< action >
[ 0.00937543 -0.05      ]
< returned_observation >
[ 0.23161328  0.48099794]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2091 #########################################
< action >
[ 0.01082527 -0.05      ]
< returned_observation >
[ 0.24243855  0.43099794]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2092 #########################################
< action >
[ 0.01168104 -0.05      ]
< returned_observation >
[ 0.25411959  0.38099794]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 2093 #########################################
< action >
[ 0.01402665 -0.05      ]
< returned_observation >
[ 0.26814625  0.33099794]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2094 #########################################
< action >
[ 0.01498802 -0.05      ]
< returned_observation >
[ 0.28313427  0.28099794]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2095 #########################################
< action >
[ 0.01515766 -0.05      ]
< returned_observation >
[ 0.29829193  0.23099794]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2096 #########################################
< action >
[ 0.0153975 -0.05     ]
< returned_observation >
[ 0.31368942  0.18099794]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2097 #########################################
< action >
[ 0.01471372 -0.05      ]
< returned_observation >
[ 0.32840315  0.13099794]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2098 #########################################
< action >
[-0.00645473 -0.05      ]
< returned_observation >
[ 0.32194842  0.08099794]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2099 #########################################
< action >
[-0.04718762 -0.05      ]
< returned_observation >
[ 0.2747608   0.03099794]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 2100 #########################################
< action >
[-0.04851952 -0.05      ]
< returned_observation >
[ 0.22624128  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2101 #########################################
< action >
[-0.04699962 -0.05      ]
< returned_observation >
[ 0.17924165  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2102 #########################################
< action >
[-0.04699308 -0.05      ]
< returned_observation >
[ 0.13224857  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2103 #########################################
< action >
[-0.04697382 -0.05      ]
< returned_observation >
[ 0.08527476  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2104 #########################################
< action >
[-0.04739211 -0.05      ]
< returned_observation >
[ 0.03788265  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2105 #########################################
< action >
[-0.04879398 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
4.399999999999999
< running_reward >
1.3199999999999996
< done >
True
##################### episode 75 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -12.7, 'episode_reward': -198.29999999999998, 'ave_reward': -9.442857142857141, 'nb_steps': 2106, 'max_reward': 4.399999999999999}
######################################### STEP 2106 #########################################
< action >
[ 0.01264284 -0.05      ]
< returned_observation >
[ 0.29917946  0.25646975]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 2107 #########################################
< action >
[ 0.01343816 -0.04999292]
< returned_observation >
[ 0.31261762  0.20647683]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2108 #########################################
< action >
[ 0.01288158 -0.05      ]
< returned_observation >
[ 0.3254992   0.15647683]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2109 #########################################
< action >
[ 0.00795071 -0.05      ]
< returned_observation >
[ 0.3334499   0.10647683]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2110 #########################################
< action >
[-0.04007415 -0.05      ]
< returned_observation >
[ 0.29337575  0.05647683]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2111 #########################################
< action >
[-0.04554729 -0.05      ]
< returned_observation >
[ 0.24782846  0.00647683]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2112 #########################################
< action >
[-0.04427463 -0.04895729]
< returned_observation >
[ 0.20355383  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2113 #########################################
< action >
[-0.04581585 -0.04860145]
< returned_observation >
[ 0.15773798  0.        ]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 2114 #########################################
< action >
[-0.04602964 -0.05      ]
< returned_observation >
[ 0.11170834  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2115 #########################################
< action >
[-0.04645676 -0.04959195]
< returned_observation >
[ 0.06525158  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2116 #########################################
< action >
[-0.04782117 -0.04892141]
< returned_observation >
[ 0.01743041  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2117 #########################################
< action >
[-0.04871296 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
3.5
< running_reward >
1.05
< done >
True
##################### episode 76 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.899999999999999, 'episode_reward': -111.99999999999999, 'ave_reward': -9.333333333333332, 'nb_steps': 2118, 'max_reward': 3.5}
######################################### STEP 2118 #########################################
< action >
[-0.04913537 -0.05      ]
< returned_observation >
[ 0.6161261   0.06139217]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2119 #########################################
< action >
[-0.04957729 -0.05      ]
< returned_observation >
[ 0.56654881  0.01139217]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2120 #########################################
< action >
[-0.04955402 -0.04608384]
< returned_observation >
[ 0.51699478  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2121 #########################################
< action >
[-0.04975313 -0.04143642]
< returned_observation >
[ 0.46724165  0.        ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2122 #########################################
< action >
[-0.05       -0.04224083]
< returned_observation >
[ 0.41724165  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2123 #########################################
< action >
[-0.05       -0.04586034]
< returned_observation >
[ 0.36724165  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2124 #########################################
< action >
[-0.05       -0.04684016]
< returned_observation >
[ 0.31724165  0.        ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2125 #########################################
< action >
[-0.05       -0.04755923]
< returned_observation >
[ 0.26724165  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2126 #########################################
< action >
[-0.05       -0.04884023]
< returned_observation >
[ 0.21724165  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2127 #########################################
< action >
[-0.05       -0.04971638]
< returned_observation >
[ 0.16724165  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2128 #########################################
< action >
[-0.05       -0.04956342]
< returned_observation >
[ 0.11724165  0.        ]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2129 #########################################
< action >
[-0.04934272 -0.04881241]
< returned_observation >
[ 0.06789893  0.        ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 2130 #########################################
< action >
[-0.05       -0.04914867]
< returned_observation >
[ 0.01789893  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2131 #########################################
< action >
[-0.05       -0.04987479]
< returned_observation >
[ 0.  0.]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
True
##################### episode 77 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.5, 'episode_reward': -105.99999999999997, 'ave_reward': -7.571428571428569, 'nb_steps': 2132, 'max_reward': 3.5}
######################################### STEP 2132 #########################################
< action >
[-0.02334215 -0.04918173]
< returned_observation >
[ 0.6415303   0.83867507]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2133 #########################################
< action >
[-0.02359353 -0.0491088 ]
< returned_observation >
[ 0.61793677  0.78956627]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2134 #########################################
< action >
[-0.0241049 -0.0474907]
< returned_observation >
[ 0.59383187  0.74207557]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2135 #########################################
< action >
[-0.02368096 -0.04982269]
< returned_observation >
[ 0.57015091  0.69225288]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2136 #########################################
< action >
[-0.0235131  -0.04828439]
< returned_observation >
[ 0.54663781  0.64396849]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 2137 #########################################
< action >
[-0.02342586 -0.04768136]
< returned_observation >
[ 0.52321195  0.59628713]
< reward >
-0.5
< running_reward >
-0.15
< done >
False
######################################### STEP 2138 #########################################
< action >
[-0.02312599 -0.04511705]
< returned_observation >
[ 0.50008597  0.55117008]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2139 #########################################
< action >
[-0.02146118 -0.04549339]
< returned_observation >
[ 0.47862479  0.50567669]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2140 #########################################
< action >
[-0.01944014 -0.04650503]
< returned_observation >
[ 0.45918465  0.45917166]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2141 #########################################
< action >
[-0.01902323 -0.04731993]
< returned_observation >
[ 0.44016142  0.41185173]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2142 #########################################
< action >
[-0.01908468 -0.04896613]
< returned_observation >
[ 0.42107674  0.3628856 ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2143 #########################################
< action >
[-0.01610981 -0.04959323]
< returned_observation >
[ 0.40496693  0.31329237]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2144 #########################################
< action >
[-0.01394278 -0.0482835 ]
< returned_observation >
[ 0.39102415  0.26500887]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2145 #########################################
< action >
[-0.01317174 -0.04750924]
< returned_observation >
[ 0.3778524   0.21749963]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2146 #########################################
< action >
[-0.03307603 -0.04617234]
< returned_observation >
[ 0.34477638  0.17132729]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2147 #########################################
< action >
[-0.04444736 -0.04579827]
< returned_observation >
[ 0.30032901  0.12552902]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2148 #########################################
< action >
[-0.04503831 -0.04507241]
< returned_observation >
[ 0.2552907   0.08045661]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2149 #########################################
< action >
[-0.04436986 -0.04545244]
< returned_observation >
[ 0.21092085  0.03500417]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2150 #########################################
< action >
[-0.0448158  -0.04262297]
< returned_observation >
[ 0.16610505  0.        ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2151 #########################################
< action >
[-0.04633168 -0.03335475]
< returned_observation >
[ 0.11977337  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2152 #########################################
< action >
[-0.04662617 -0.03650619]
< returned_observation >
[ 0.0731472  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2153 #########################################
< action >
[-0.04629683 -0.03934838]
< returned_observation >
[ 0.02685037  0.        ]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2154 #########################################
< action >
[-0.04428405 -0.04140418]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 78 infomation #####################
{'nb_episode_steps': 23, 'min_reward': -12.5, 'episode_reward': -158.5, 'ave_reward': -6.891304347826087, 'nb_steps': 2155, 'max_reward': 3.5}
######################################### STEP 2155 #########################################
< action >
[-0.03761584 -0.05      ]
< returned_observation >
[ 0.65869543  0.39032788]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2156 #########################################
< action >
[-0.0356681  -0.04956799]
< returned_observation >
[ 0.62302733  0.34075989]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2157 #########################################
< action >
[-0.03923378 -0.04892628]
< returned_observation >
[ 0.58379355  0.29183361]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2158 #########################################
< action >
[-0.04687574 -0.04813929]
< returned_observation >
[ 0.53691781  0.24369431]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2159 #########################################
< action >
[-0.04936463 -0.0468049 ]
< returned_observation >
[ 0.48755318  0.19688942]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2160 #########################################
< action >
[-0.04865541 -0.04594102]
< returned_observation >
[ 0.43889777  0.1509484 ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2161 #########################################
< action >
[-0.0479514  -0.04660993]
< returned_observation >
[ 0.39094638  0.10433847]
< reward >
1.0
< running_reward >
0.3
< done >
False
######################################### STEP 2162 #########################################
< action >
[-0.0483488  -0.04848702]
< returned_observation >
[ 0.34259757  0.05585145]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2163 #########################################
< action >
[-0.04835194 -0.04728062]
< returned_observation >
[ 0.29424563  0.00857083]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2164 #########################################
< action >
[-0.04853921 -0.03313612]
< returned_observation >
[ 0.24570642  0.        ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2165 #########################################
< action >
[-0.04686052 -0.03335964]
< returned_observation >
[ 0.19884589  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2166 #########################################
< action >
[-0.04821628 -0.03902128]
< returned_observation >
[ 0.15062962  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2167 #########################################
< action >
[-0.05       -0.04305783]
< returned_observation >
[ 0.10062962  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2168 #########################################
< action >
[-0.05      -0.0460444]
< returned_observation >
[ 0.05062962  0.        ]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2169 #########################################
< action >
[-0.05       -0.04790233]
< returned_observation >
[ 0.00062962  0.        ]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2170 #########################################
< action >
[-0.04824896 -0.04870328]
< returned_observation >
[ 0.  0.]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
True
##################### episode 79 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.3, 'episode_reward': -87.6, 'ave_reward': -5.475, 'nb_steps': 2171, 'max_reward': 3.5}
######################################### STEP 2171 #########################################
< action >
[-0.04245796 -0.04849554]
< returned_observation >
[ 0.39575642  0.71660056]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2172 #########################################
< action >
[-0.04055991 -0.04794206]
< returned_observation >
[ 0.35519651  0.66865849]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2173 #########################################
< action >
[-0.03979918 -0.04734919]
< returned_observation >
[ 0.31539733  0.6213093 ]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 2174 #########################################
< action >
[-0.03615967 -0.04578667]
< returned_observation >
[ 0.27923766  0.57552263]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 2175 #########################################
< action >
[-0.03362075 -0.0462408 ]
< returned_observation >
[ 0.24561691  0.52928184]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2176 #########################################
< action >
[-0.03050528 -0.04642316]
< returned_observation >
[ 0.21511163  0.48285868]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2177 #########################################
< action >
[-0.02472525 -0.0468093 ]
< returned_observation >
[ 0.19038638  0.43604938]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 2178 #########################################
< action >
[-0.01938526 -0.04795363]
< returned_observation >
[ 0.17100112  0.38809576]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2179 #########################################
< action >
[-0.01447189 -0.04844156]
< returned_observation >
[ 0.15652923  0.3396542 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2180 #########################################
< action >
[-0.01057922 -0.04718287]
< returned_observation >
[ 0.14595001  0.29247133]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2181 #########################################
< action >
[-0.01084253 -0.04828108]
< returned_observation >
[ 0.13510748  0.24419025]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2182 #########################################
< action >
[-0.03451133 -0.04792568]
< returned_observation >
[ 0.10059615  0.19626457]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2183 #########################################
< action >
[-0.04583259 -0.04949662]
< returned_observation >
[ 0.05476356  0.14676795]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 2184 #########################################
< action >
[-0.04887959 -0.05      ]
< returned_observation >
[ 0.00588397  0.09676795]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2185 #########################################
< action >
[-0.04927593 -0.04984072]
< returned_observation >
[ 0.          0.04692722]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2186 #########################################
< action >
[-0.04954691 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 80 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -12.399999999999999, 'episode_reward': -90.3, 'ave_reward': -5.64375, 'nb_steps': 2187, 'max_reward': 3.6000000000000014}
######################################### STEP 2187 #########################################
< action >
[-0.05       -0.04489604]
< returned_observation >
[ 0.515642    0.04000812]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 2188 #########################################
< action >
[-0.05       -0.01329841]
< returned_observation >
[ 0.465642    0.02670971]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2189 #########################################
< action >
[-0.05      -0.0094578]
< returned_observation >
[ 0.415642    0.01725191]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2190 #########################################
< action >
[-0.05       -0.01209108]
< returned_observation >
[ 0.365642    0.00516083]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2191 #########################################
< action >
[-0.04967843 -0.00706475]
< returned_observation >
[ 0.31596357  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2192 #########################################
< action >
[-0.04943697 -0.01294049]
< returned_observation >
[ 0.2665266  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2193 #########################################
< action >
[-0.04890735 -0.02331162]
< returned_observation >
[ 0.21761925  0.        ]
< reward >
-9.9
< running_reward >
-2.97
< done >
False
######################################### STEP 2194 #########################################
< action >
[-0.04780683 -0.03133789]
< returned_observation >
[ 0.16981243  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2195 #########################################
< action >
[-0.04806517 -0.03699366]
< returned_observation >
[ 0.12174726  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2196 #########################################
< action >
[-0.04852387 -0.0392787 ]
< returned_observation >
[ 0.07322339  0.        ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2197 #########################################
< action >
[-0.04779867 -0.04184887]
< returned_observation >
[ 0.02542473  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2198 #########################################
< action >
[-0.04678672 -0.04322507]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 81 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -12.8, 'episode_reward': -138.6, 'ave_reward': -11.549999999999999, 'nb_steps': 2199, 'max_reward': -9.9}
######################################### STEP 2199 #########################################
< action >
[-0.04866261 -0.04930945]
< returned_observation >
[ 0.53400848  0.76553425]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2200 #########################################
< action >
[-0.04789623 -0.04825335]
< returned_observation >
[ 0.48611225  0.7172809 ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2201 #########################################
< action >
[-0.04655554 -0.04900236]
< returned_observation >
[ 0.43955672  0.66827854]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2202 #########################################
< action >
[-0.04680629 -0.04743391]
< returned_observation >
[ 0.39275042  0.62084463]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2203 #########################################
< action >
[-0.04501148 -0.04715857]
< returned_observation >
[ 0.34773894  0.57368606]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 2204 #########################################
< action >
[-0.0447028  -0.04842848]
< returned_observation >
[ 0.30303615  0.52525758]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 2205 #########################################
< action >
[-0.04258777 -0.04805467]
< returned_observation >
[ 0.26044837  0.47720291]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2206 #########################################
< action >
[-0.04010844 -0.04957914]
< returned_observation >
[ 0.22033993  0.42762377]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2207 #########################################
< action >
[-0.03865175 -0.05      ]
< returned_observation >
[ 0.18168819  0.37762377]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2208 #########################################
< action >
[-0.03698723 -0.04921215]
< returned_observation >
[ 0.14470095  0.32841161]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2209 #########################################
< action >
[-0.04233213 -0.05      ]
< returned_observation >
[ 0.10236882  0.27841161]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2210 #########################################
< action >
[-0.04801467 -0.0499729 ]
< returned_observation >
[ 0.05435415  0.22843871]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2211 #########################################
< action >
[-0.05       -0.04923287]
< returned_observation >
[ 0.00435415  0.17920584]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2212 #########################################
< action >
[-0.04783751 -0.04956166]
< returned_observation >
[ 0.          0.12964418]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2213 #########################################
< action >
[-0.046443  -0.0496088]
< returned_observation >
[ 0.          0.08003538]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2214 #########################################
< action >
[-0.04759925 -0.05      ]
< returned_observation >
[ 0.          0.03003538]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2215 #########################################
< action >
[-0.04690795 -0.04989253]
< returned_observation >
[ 0.  0.]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
True
##################### episode 82 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.5, 'episode_reward': -129.3, 'ave_reward': -7.605882352941177, 'nb_steps': 2216, 'max_reward': 3.0}
######################################### STEP 2216 #########################################
< action >
[-0.05       -0.04964628]
< returned_observation >
[ 0.28706638  0.8779303 ]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 2217 #########################################
< action >
[-0.04996461 -0.04957052]
< returned_observation >
[ 0.23710177  0.82835978]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2218 #########################################
< action >
[-0.05       -0.04655125]
< returned_observation >
[ 0.18710177  0.78180853]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2219 #########################################
< action >
[-0.04963131 -0.04629362]
< returned_observation >
[ 0.13747046  0.7355149 ]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 2220 #########################################
< action >
[-0.04845762 -0.04543618]
< returned_observation >
[ 0.08901284  0.69007872]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2221 #########################################
< action >
[-0.05       -0.04618704]
< returned_observation >
[ 0.03901284  0.64389168]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 2222 #########################################
< action >
[-0.05       -0.04800947]
< returned_observation >
[ 0.          0.59588222]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 2223 #########################################
< action >
[-0.05       -0.04764535]
< returned_observation >
[ 0.          0.54823687]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2224 #########################################
< action >
[-0.05       -0.04959072]
< returned_observation >
[ 0.          0.49864615]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 2225 #########################################
< action >
[-0.04920218 -0.05      ]
< returned_observation >
[ 0.          0.44864615]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2226 #########################################
< action >
[-0.04940075 -0.05      ]
< returned_observation >
[ 0.          0.39864615]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2227 #########################################
< action >
[-0.04843463 -0.05      ]
< returned_observation >
[ 0.          0.34864615]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2228 #########################################
< action >
[-0.04876111 -0.05      ]
< returned_observation >
[ 0.          0.29864615]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2229 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.24864615]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2230 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.19864615]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2231 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.14864615]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2232 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.09864615]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2233 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.04864615]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2234 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-12.3
< running_reward >
-3.69
< done >
True
##################### episode 83 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -12.5, 'episode_reward': -114.19999999999999, 'ave_reward': -6.010526315789473, 'nb_steps': 2235, 'max_reward': 2.5}
######################################### STEP 2235 #########################################
< action >
[-0.04794872 -0.04916063]
< returned_observation >
[ 0.70276828  0.52490319]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2236 #########################################
< action >
[-0.04952254 -0.04949584]
< returned_observation >
[ 0.65324574  0.47540735]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2237 #########################################
< action >
[-0.0478636 -0.05     ]
< returned_observation >
[ 0.60538214  0.42540735]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2238 #########################################
< action >
[-0.04763857 -0.04999305]
< returned_observation >
[ 0.55774357  0.3754143 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2239 #########################################
< action >
[-0.04716965 -0.05      ]
< returned_observation >
[ 0.51057392  0.3254143 ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2240 #########################################
< action >
[-0.04624045 -0.05      ]
< returned_observation >
[ 0.46433347  0.2754143 ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2241 #########################################
< action >
[-0.04714505 -0.05      ]
< returned_observation >
[ 0.41718842  0.2254143 ]
< reward >
-13.600000000000001
< running_reward >
-4.08
< done >
False
######################################### STEP 2242 #########################################
< action >
[-0.0453375 -0.05     ]
< returned_observation >
[ 0.37185091  0.1754143 ]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2243 #########################################
< action >
[-0.04688547 -0.05      ]
< returned_observation >
[ 0.32496544  0.1254143 ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2244 #########################################
< action >
[-0.04606379 -0.05      ]
< returned_observation >
[ 0.27890165  0.0754143 ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2245 #########################################
< action >
[-0.04608845 -0.05      ]
< returned_observation >
[ 0.2328132  0.0254143]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2246 #########################################
< action >
[-0.0449411 -0.05     ]
< returned_observation >
[ 0.1878721  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2247 #########################################
< action >
[-0.04443467 -0.04977212]
< returned_observation >
[ 0.14343743  0.        ]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 2248 #########################################
< action >
[-0.0457228 -0.05     ]
< returned_observation >
[ 0.09771463  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2249 #########################################
< action >
[-0.04640686 -0.05      ]
< returned_observation >
[ 0.05130778  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2250 #########################################
< action >
[-0.04765342 -0.05      ]
< returned_observation >
[ 0.00365436  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2251 #########################################
< action >
[-0.04851229 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 84 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -13.600000000000001, 'episode_reward': -183.0, 'ave_reward': -10.764705882352942, 'nb_steps': 2252, 'max_reward': 3.5}
######################################### STEP 2252 #########################################
< action >
[-0.04941858  0.04854205]
< returned_observation >
[ 0.70222541  0.12769101]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2253 #########################################
< action >
[-0.05        0.02367257]
< returned_observation >
[ 0.65222541  0.15136358]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2254 #########################################
< action >
[-0.05       -0.02090767]
< returned_observation >
[ 0.60222541  0.13045591]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2255 #########################################
< action >
[-0.05       -0.00807527]
< returned_observation >
[ 0.55222541  0.12238064]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2256 #########################################
< action >
[-0.05       -0.01365774]
< returned_observation >
[ 0.50222541  0.1087229 ]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 2257 #########################################
< action >
[-0.05     -0.016395]
< returned_observation >
[ 0.45222541  0.0923279 ]
< reward >
-13.3
< running_reward >
-3.99
< done >
False
######################################### STEP 2258 #########################################
< action >
[-0.05       -0.01541587]
< returned_observation >
[ 0.40222541  0.07691203]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2259 #########################################
< action >
[-0.05       -0.01553634]
< returned_observation >
[ 0.35222541  0.0613757 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2260 #########################################
< action >
[-0.05       -0.01673758]
< returned_observation >
[ 0.30222541  0.04463812]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2261 #########################################
< action >
[-0.05       -0.01777047]
< returned_observation >
[ 0.25222541  0.02686765]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2262 #########################################
< action >
[-0.05       -0.01922566]
< returned_observation >
[ 0.20222541  0.00764199]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2263 #########################################
< action >
[-0.05       -0.02437041]
< returned_observation >
[ 0.15222541  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2264 #########################################
< action >
[-0.05       -0.03888091]
< returned_observation >
[ 0.10222541  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2265 #########################################
< action >
[-0.05       -0.04795943]
< returned_observation >
[ 0.05222541  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2266 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.00222541  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2267 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-12.5
< running_reward >
-3.75
< done >
True
##################### episode 85 infomation #####################
{'nb_episode_steps': 16, 'min_reward': -13.3, 'episode_reward': -157.4, 'ave_reward': -9.8375, 'nb_steps': 2268, 'max_reward': 3.1000000000000014}
######################################### STEP 2268 #########################################
< action >
[-0.05       -0.04955976]
< returned_observation >
[ 0.80938908  0.77194435]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 2269 #########################################
< action >
[-0.05       -0.04878323]
< returned_observation >
[ 0.75938908  0.72316112]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 2270 #########################################
< action >
[-0.04941641 -0.04806026]
< returned_observation >
[ 0.70997267  0.67510086]
< reward >
-13.2
< running_reward >
-3.9599999999999995
< done >
False
######################################### STEP 2271 #########################################
< action >
[-0.05       -0.04815862]
< returned_observation >
[ 0.65997267  0.62694224]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2272 #########################################
< action >
[-0.05      -0.0483417]
< returned_observation >
[ 0.60997267  0.57860054]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 2273 #########################################
< action >
[-0.05       -0.04833614]
< returned_observation >
[ 0.55997267  0.5302644 ]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 2274 #########################################
< action >
[-0.05       -0.04844726]
< returned_observation >
[ 0.50997267  0.48181714]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2275 #########################################
< action >
[-0.05       -0.04935014]
< returned_observation >
[ 0.45997267  0.43246699]
< reward >
0.8000000000000007
< running_reward >
0.2400000000000002
< done >
False
######################################### STEP 2276 #########################################
< action >
[-0.05       -0.04991067]
< returned_observation >
[ 0.40997267  0.38255632]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2277 #########################################
< action >
[-0.05       -0.04959901]
< returned_observation >
[ 0.35997267  0.33295731]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2278 #########################################
< action >
[-0.05       -0.04921496]
< returned_observation >
[ 0.30997267  0.28374235]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2279 #########################################
< action >
[-0.05       -0.04892901]
< returned_observation >
[ 0.25997267  0.23481334]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2280 #########################################
< action >
[-0.05      -0.0496729]
< returned_observation >
[ 0.20997267  0.18514044]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2281 #########################################
< action >
[-0.05       -0.04972892]
< returned_observation >
[ 0.15997267  0.13541152]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2282 #########################################
< action >
[-0.0494305  -0.04889276]
< returned_observation >
[ 0.11054217  0.08651876]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2283 #########################################
< action >
[-0.05       -0.04710954]
< returned_observation >
[ 0.06054217  0.03940922]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2284 #########################################
< action >
[-0.05       -0.04680662]
< returned_observation >
[ 0.01054217  0.        ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2285 #########################################
< action >
[-0.05       -0.04574045]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 86 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -13.2, 'episode_reward': -118.29999999999998, 'ave_reward': -6.572222222222221, 'nb_steps': 2286, 'max_reward': 3.1000000000000014}
######################################### STEP 2286 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.85987166  0.1786312 ]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2287 #########################################
< action >
[-0.05        0.04805089]
< returned_observation >
[ 0.80987166  0.22668209]
< reward >
-13.5
< running_reward >
-4.05
< done >
False
######################################### STEP 2288 #########################################
< action >
[-0.04968479  0.03344497]
< returned_observation >
[ 0.76018687  0.26012706]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 2289 #########################################
< action >
[-0.05       -0.01564163]
< returned_observation >
[ 0.71018687  0.24448543]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2290 #########################################
< action >
[-0.05       -0.01992653]
< returned_observation >
[ 0.66018687  0.2245589 ]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 2291 #########################################
< action >
[-0.05       -0.02104729]
< returned_observation >
[ 0.61018687  0.20351161]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2292 #########################################
< action >
[-0.05       -0.02354967]
< returned_observation >
[ 0.56018687  0.17996194]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2293 #########################################
< action >
[-0.05       -0.02516241]
< returned_observation >
[ 0.51018687  0.15479953]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2294 #########################################
< action >
[-0.05       -0.02267961]
< returned_observation >
[ 0.46018687  0.13211992]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2295 #########################################
< action >
[-0.05       -0.02310519]
< returned_observation >
[ 0.41018687  0.10901474]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2296 #########################################
< action >
[-0.05       -0.02311913]
< returned_observation >
[ 0.36018687  0.0858956 ]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 2297 #########################################
< action >
[-0.05       -0.02542696]
< returned_observation >
[ 0.31018687  0.06046864]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2298 #########################################
< action >
[-0.05       -0.02881687]
< returned_observation >
[ 0.26018687  0.03165177]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2299 #########################################
< action >
[-0.05       -0.02974196]
< returned_observation >
[ 0.21018687  0.00190981]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2300 #########################################
< action >
[-0.05       -0.03036672]
< returned_observation >
[ 0.16018687  0.        ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2301 #########################################
< action >
[-0.05       -0.04546207]
< returned_observation >
[ 0.11018687  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2302 #########################################
< action >
[-0.05       -0.04909899]
< returned_observation >
[ 0.06018687  0.        ]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2303 #########################################
< action >
[-0.05       -0.04930034]
< returned_observation >
[ 0.01018687  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2304 #########################################
< action >
[-0.05       -0.04905109]
< returned_observation >
[ 0.  0.]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
True
##################### episode 87 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -13.5, 'episode_reward': -127.90000000000003, 'ave_reward': -6.731578947368423, 'nb_steps': 2305, 'max_reward': 3.5}
######################################### STEP 2305 #########################################
< action >
[-0.05       -0.04832873]
< returned_observation >
[ 0.03178009  0.09008684]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2306 #########################################
< action >
[-0.05       -0.04474305]
< returned_observation >
[ 0.          0.04534379]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2307 #########################################
< action >
[-0.05       -0.04333478]
< returned_observation >
[ 0.          0.00200901]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2308 #########################################
< action >
[-0.05       -0.04482676]
< returned_observation >
[ 0.  0.]
< reward >
3.5
< running_reward >
1.05
< done >
True
##################### episode 88 infomation #####################
{'nb_episode_steps': 4, 'min_reward': -12.100000000000001, 'episode_reward': -30.6, 'ave_reward': -7.65, 'nb_steps': 2309, 'max_reward': 3.5}
######################################### STEP 2309 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.34937871  0.37430686]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2310 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.29937871  0.32430686]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 2311 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.24937871  0.27430686]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2312 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.19937871  0.22430686]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2313 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.14937871  0.17430686]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2314 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.09937871  0.12430686]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2315 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.04937871  0.07430686]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2316 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.02430686]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2317 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
True
##################### episode 89 infomation #####################
{'nb_episode_steps': 9, 'min_reward': -11.600000000000001, 'episode_reward': -74.9, 'ave_reward': -8.322222222222223, 'nb_steps': 2318, 'max_reward': 2.5}
######################################### STEP 2318 #########################################
< action >
[-0.05       0.0483898]
< returned_observation >
[ 0.51221838  0.17063335]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2319 #########################################
< action >
[-0.05       -0.02466348]
< returned_observation >
[ 0.46221838  0.14596987]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2320 #########################################
< action >
[-0.05      -0.0300483]
< returned_observation >
[ 0.41221838  0.11592157]
< reward >
-13.8
< running_reward >
-4.14
< done >
False
######################################### STEP 2321 #########################################
< action >
[-0.05       -0.02973023]
< returned_observation >
[ 0.36221838  0.08619134]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2322 #########################################
< action >
[-0.05       -0.03029208]
< returned_observation >
[ 0.31221838  0.05589926]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2323 #########################################
< action >
[-0.05       -0.03168077]
< returned_observation >
[ 0.26221838  0.02421849]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2324 #########################################
< action >
[-0.04935872 -0.03260221]
< returned_observation >
[ 0.21285966  0.        ]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2325 #########################################
< action >
[-0.05       -0.03769443]
< returned_observation >
[ 0.16285966  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2326 #########################################
< action >
[-0.05       -0.04541485]
< returned_observation >
[ 0.11285966  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2327 #########################################
< action >
[-0.05       -0.04615721]
< returned_observation >
[ 0.06285966  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2328 #########################################
< action >
[-0.05       -0.04650056]
< returned_observation >
[ 0.01285966  0.        ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2329 #########################################
< action >
[-0.05      -0.0460786]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 90 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -13.8, 'episode_reward': -138.9, 'ave_reward': -11.575000000000001, 'nb_steps': 2330, 'max_reward': -10.899999999999999}
######################################### STEP 2330 #########################################
< action >
[-0.04828023 -0.04823634]
< returned_observation >
[ 0.15311927  0.76340801]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2331 #########################################
< action >
[-0.04701901 -0.04863468]
< returned_observation >
[ 0.10610026  0.71477332]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2332 #########################################
< action >
[-0.04756398 -0.04713216]
< returned_observation >
[ 0.05853627  0.66764116]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2333 #########################################
< action >
[-0.04773932 -0.04897282]
< returned_observation >
[ 0.01079695  0.61866834]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2334 #########################################
< action >
[-0.04831776 -0.04763225]
< returned_observation >
[ 0.          0.57103609]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2335 #########################################
< action >
[-0.04728477 -0.04745966]
< returned_observation >
[ 0.          0.52357643]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2336 #########################################
< action >
[-0.04684108 -0.04810973]
< returned_observation >
[ 0.          0.47546671]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2337 #########################################
< action >
[-0.04622819 -0.04946832]
< returned_observation >
[ 0.          0.42599838]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2338 #########################################
< action >
[-0.04505618 -0.04790586]
< returned_observation >
[ 0.          0.37809252]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2339 #########################################
< action >
[-0.04491028 -0.04774058]
< returned_observation >
[ 0.          0.33035194]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2340 #########################################
< action >
[-0.04539313 -0.0490655 ]
< returned_observation >
[ 0.          0.28128644]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2341 #########################################
< action >
[-0.04621991 -0.04833824]
< returned_observation >
[ 0.         0.2329482]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2342 #########################################
< action >
[-0.04654153 -0.04793712]
< returned_observation >
[ 0.          0.18501109]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2343 #########################################
< action >
[-0.04647726 -0.04777978]
< returned_observation >
[ 0.          0.13723131]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2344 #########################################
< action >
[-0.04590516 -0.0485362 ]
< returned_observation >
[ 0.          0.08869511]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2345 #########################################
< action >
[-0.04407901 -0.04938823]
< returned_observation >
[ 0.          0.03930687]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2346 #########################################
< action >
[-0.04273691 -0.04793853]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 91 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.2, 'episode_reward': -139.6, 'ave_reward': -8.211764705882352, 'nb_steps': 2347, 'max_reward': 3.1999999999999993}
######################################### STEP 2347 #########################################
< action >
[-0.04959712 -0.05      ]
< returned_observation >
[ 0.41839046  0.75793821]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2348 #########################################
< action >
[-0.04895971 -0.0486447 ]
< returned_observation >
[ 0.36943075  0.70929351]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2349 #########################################
< action >
[-0.04772041 -0.04890244]
< returned_observation >
[ 0.32171034  0.66039107]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2350 #########################################
< action >
[-0.0471663  -0.04756433]
< returned_observation >
[ 0.27454403  0.61282674]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2351 #########################################
< action >
[-0.04692459 -0.04578958]
< returned_observation >
[ 0.22761944  0.56703716]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 2352 #########################################
< action >
[-0.04693974 -0.04591542]
< returned_observation >
[ 0.1806797   0.52112174]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2353 #########################################
< action >
[-0.04575972 -0.04697229]
< returned_observation >
[ 0.13491997  0.47414944]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2354 #########################################
< action >
[-0.04543932 -0.0480844 ]
< returned_observation >
[ 0.08948066  0.42606504]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2355 #########################################
< action >
[-0.04504851 -0.04805039]
< returned_observation >
[ 0.04443215  0.37801465]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2356 #########################################
< action >
[-0.04560851 -0.04736207]
< returned_observation >
[ 0.          0.33065258]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2357 #########################################
< action >
[-0.04598666 -0.04723064]
< returned_observation >
[ 0.          0.28342194]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2358 #########################################
< action >
[-0.04426961 -0.04773211]
< returned_observation >
[ 0.          0.23568984]
< reward >
3.8000000000000007
< running_reward >
1.1400000000000001
< done >
False
######################################### STEP 2359 #########################################
< action >
[-0.04418501 -0.04603623]
< returned_observation >
[ 0.         0.1896536]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2360 #########################################
< action >
[-0.04645599 -0.04492915]
< returned_observation >
[ 0.          0.14472445]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2361 #########################################
< action >
[-0.0466397  -0.04476939]
< returned_observation >
[ 0.          0.09995506]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2362 #########################################
< action >
[-0.04818371 -0.04538895]
< returned_observation >
[ 0.          0.05456611]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2363 #########################################
< action >
[-0.04895332 -0.04654175]
< returned_observation >
[ 0.          0.00802436]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2364 #########################################
< action >
[-0.04989198 -0.04600675]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 92 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -12.399999999999999, 'episode_reward': -76.39999999999998, 'ave_reward': -4.244444444444444, 'nb_steps': 2365, 'max_reward': 3.8000000000000007}
######################################### STEP 2365 #########################################
< action >
[-0.04768081 -0.04832704]
< returned_observation >
[ 0.          0.50326569]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2366 #########################################
< action >
[-0.04752688 -0.04701499]
< returned_observation >
[ 0.         0.4562507]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2367 #########################################
< action >
[-0.0474861  -0.04656025]
< returned_observation >
[ 0.          0.40969046]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 2368 #########################################
< action >
[-0.04807198 -0.04635945]
< returned_observation >
[ 0.          0.36333101]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2369 #########################################
< action >
[-0.04856547 -0.04612366]
< returned_observation >
[ 0.          0.31720735]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2370 #########################################
< action >
[-0.04849195 -0.04627406]
< returned_observation >
[ 0.          0.27093329]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2371 #########################################
< action >
[-0.0482526  -0.04629295]
< returned_observation >
[ 0.          0.22464034]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2372 #########################################
< action >
[-0.04919581 -0.04455404]
< returned_observation >
[ 0.         0.1800863]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2373 #########################################
< action >
[-0.05       -0.04597347]
< returned_observation >
[ 0.          0.13411283]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2374 #########################################
< action >
[-0.0492593  -0.04672318]
< returned_observation >
[ 0.          0.08738965]
< reward >
-10.8
< running_reward >
-3.24
< done >
False
######################################### STEP 2375 #########################################
< action >
[-0.04936733 -0.04689095]
< returned_observation >
[ 0.         0.0404987]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2376 #########################################
< action >
[-0.04969996 -0.04726162]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 93 infomation #####################
{'nb_episode_steps': 12, 'min_reward': -11.8, 'episode_reward': -108.8, 'ave_reward': -9.066666666666666, 'nb_steps': 2377, 'max_reward': 3.3999999999999986}
######################################### STEP 2377 #########################################
< action >
[-0.05       -0.04986866]
< returned_observation >
[ 0.88193215  0.5323068 ]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2378 #########################################
< action >
[-0.05       -0.04889896]
< returned_observation >
[ 0.83193215  0.48340784]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 2379 #########################################
< action >
[-0.04996269 -0.04783932]
< returned_observation >
[ 0.78196946  0.43556851]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2380 #########################################
< action >
[-0.05       -0.04837801]
< returned_observation >
[ 0.73196946  0.3871905 ]
< reward >
-14.399999999999999
< running_reward >
-4.319999999999999
< done >
False
######################################### STEP 2381 #########################################
< action >
[-0.05       -0.04875539]
< returned_observation >
[ 0.68196946  0.33843511]
< reward >
-14.2
< running_reward >
-4.26
< done >
False
######################################### STEP 2382 #########################################
< action >
[-0.05       -0.04787813]
< returned_observation >
[ 0.63196946  0.29055698]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2383 #########################################
< action >
[-0.05       -0.04773321]
< returned_observation >
[ 0.58196946  0.24282377]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2384 #########################################
< action >
[-0.04985761 -0.04671842]
< returned_observation >
[ 0.53211185  0.19610536]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2385 #########################################
< action >
[-0.04844781 -0.04284708]
< returned_observation >
[ 0.48366404  0.15325827]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2386 #########################################
< action >
[-0.0477764  -0.03991215]
< returned_observation >
[ 0.43588764  0.11334612]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2387 #########################################
< action >
[-0.04878753 -0.03779857]
< returned_observation >
[ 0.38710011  0.07554754]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2388 #########################################
< action >
[-0.0492994  -0.03850365]
< returned_observation >
[ 0.3378007   0.03704389]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2389 #########################################
< action >
[-0.05       -0.03829513]
< returned_observation >
[ 0.2878007  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2390 #########################################
< action >
[-0.05       -0.03844056]
< returned_observation >
[ 0.2378007  0.       ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2391 #########################################
< action >
[-0.05       -0.04821741]
< returned_observation >
[ 0.1878007  0.       ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2392 #########################################
< action >
[-0.05       -0.04745674]
< returned_observation >
[ 0.1378007  0.       ]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2393 #########################################
< action >
[-0.05       -0.04808082]
< returned_observation >
[ 0.0878007  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2394 #########################################
< action >
[-0.04983317 -0.04667797]
< returned_observation >
[ 0.03796753  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2395 #########################################
< action >
[-0.05       -0.04586164]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 94 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -14.399999999999999, 'episode_reward': -171.00000000000003, 'ave_reward': -9.000000000000002, 'nb_steps': 2396, 'max_reward': 3.6000000000000014}
######################################### STEP 2396 #########################################
< action >
[-0.04737332 -0.04995645]
< returned_observation >
[ 0.15872241  0.66780111]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2397 #########################################
< action >
[-0.04714989 -0.04983681]
< returned_observation >
[ 0.11157251  0.6179643 ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2398 #########################################
< action >
[-0.04650479 -0.05      ]
< returned_observation >
[ 0.06506773  0.5679643 ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2399 #########################################
< action >
[-0.04711692 -0.04963836]
< returned_observation >
[ 0.01795081  0.51832594]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2400 #########################################
< action >
[-0.04460984 -0.05      ]
< returned_observation >
[ 0.          0.46832594]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2401 #########################################
< action >
[-0.04584 -0.05   ]
< returned_observation >
[ 0.          0.41832594]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2402 #########################################
< action >
[-0.0464411 -0.05     ]
< returned_observation >
[ 0.          0.36832594]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 2403 #########################################
< action >
[-0.04640616 -0.04959331]
< returned_observation >
[ 0.          0.31873263]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2404 #########################################
< action >
[-0.04696838 -0.04966162]
< returned_observation >
[ 0.          0.26907101]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2405 #########################################
< action >
[-0.04766857 -0.04742114]
< returned_observation >
[ 0.          0.22164987]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2406 #########################################
< action >
[-0.0481637 -0.05     ]
< returned_observation >
[ 0.          0.17164987]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 2407 #########################################
< action >
[-0.04737657 -0.04868894]
< returned_observation >
[ 0.          0.12296093]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2408 #########################################
< action >
[-0.04648133 -0.04852879]
< returned_observation >
[ 0.          0.07443214]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2409 #########################################
< action >
[-0.04630482 -0.04873054]
< returned_observation >
[ 0.         0.0257016]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2410 #########################################
< action >
[-0.04671678 -0.0498067 ]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 95 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -11.5, 'episode_reward': -86.2, 'ave_reward': -5.746666666666667, 'nb_steps': 2411, 'max_reward': 3.6000000000000014}
######################################### STEP 2411 #########################################
< action >
[-0.0495824  -0.04988111]
< returned_observation >
[ 0.32940345  0.61850284]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2412 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.27940345  0.56850284]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2413 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.22940345  0.51850284]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2414 #########################################
< action >
[-0.0491317 -0.05     ]
< returned_observation >
[ 0.18027175  0.46850284]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2415 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.13027175  0.41850284]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2416 #########################################
< action >
[-0.05       -0.04962062]
< returned_observation >
[ 0.08027175  0.36888223]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2417 #########################################
< action >
[-0.05       -0.04944612]
< returned_observation >
[ 0.03027175  0.31943611]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2418 #########################################
< action >
[-0.0499652  -0.04875905]
< returned_observation >
[ 0.          0.27067706]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2419 #########################################
< action >
[-0.05       -0.04981997]
< returned_observation >
[ 0.          0.22085709]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2420 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.17085709]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2421 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.12085709]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2422 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.07085709]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2423 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.02085709]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2424 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 96 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.3, 'episode_reward': -160.5, 'ave_reward': -11.464285714285714, 'nb_steps': 2425, 'max_reward': -11.100000000000001}
######################################### STEP 2425 #########################################
< action >
[-0.04729435 -0.05      ]
< returned_observation >
[ 0.          0.58590036]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 2426 #########################################
< action >
[-0.04624876 -0.05      ]
< returned_observation >
[ 0.          0.53590036]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 2427 #########################################
< action >
[-0.04622682 -0.05      ]
< returned_observation >
[ 0.          0.48590036]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2428 #########################################
< action >
[-0.04442723 -0.05      ]
< returned_observation >
[ 0.          0.43590036]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2429 #########################################
< action >
[-0.04092831 -0.05      ]
< returned_observation >
[ 0.          0.38590036]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2430 #########################################
< action >
[-0.03962573 -0.05      ]
< returned_observation >
[ 0.          0.33590036]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2431 #########################################
< action >
[-0.04110912 -0.04910308]
< returned_observation >
[ 0.          0.28679728]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2432 #########################################
< action >
[-0.0444895  -0.04937776]
< returned_observation >
[ 0.          0.23741952]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2433 #########################################
< action >
[-0.04497291 -0.04989219]
< returned_observation >
[ 0.          0.18752733]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2434 #########################################
< action >
[-0.04629757 -0.05      ]
< returned_observation >
[ 0.          0.13752733]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 2435 #########################################
< action >
[-0.04562681 -0.04866339]
< returned_observation >
[ 0.          0.08886395]
< reward >
-12.8
< running_reward >
-3.84
< done >
False
######################################### STEP 2436 #########################################
< action >
[-0.0436698  -0.04940112]
< returned_observation >
[ 0.          0.03946282]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2437 #########################################
< action >
[-0.04652215 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 97 infomation #####################
{'nb_episode_steps': 13, 'min_reward': -12.8, 'episode_reward': -66.5, 'ave_reward': -5.115384615384615, 'nb_steps': 2438, 'max_reward': 3.1000000000000014}
######################################### STEP 2438 #########################################
< action >
[-0.04872926 -0.05      ]
< returned_observation >
[ 0.          0.69478066]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 2439 #########################################
< action >
[-0.0485212 -0.05     ]
< returned_observation >
[ 0.          0.64478066]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 2440 #########################################
< action >
[-0.04743016 -0.05      ]
< returned_observation >
[ 0.          0.59478066]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 2441 #########################################
< action >
[-0.04696697 -0.05      ]
< returned_observation >
[ 0.          0.54478066]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2442 #########################################
< action >
[-0.0485738 -0.05     ]
< returned_observation >
[ 0.          0.49478066]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 2443 #########################################
< action >
[-0.04692644 -0.05      ]
< returned_observation >
[ 0.          0.44478066]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2444 #########################################
< action >
[-0.04394103 -0.05      ]
< returned_observation >
[ 0.          0.39478066]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2445 #########################################
< action >
[-0.04302214 -0.05      ]
< returned_observation >
[ 0.          0.34478066]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2446 #########################################
< action >
[-0.04428193 -0.05      ]
< returned_observation >
[ 0.          0.29478066]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2447 #########################################
< action >
[-0.04976255 -0.05      ]
< returned_observation >
[ 0.          0.24478066]
< reward >
1.8999999999999986
< running_reward >
0.5699999999999995
< done >
False
######################################### STEP 2448 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.19478066]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2449 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.14478066]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2450 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.09478066]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2451 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.04478066]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2452 #########################################
< action >
[-0.05       -0.04965025]
< returned_observation >
[ 0.  0.]
< reward >
-11.8
< running_reward >
-3.54
< done >
True
##################### episode 98 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -12.3, 'episode_reward': -80.2, 'ave_reward': -5.346666666666667, 'nb_steps': 2453, 'max_reward': 3.5}
######################################### STEP 2453 #########################################
< action >
[-0.05        0.04933357]
< returned_observation >
[ 0.422913    0.17108793]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2454 #########################################
< action >
[-0.05        0.00740337]
< returned_observation >
[ 0.372913   0.1784913]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2455 #########################################
< action >
[-0.05       -0.04534986]
< returned_observation >
[ 0.322913    0.13314144]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2456 #########################################
< action >
[-0.04931116 -0.04771614]
< returned_observation >
[ 0.27360184  0.0854253 ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2457 #########################################
< action >
[-0.04892346 -0.04796261]
< returned_observation >
[ 0.22467838  0.03746269]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2458 #########################################
< action >
[-0.04835253 -0.0491622 ]
< returned_observation >
[ 0.17632585  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2459 #########################################
< action >
[-0.04975355 -0.05      ]
< returned_observation >
[ 0.1265723  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2460 #########################################
< action >
[-0.04818958 -0.05      ]
< returned_observation >
[ 0.07838271  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2461 #########################################
< action >
[-0.04825661 -0.05      ]
< returned_observation >
[ 0.0301261  0.       ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2462 #########################################
< action >
[-0.04799057 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 99 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -12.5, 'episode_reward': -115.80000000000001, 'ave_reward': -11.580000000000002, 'nb_steps': 2463, 'max_reward': -11.2}
######################################### STEP 2463 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.49263593  0.11677444]
< reward >
0.5
< running_reward >
0.15
< done >
False
######################################### STEP 2464 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.44263593  0.16677444]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2465 #########################################
< action >
[-0.05       -0.00451816]
< returned_observation >
[ 0.39263593  0.16225628]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2466 #########################################
< action >
[-0.05       -0.04559597]
< returned_observation >
[ 0.34263593  0.11666032]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2467 #########################################
< action >
[-0.05       -0.04714418]
< returned_observation >
[ 0.29263593  0.06951614]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2468 #########################################
< action >
[-0.05       -0.04839402]
< returned_observation >
[ 0.24263593  0.02112212]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2469 #########################################
< action >
[-0.04908582 -0.04930411]
< returned_observation >
[ 0.1935501  0.       ]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2470 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.1435501  0.       ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2471 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0935501  0.       ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2472 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0435501  0.       ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2473 #########################################
< action >
[-0.05       -0.04913185]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 100 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -12.3, 'episode_reward': -72.19999999999999, 'ave_reward': -6.563636363636363, 'nb_steps': 2474, 'max_reward': 3.6000000000000014}
######################################### STEP 2474 #########################################
< action >
[-0.05      -0.0497154]
< returned_observation >
[ 0.60336487  0.94637092]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2475 #########################################
< action >
[-0.05       -0.04991903]
< returned_observation >
[ 0.55336487  0.89645189]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 2476 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.50336487  0.84645189]
< reward >
-1.3000000000000007
< running_reward >
-0.3900000000000002
< done >
False
######################################### STEP 2477 #########################################
< action >
[-0.05       -0.04900425]
< returned_observation >
[ 0.45336487  0.79744764]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2478 #########################################
< action >
[-0.05       -0.04945815]
< returned_observation >
[ 0.40336487  0.74798949]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2479 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.35336487  0.69798949]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2480 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.30336487  0.64798949]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2481 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.25336487  0.59798949]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2482 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.20336487  0.54798949]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2483 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.15336487  0.49798949]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2484 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.10336487  0.44798949]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2485 #########################################
< action >
[-0.04699562 -0.05      ]
< returned_observation >
[ 0.05636925  0.39798949]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2486 #########################################
< action >
[-0.04114732 -0.04835254]
< returned_observation >
[ 0.01522193  0.34963695]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2487 #########################################
< action >
[-0.04346246 -0.04940195]
< returned_observation >
[ 0.        0.300235]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2488 #########################################
< action >
[-0.04895704 -0.04984403]
< returned_observation >
[ 0.          0.25039097]
< reward >
2.5
< running_reward >
0.75
< done >
False
######################################### STEP 2489 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.20039097]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2490 #########################################
< action >
[-0.05      -0.0495323]
< returned_observation >
[ 0.          0.15085868]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2491 #########################################
< action >
[-0.05       -0.04784691]
< returned_observation >
[ 0.          0.10301177]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2492 #########################################
< action >
[-0.05       -0.04629588]
< returned_observation >
[ 0.          0.05671589]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2493 #########################################
< action >
[-0.05       -0.04620108]
< returned_observation >
[ 0.         0.0105148]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2494 #########################################
< action >
[-0.05       -0.04658536]
< returned_observation >
[ 0.  0.]
< reward >
-11.8
< running_reward >
-3.54
< done >
True
##################### episode 101 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -12.100000000000001, 'episode_reward': -107.99999999999999, 'ave_reward': -5.142857142857142, 'nb_steps': 2495, 'max_reward': 3.1999999999999993}
######################################### STEP 2495 #########################################
< action >
[-0.04825772 -0.04440628]
< returned_observation >
[ 0.72113961  0.52936783]
< reward >
1.8000000000000007
< running_reward >
0.5400000000000001
< done >
False
######################################### STEP 2496 #########################################
< action >
[-0.04717117 -0.04313798]
< returned_observation >
[ 0.67396845  0.48622985]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2497 #########################################
< action >
[-0.0460874 -0.0442458]
< returned_observation >
[ 0.62788104  0.44198406]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2498 #########################################
< action >
[-0.04524361 -0.04595521]
< returned_observation >
[ 0.58263744  0.39602885]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2499 #########################################
< action >
[-0.04436771 -0.04627727]
< returned_observation >
[ 0.53826973  0.34975157]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2500 #########################################
< action >
[-0.0448639  -0.04646589]
< returned_observation >
[ 0.49340583  0.30328568]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2501 #########################################
< action >
[-0.04563793 -0.04737087]
< returned_observation >
[ 0.44776791  0.25591481]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2502 #########################################
< action >
[-0.04727308 -0.04778911]
< returned_observation >
[ 0.40049483  0.2081257 ]
< reward >
-12.399999999999999
< running_reward >
-3.7199999999999993
< done >
False
######################################### STEP 2503 #########################################
< action >
[-0.04690211 -0.04738385]
< returned_observation >
[ 0.35359272  0.16074185]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2504 #########################################
< action >
[-0.04810931 -0.04791357]
< returned_observation >
[ 0.30548341  0.11282828]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2505 #########################################
< action >
[-0.04654026 -0.04679724]
< returned_observation >
[ 0.25894315  0.06603104]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2506 #########################################
< action >
[-0.0473813  -0.04696448]
< returned_observation >
[ 0.21156184  0.01906656]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2507 #########################################
< action >
[-0.04696256 -0.04689298]
< returned_observation >
[ 0.16459929  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2508 #########################################
< action >
[-0.04984457 -0.04577247]
< returned_observation >
[ 0.11475472  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2509 #########################################
< action >
[-0.05       -0.04658346]
< returned_observation >
[ 0.06475472  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2510 #########################################
< action >
[-0.05       -0.04657155]
< returned_observation >
[ 0.01475472  0.        ]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2511 #########################################
< action >
[-0.05       -0.04618693]
< returned_observation >
[ 0.  0.]
< reward >
-10.8
< running_reward >
-3.24
< done >
True
##################### episode 102 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.5, 'episode_reward': -141.8, 'ave_reward': -8.341176470588236, 'nb_steps': 2512, 'max_reward': 3.6000000000000014}
######################################### STEP 2512 #########################################
< action >
[-0.04132846 -0.04982525]
< returned_observation >
[ 0.0613068   0.65000882]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2513 #########################################
< action >
[-0.0389176  -0.04789752]
< returned_observation >
[ 0.02238921  0.60211131]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2514 #########################################
< action >
[-0.03577273 -0.04775248]
< returned_observation >
[ 0.          0.55435883]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2515 #########################################
< action >
[-0.03269722 -0.04656019]
< returned_observation >
[ 0.          0.50779863]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2516 #########################################
< action >
[-0.03050223 -0.04525121]
< returned_observation >
[ 0.          0.46254743]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2517 #########################################
< action >
[-0.02721081 -0.04524882]
< returned_observation >
[ 0.         0.4172986]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2518 #########################################
< action >
[-0.02328454 -0.04614522]
< returned_observation >
[ 0.          0.37115339]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2519 #########################################
< action >
[-0.01869952 -0.0468727 ]
< returned_observation >
[ 0.          0.32428069]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2520 #########################################
< action >
[-0.03665237 -0.0472159 ]
< returned_observation >
[ 0.          0.27706479]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2521 #########################################
< action >
[-0.04512278 -0.04769372]
< returned_observation >
[ 0.          0.22937107]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2522 #########################################
< action >
[-0.04724968 -0.04775608]
< returned_observation >
[ 0.          0.18161499]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2523 #########################################
< action >
[-0.04754454 -0.04681452]
< returned_observation >
[ 0.          0.13480047]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2524 #########################################
< action >
[-0.04724712 -0.04792824]
< returned_observation >
[ 0.          0.08687223]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 2525 #########################################
< action >
[-0.04712959 -0.04766353]
< returned_observation >
[ 0.         0.0392087]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2526 #########################################
< action >
[-0.04690994 -0.04636149]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 103 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -13.100000000000001, 'episode_reward': -146.4, 'ave_reward': -9.76, 'nb_steps': 2527, 'max_reward': 3.1999999999999993}
######################################### STEP 2527 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.61116787  0.09909713]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2528 #########################################
< action >
[-0.04882902  0.0490885 ]
< returned_observation >
[ 0.56233885  0.14818563]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2529 #########################################
< action >
[-0.04771529  0.0495187 ]
< returned_observation >
[ 0.51462356  0.19770433]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2530 #########################################
< action >
[-0.04750397  0.05      ]
< returned_observation >
[ 0.46711959  0.24770433]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2531 #########################################
< action >
[-0.04813068  0.00100165]
< returned_observation >
[ 0.4189889   0.24870598]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2532 #########################################
< action >
[-0.04563609 -0.04174454]
< returned_observation >
[ 0.37335281  0.20696144]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2533 #########################################
< action >
[-0.04560274 -0.04400566]
< returned_observation >
[ 0.32775007  0.16295578]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2534 #########################################
< action >
[-0.04659996 -0.04621178]
< returned_observation >
[ 0.28115011  0.116744  ]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2535 #########################################
< action >
[-0.04552936 -0.04840598]
< returned_observation >
[ 0.23562075  0.06833802]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2536 #########################################
< action >
[-0.04331354 -0.04866832]
< returned_observation >
[ 0.19230721  0.0196697 ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2537 #########################################
< action >
[-0.042648   -0.04759504]
< returned_observation >
[ 0.14965921  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2538 #########################################
< action >
[-0.04306052 -0.04867456]
< returned_observation >
[ 0.10659869  0.        ]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2539 #########################################
< action >
[-0.04152796 -0.0468617 ]
< returned_observation >
[ 0.06507073  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2540 #########################################
< action >
[-0.03957501 -0.04693605]
< returned_observation >
[ 0.02549572  0.        ]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 2541 #########################################
< action >
[-0.03860187 -0.04682004]
< returned_observation >
[ 0.  0.]
< reward >
-12.3
< running_reward >
-3.69
< done >
True
##################### episode 104 infomation #####################
{'nb_episode_steps': 15, 'min_reward': -12.3, 'episode_reward': -129.3, 'ave_reward': -8.620000000000001, 'nb_steps': 2542, 'max_reward': 3.6999999999999993}
######################################### STEP 2542 #########################################
< action >
[-0.0486062   0.04380541]
< returned_observation >
[ 0.74369311  0.562522  ]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 2543 #########################################
< action >
[-0.04799518 -0.00201736]
< returned_observation >
[ 0.69569792  0.56050464]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2544 #########################################
< action >
[-0.04850296 -0.02787258]
< returned_observation >
[ 0.64719496  0.53263206]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2545 #########################################
< action >
[-0.04836284 -0.02951301]
< returned_observation >
[ 0.59883212  0.50311905]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2546 #########################################
< action >
[-0.04755309 -0.03060299]
< returned_observation >
[ 0.55127903  0.47251606]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2547 #########################################
< action >
[-0.04795417 -0.04092455]
< returned_observation >
[ 0.50332486  0.4315915 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2548 #########################################
< action >
[-0.04744383 -0.0459378 ]
< returned_observation >
[ 0.45588103  0.3856537 ]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2549 #########################################
< action >
[-0.0480539  -0.04980491]
< returned_observation >
[ 0.40782713  0.33584879]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2550 #########################################
< action >
[-0.04773069 -0.05      ]
< returned_observation >
[ 0.36009644  0.28584879]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2551 #########################################
< action >
[-0.04773445 -0.05      ]
< returned_observation >
[ 0.31236199  0.23584879]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2552 #########################################
< action >
[-0.04819709 -0.05      ]
< returned_observation >
[ 0.2641649   0.18584879]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2553 #########################################
< action >
[-0.04937973 -0.05      ]
< returned_observation >
[ 0.21478518  0.13584879]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2554 #########################################
< action >
[-0.04958239 -0.05      ]
< returned_observation >
[ 0.16520278  0.08584879]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2555 #########################################
< action >
[-0.04939531 -0.05      ]
< returned_observation >
[ 0.11580748  0.03584879]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2556 #########################################
< action >
[-0.04887172 -0.05      ]
< returned_observation >
[ 0.06693576  0.        ]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 2557 #########################################
< action >
[-0.04905852 -0.05      ]
< returned_observation >
[ 0.01787724  0.        ]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2558 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 105 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -13.100000000000001, 'episode_reward': -136.09999999999997, 'ave_reward': -8.005882352941175, 'nb_steps': 2559, 'max_reward': 3.5}
######################################### STEP 2559 #########################################
< action >
[-0.05       -0.04954983]
< returned_observation >
[ 0.37586769  0.73863734]
< reward >
0.3000000000000007
< running_reward >
0.0900000000000002
< done >
False
######################################### STEP 2560 #########################################
< action >
[-0.05       -0.04876943]
< returned_observation >
[ 0.32586769  0.68986791]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2561 #########################################
< action >
[-0.05       -0.04809163]
< returned_observation >
[ 0.27586769  0.64177628]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2562 #########################################
< action >
[-0.05       -0.04807591]
< returned_observation >
[ 0.22586769  0.59370037]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2563 #########################################
< action >
[-0.04739566 -0.04752162]
< returned_observation >
[ 0.17847203  0.54617875]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2564 #########################################
< action >
[-0.04211636 -0.04654445]
< returned_observation >
[ 0.13635567  0.4996343 ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2565 #########################################
< action >
[-0.03374058 -0.0475451 ]
< returned_observation >
[ 0.1026151  0.4520892]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2566 #########################################
< action >
[-0.02419776 -0.04931246]
< returned_observation >
[ 0.07841734  0.40277674]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2567 #########################################
< action >
[-0.03060545 -0.04801329]
< returned_observation >
[ 0.0478119   0.35476345]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2568 #########################################
< action >
[-0.03844235 -0.0476821 ]
< returned_observation >
[ 0.00936955  0.30708135]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2569 #########################################
< action >
[-0.04176614 -0.04679537]
< returned_observation >
[ 0.          0.26028598]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2570 #########################################
< action >
[-0.04845995 -0.04561171]
< returned_observation >
[ 0.          0.21467428]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2571 #########################################
< action >
[-0.04957479 -0.04509052]
< returned_observation >
[ 0.          0.16958376]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2572 #########################################
< action >
[-0.05       -0.04467509]
< returned_observation >
[ 0.          0.12490867]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2573 #########################################
< action >
[-0.05       -0.04541085]
< returned_observation >
[ 0.          0.07949782]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2574 #########################################
< action >
[-0.05       -0.04580946]
< returned_observation >
[ 0.          0.03368837]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 2575 #########################################
< action >
[-0.05       -0.04669957]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 106 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -12.3, 'episode_reward': -88.89999999999999, 'ave_reward': -5.2294117647058815, 'nb_steps': 2576, 'max_reward': 3.3000000000000007}
######################################### STEP 2576 #########################################
< action >
[-0.05       -0.04924564]
< returned_observation >
[ 0.36156922  0.43178064]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2577 #########################################
< action >
[-0.05       -0.04733201]
< returned_observation >
[ 0.31156922  0.38444863]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2578 #########################################
< action >
[-0.05       -0.04700404]
< returned_observation >
[ 0.26156922  0.33744458]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2579 #########################################
< action >
[-0.05       -0.04730589]
< returned_observation >
[ 0.21156922  0.29013869]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2580 #########################################
< action >
[-0.05       -0.04806447]
< returned_observation >
[ 0.16156922  0.24207422]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2581 #########################################
< action >
[-0.05      -0.0468899]
< returned_observation >
[ 0.11156922  0.19518433]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2582 #########################################
< action >
[-0.05       -0.04700433]
< returned_observation >
[ 0.06156922  0.14817999]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2583 #########################################
< action >
[-0.049947   -0.04446074]
< returned_observation >
[ 0.01162222  0.10371925]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2584 #########################################
< action >
[-0.04990166 -0.0459627 ]
< returned_observation >
[ 0.          0.05775655]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2585 #########################################
< action >
[-0.04872668 -0.0471395 ]
< returned_observation >
[ 0.          0.01061705]
< reward >
-13.899999999999999
< running_reward >
-4.169999999999999
< done >
False
######################################### STEP 2586 #########################################
< action >
[-0.04769192 -0.04691989]
< returned_observation >
[ 0.  0.]
< reward >
-12.3
< running_reward >
-3.69
< done >
True
##################### episode 107 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -13.899999999999999, 'episode_reward': -102.89999999999999, 'ave_reward': -9.354545454545454, 'nb_steps': 2587, 'max_reward': 3.3000000000000007}
######################################### STEP 2587 #########################################
< action >
[-0.0473503 -0.05     ]
< returned_observation >
[ 0.13427854  0.2713189 ]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2588 #########################################
< action >
[-0.04734891 -0.05      ]
< returned_observation >
[ 0.08692963  0.2213189 ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2589 #########################################
< action >
[-0.04914386 -0.05      ]
< returned_observation >
[ 0.03778577  0.1713189 ]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2590 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.         0.1213189]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2591 #########################################
< action >
[-0.04967877 -0.05      ]
< returned_observation >
[ 0.         0.0713189]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2592 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.         0.0213189]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2593 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 108 infomation #####################
{'nb_episode_steps': 7, 'min_reward': -12.100000000000001, 'episode_reward': -66.9, 'ave_reward': -9.557142857142859, 'nb_steps': 2594, 'max_reward': 2.8999999999999986}
######################################### STEP 2594 #########################################
< action >
[-0.05        0.04996952]
< returned_observation >
[ 0.795533    0.23687327]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2595 #########################################
< action >
[-0.0493069   0.04918878]
< returned_observation >
[ 0.7462261   0.28606205]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 2596 #########################################
< action >
[-0.05        0.04715606]
< returned_observation >
[ 0.6962261   0.33321811]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2597 #########################################
< action >
[-0.05       0.0480562]
< returned_observation >
[ 0.6462261   0.38127431]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2598 #########################################
< action >
[-0.05        0.04706435]
< returned_observation >
[ 0.5962261   0.42833866]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 2599 #########################################
< action >
[-0.05        0.02668362]
< returned_observation >
[ 0.5462261   0.45502229]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2600 #########################################
< action >
[-0.05       -0.02654998]
< returned_observation >
[ 0.4962261   0.42847231]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2601 #########################################
< action >
[-0.05       -0.04667132]
< returned_observation >
[ 0.4462261   0.38180098]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2602 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.3962261   0.33180098]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2603 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.3462261   0.28180098]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2604 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.2962261   0.23180098]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 2605 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.2462261   0.18180098]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2606 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.1962261   0.13180098]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2607 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.1462261   0.08180098]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2608 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0962261   0.03180098]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2609 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.0462261  0.       ]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2610 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.8
< running_reward >
-3.54
< done >
True
##################### episode 109 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -11.899999999999999, 'episode_reward': -86.19999999999999, 'ave_reward': -5.070588235294117, 'nb_steps': 2611, 'max_reward': 3.3999999999999986}
######################################### STEP 2611 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.36729106  0.93903451]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2612 #########################################
< action >
[-0.05       -0.04793164]
< returned_observation >
[ 0.31729106  0.89110286]
< reward >
1.3999999999999986
< running_reward >
0.41999999999999954
< done >
False
######################################### STEP 2613 #########################################
< action >
[-0.05       -0.04834756]
< returned_observation >
[ 0.26729106  0.8427553 ]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2614 #########################################
< action >
[-0.05      -0.0482699]
< returned_observation >
[ 0.21729106  0.79448541]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 2615 #########################################
< action >
[-0.05       -0.04819519]
< returned_observation >
[ 0.16729106  0.74629022]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 2616 #########################################
< action >
[-0.04959367 -0.046974  ]
< returned_observation >
[ 0.1176974   0.69931621]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2617 #########################################
< action >
[-0.04564295 -0.04718215]
< returned_observation >
[ 0.07205445  0.65213406]
< reward >
3.3000000000000007
< running_reward >
0.9900000000000002
< done >
False
######################################### STEP 2618 #########################################
< action >
[-0.03625457 -0.04681362]
< returned_observation >
[ 0.03579987  0.60532045]
< reward >
1.3000000000000007
< running_reward >
0.3900000000000002
< done >
False
######################################### STEP 2619 #########################################
< action >
[-0.02414293 -0.04644054]
< returned_observation >
[ 0.01165695  0.55887991]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2620 #########################################
< action >
[-0.01128635 -0.04728145]
< returned_observation >
[  3.70595533e-04   5.11598461e-01]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2621 #########################################
< action >
[-0.0061873  -0.04670078]
< returned_observation >
[ 0.          0.46489769]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 2622 #########################################
< action >
[-0.00380194 -0.04680401]
< returned_observation >
[ 0.          0.41809367]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2623 #########################################
< action >
[ 0.0002005 -0.0472121]
< returned_observation >
[  2.00504065e-04   3.70881574e-01]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2624 #########################################
< action >
[-0.00694998 -0.04699528]
< returned_observation >
[ 0.         0.3238863]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2625 #########################################
< action >
[-0.033701   -0.04627242]
< returned_observation >
[ 0.          0.27761387]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2626 #########################################
< action >
[-0.04216787 -0.04440949]
< returned_observation >
[ 0.          0.23320439]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2627 #########################################
< action >
[-0.04331312 -0.04352948]
< returned_observation >
[ 0.          0.18967491]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2628 #########################################
< action >
[-0.04131812 -0.04357247]
< returned_observation >
[ 0.          0.14610243]
< reward >
3.0
< running_reward >
0.8999999999999999
< done >
False
######################################### STEP 2629 #########################################
< action >
[-0.04085029 -0.04245736]
< returned_observation >
[ 0.          0.10364508]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2630 #########################################
< action >
[-0.04010154 -0.04314408]
< returned_observation >
[ 0.        0.060501]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2631 #########################################
< action >
[-0.03961804 -0.0443757 ]
< returned_observation >
[ 0.         0.0161253]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2632 #########################################
< action >
[-0.03927597 -0.04465287]
< returned_observation >
[ 0.  0.]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
True
##################### episode 110 infomation #####################
{'nb_episode_steps': 22, 'min_reward': -11.8, 'episode_reward': -42.99999999999999, 'ave_reward': -1.9545454545454541, 'nb_steps': 2633, 'max_reward': 3.6999999999999993}
######################################### STEP 2633 #########################################
< action >
[-0.04845933 -0.0495546 ]
< returned_observation >
[ 0.18814048  0.86727773]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2634 #########################################
< action >
[-0.04743715 -0.04972288]
< returned_observation >
[ 0.14070333  0.81755485]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2635 #########################################
< action >
[-0.04491386 -0.05      ]
< returned_observation >
[ 0.09578948  0.76755485]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2636 #########################################
< action >
[-0.03599817 -0.05      ]
< returned_observation >
[ 0.0597913   0.71755485]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 2637 #########################################
< action >
[-0.02560144 -0.05      ]
< returned_observation >
[ 0.03418986  0.66755485]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2638 #########################################
< action >
[-0.01696897 -0.04933351]
< returned_observation >
[ 0.01722089  0.61822133]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2639 #########################################
< action >
[-0.01059256 -0.05      ]
< returned_observation >
[ 0.00662833  0.56822133]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2640 #########################################
< action >
[-0.00585797 -0.05      ]
< returned_observation >
[ 0.00077036  0.51822133]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2641 #########################################
< action >
[-0.00179915 -0.05      ]
< returned_observation >
[ 0.          0.46822133]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2642 #########################################
< action >
[ 0.00252801 -0.05      ]
< returned_observation >
[ 0.00252801  0.41822133]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2643 #########################################
< action >
[ 0.00360027 -0.05      ]
< returned_observation >
[ 0.00612828  0.36822133]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2644 #########################################
< action >
[-0.00079041 -0.05      ]
< returned_observation >
[ 0.00533786  0.31822133]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2645 #########################################
< action >
[-0.03774675 -0.05      ]
< returned_observation >
[ 0.          0.26822133]
< reward >
2.1000000000000014
< running_reward >
0.6300000000000004
< done >
False
######################################### STEP 2646 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.21822133]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2647 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.16822133]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2648 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.11822133]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2649 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.06822133]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2650 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.01822133]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2651 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
True
##################### episode 111 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -12.100000000000001, 'episode_reward': -148.5, 'ave_reward': -7.815789473684211, 'nb_steps': 2652, 'max_reward': 3.5}
######################################### STEP 2652 #########################################
< action >
[-0.04888973  0.05      ]
< returned_observation >
[ 0.86950773  0.14129634]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2653 #########################################
< action >
[-0.04897529  0.05      ]
< returned_observation >
[ 0.82053245  0.19129634]
< reward >
3.3999999999999986
< running_reward >
1.0199999999999996
< done >
False
######################################### STEP 2654 #########################################
< action >
[-0.04933824  0.05      ]
< returned_observation >
[ 0.7711942   0.24129634]
< reward >
-13.399999999999999
< running_reward >
-4.02
< done >
False
######################################### STEP 2655 #########################################
< action >
[-0.0476563  0.05     ]
< returned_observation >
[ 0.7235379   0.29129634]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2656 #########################################
< action >
[-0.04803481  0.05      ]
< returned_observation >
[ 0.67550309  0.34129634]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 2657 #########################################
< action >
[-0.04976394  0.05      ]
< returned_observation >
[ 0.62573916  0.39129634]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 2658 #########################################
< action >
[-0.04937147  0.0379256 ]
< returned_observation >
[ 0.57636769  0.42922194]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2659 #########################################
< action >
[-0.05       -0.02005337]
< returned_observation >
[ 0.52636769  0.40916858]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2660 #########################################
< action >
[-0.05       -0.02886349]
< returned_observation >
[ 0.47636769  0.38030509]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2661 #########################################
< action >
[-0.05       -0.03183178]
< returned_observation >
[ 0.42636769  0.34847331]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2662 #########################################
< action >
[-0.05       -0.04255018]
< returned_observation >
[ 0.37636769  0.30592313]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2663 #########################################
< action >
[-0.05       -0.04500029]
< returned_observation >
[ 0.32636769  0.26092284]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2664 #########################################
< action >
[-0.05       -0.04523697]
< returned_observation >
[ 0.27636769  0.21568587]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2665 #########################################
< action >
[-0.05       -0.04621558]
< returned_observation >
[ 0.22636769  0.16947029]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2666 #########################################
< action >
[-0.05       -0.04670936]
< returned_observation >
[ 0.17636769  0.12276093]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2667 #########################################
< action >
[-0.05       -0.04595828]
< returned_observation >
[ 0.12636769  0.07680265]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2668 #########################################
< action >
[-0.05       -0.04587014]
< returned_observation >
[ 0.07636769  0.03093251]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2669 #########################################
< action >
[-0.05       -0.04757289]
< returned_observation >
[ 0.02636769  0.        ]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2670 #########################################
< action >
[-0.05       -0.04852294]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 112 infomation #####################
{'nb_episode_steps': 19, 'min_reward': -13.399999999999999, 'episode_reward': -135.6, 'ave_reward': -7.136842105263158, 'nb_steps': 2671, 'max_reward': 3.6000000000000014}
######################################### STEP 2671 #########################################
< action >
[-0.04822597 -0.04938675]
< returned_observation >
[ 0.41542675  0.45282958]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2672 #########################################
< action >
[-0.04925145 -0.04945439]
< returned_observation >
[ 0.3661753  0.4033752]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2673 #########################################
< action >
[-0.04815628 -0.04936013]
< returned_observation >
[ 0.31801902  0.35401507]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2674 #########################################
< action >
[-0.04783673 -0.0487848 ]
< returned_observation >
[ 0.27018229  0.30523026]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2675 #########################################
< action >
[-0.04854408 -0.04864833]
< returned_observation >
[ 0.22163821  0.25658194]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2676 #########################################
< action >
[-0.04976323 -0.04794117]
< returned_observation >
[ 0.17187498  0.20864076]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2677 #########################################
< action >
[-0.05       -0.04838977]
< returned_observation >
[ 0.12187498  0.16025099]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2678 #########################################
< action >
[-0.05      -0.0490691]
< returned_observation >
[ 0.07187498  0.11118189]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2679 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.02187498  0.06118189]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2680 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.01118189]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2681 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 113 infomation #####################
{'nb_episode_steps': 11, 'min_reward': -12.0, 'episode_reward': -82.9, 'ave_reward': -7.536363636363637, 'nb_steps': 2682, 'max_reward': 3.6000000000000014}
######################################### STEP 2682 #########################################
< action >
[-0.05       0.0107308]
< returned_observation >
[ 0.26366895  0.05807033]
< reward >
-12.899999999999999
< running_reward >
-3.869999999999999
< done >
False
######################################### STEP 2683 #########################################
< action >
[-0.04878881 -0.04755549]
< returned_observation >
[ 0.21488014  0.01051485]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2684 #########################################
< action >
[-0.04732636 -0.05      ]
< returned_observation >
[ 0.16755379  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2685 #########################################
< action >
[-0.04626557 -0.05      ]
< returned_observation >
[ 0.12128822  0.        ]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2686 #########################################
< action >
[-0.04666058 -0.05      ]
< returned_observation >
[ 0.07462764  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2687 #########################################
< action >
[-0.0457991 -0.05     ]
< returned_observation >
[ 0.02882854  0.        ]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2688 #########################################
< action >
[-0.04593967 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 114 infomation #####################
{'nb_episode_steps': 7, 'min_reward': -12.899999999999999, 'episode_reward': -82.69999999999999, 'ave_reward': -11.814285714285713, 'nb_steps': 2689, 'max_reward': -11.0}
######################################### STEP 2689 #########################################
< action >
[-0.05     -0.049867]
< returned_observation >
[ 0.19168564  0.04566264]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2690 #########################################
< action >
[-0.04895839 -0.04900541]
< returned_observation >
[ 0.14272725  0.        ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2691 #########################################
< action >
[-0.04777917 -0.04852963]
< returned_observation >
[ 0.09494808  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2692 #########################################
< action >
[-0.0464454  -0.04797115]
< returned_observation >
[ 0.04850268  0.        ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2693 #########################################
< action >
[-0.04696476 -0.04842497]
< returned_observation >
[ 0.00153791  0.        ]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2694 #########################################
< action >
[-0.04658188 -0.04796834]
< returned_observation >
[ 0.  0.]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
True
##################### episode 115 infomation #####################
{'nb_episode_steps': 6, 'min_reward': -11.600000000000001, 'episode_reward': -68.6, 'ave_reward': -11.433333333333332, 'nb_steps': 2695, 'max_reward': -11.3}
######################################### STEP 2695 #########################################
< action >
[-0.04784604 -0.05      ]
< returned_observation >
[ 0.19040386  0.75779109]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2696 #########################################
< action >
[-0.0449739 -0.0488599]
< returned_observation >
[ 0.14542997  0.70893118]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2697 #########################################
< action >
[-0.0404559  -0.04849954]
< returned_observation >
[ 0.10497407  0.66043164]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2698 #########################################
< action >
[-0.03302898 -0.0485482 ]
< returned_observation >
[ 0.07194508  0.61188345]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2699 #########################################
< action >
[-0.0233521  -0.04745375]
< returned_observation >
[ 0.04859299  0.56442969]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2700 #########################################
< action >
[-0.01452704 -0.04798488]
< returned_observation >
[ 0.03406594  0.51644481]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2701 #########################################
< action >
[-0.00776019 -0.04816137]
< returned_observation >
[ 0.02630576  0.46828343]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2702 #########################################
< action >
[ 0.00034642 -0.04872677]
< returned_observation >
[ 0.02665217  0.41955667]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2703 #########################################
< action >
[ 0.00386345 -0.04854085]
< returned_observation >
[ 0.03051562  0.37101582]
< reward >
-11.600000000000001
< running_reward >
-3.4800000000000004
< done >
False
######################################### STEP 2704 #########################################
< action >
[ 0.00532214 -0.04813279]
< returned_observation >
[ 0.03583776  0.32288303]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2705 #########################################
< action >
[-0.02332303 -0.0473075 ]
< returned_observation >
[ 0.01251474  0.27557553]
< reward >
2.0
< running_reward >
0.6
< done >
False
######################################### STEP 2706 #########################################
< action >
[-0.03845274 -0.04695025]
< returned_observation >
[ 0.          0.22862528]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2707 #########################################
< action >
[-0.04772306 -0.04848359]
< returned_observation >
[ 0.          0.18014169]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2708 #########################################
< action >
[-0.05       -0.04766668]
< returned_observation >
[ 0.          0.13247501]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2709 #########################################
< action >
[-0.04979934 -0.047316  ]
< returned_observation >
[ 0.          0.08515901]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2710 #########################################
< action >
[-0.04983188 -0.04816301]
< returned_observation >
[ 0.          0.03699601]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2711 #########################################
< action >
[-0.05       -0.04855137]
< returned_observation >
[ 0.  0.]
< reward >
-11.0
< running_reward >
-3.3
< done >
True
##################### episode 116 infomation #####################
{'nb_episode_steps': 17, 'min_reward': -11.7, 'episode_reward': -84.3, 'ave_reward': -4.958823529411765, 'nb_steps': 2712, 'max_reward': 3.5}
######################################### STEP 2712 #########################################
< action >
[-0.04973682  0.05      ]
< returned_observation >
[ 0.84524146  0.09322289]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 2713 #########################################
< action >
[-0.05        0.04944757]
< returned_observation >
[ 0.79524146  0.14267046]
< reward >
0.1999999999999993
< running_reward >
0.05999999999999978
< done >
False
######################################### STEP 2714 #########################################
< action >
[-0.05        0.04872754]
< returned_observation >
[ 0.74524146  0.191398  ]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2715 #########################################
< action >
[-0.05        0.04849191]
< returned_observation >
[ 0.69524146  0.23988991]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2716 #########################################
< action >
[-0.05        0.04950866]
< returned_observation >
[ 0.64524146  0.28939856]
< reward >
2.8999999999999986
< running_reward >
0.8699999999999996
< done >
False
######################################### STEP 2717 #########################################
< action >
[-0.04977357  0.0478605 ]
< returned_observation >
[ 0.59546789  0.33725906]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2718 #########################################
< action >
[-0.05        0.04526709]
< returned_observation >
[ 0.54546789  0.38252615]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2719 #########################################
< action >
[-0.05        0.01325664]
< returned_observation >
[ 0.49546789  0.39578279]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2720 #########################################
< action >
[-0.04941251 -0.0304114 ]
< returned_observation >
[ 0.44605538  0.36537139]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2721 #########################################
< action >
[-0.05       -0.03196324]
< returned_observation >
[ 0.39605538  0.33340815]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2722 #########################################
< action >
[-0.05       -0.04514709]
< returned_observation >
[ 0.34605538  0.28826106]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2723 #########################################
< action >
[-0.04919763 -0.04928795]
< returned_observation >
[ 0.29685775  0.23897311]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2724 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.24685775  0.18897311]
< reward >
-12.7
< running_reward >
-3.8099999999999996
< done >
False
######################################### STEP 2725 #########################################
< action >
[-0.0492899  -0.04937594]
< returned_observation >
[ 0.19756784  0.13959717]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2726 #########################################
< action >
[-0.04953404 -0.04935635]
< returned_observation >
[ 0.1480338   0.09024081]
< reward >
-12.0
< running_reward >
-3.5999999999999996
< done >
False
######################################### STEP 2727 #########################################
< action >
[-0.04933887 -0.05      ]
< returned_observation >
[ 0.09869493  0.04024081]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 2728 #########################################
< action >
[-0.04928121 -0.05      ]
< returned_observation >
[ 0.04941373  0.        ]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2729 #########################################
< action >
[-0.0496245 -0.05     ]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 117 infomation #####################
{'nb_episode_steps': 18, 'min_reward': -13.100000000000001, 'episode_reward': -127.6, 'ave_reward': -7.088888888888889, 'nb_steps': 2730, 'max_reward': 3.6999999999999993}
######################################### STEP 2730 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.25194684  0.9305822 ]
< reward >
1.5
< running_reward >
0.44999999999999996
< done >
False
######################################### STEP 2731 #########################################
< action >
[-0.04979558 -0.04994232]
< returned_observation >
[ 0.20215126  0.88063988]
< reward >
1.6999999999999993
< running_reward >
0.5099999999999998
< done >
False
######################################### STEP 2732 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.15215126  0.83063988]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2733 #########################################
< action >
[-0.04873531 -0.05      ]
< returned_observation >
[ 0.10341594  0.78063988]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2734 #########################################
< action >
[-0.04481644 -0.05      ]
< returned_observation >
[ 0.0585995   0.73063988]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2735 #########################################
< action >
[-0.03430207 -0.0496596 ]
< returned_observation >
[ 0.02429743  0.68098028]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 2736 #########################################
< action >
[-0.02273386 -0.05      ]
< returned_observation >
[ 0.00156357  0.63098028]
< reward >
1.6000000000000014
< running_reward >
0.4800000000000004
< done >
False
######################################### STEP 2737 #########################################
< action >
[-0.01152685 -0.05      ]
< returned_observation >
[ 0.          0.58098028]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2738 #########################################
< action >
[-0.00513289 -0.05      ]
< returned_observation >
[ 0.          0.53098028]
< reward >
0.8999999999999986
< running_reward >
0.2699999999999996
< done >
False
######################################### STEP 2739 #########################################
< action >
[ 0.00229485 -0.05      ]
< returned_observation >
[ 0.00229485  0.48098028]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2740 #########################################
< action >
[ 0.00633808 -0.05      ]
< returned_observation >
[ 0.00863293  0.43098028]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2741 #########################################
< action >
[ 0.01049433 -0.05      ]
< returned_observation >
[ 0.01912726  0.38098028]
< reward >
-12.3
< running_reward >
-3.69
< done >
False
######################################### STEP 2742 #########################################
< action >
[ 0.01152984 -0.05      ]
< returned_observation >
[ 0.0306571   0.33098028]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2743 #########################################
< action >
[-0.01758301 -0.05      ]
< returned_observation >
[ 0.01307409  0.28098028]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2744 #########################################
< action >
[-0.03812274 -0.05      ]
< returned_observation >
[ 0.          0.23098028]
< reward >
3.1999999999999993
< running_reward >
0.9599999999999997
< done >
False
######################################### STEP 2745 #########################################
< action >
[-0.04702966 -0.05      ]
< returned_observation >
[ 0.          0.18098028]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2746 #########################################
< action >
[-0.04860835 -0.05      ]
< returned_observation >
[ 0.          0.13098028]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2747 #########################################
< action >
[-0.04832042 -0.05      ]
< returned_observation >
[ 0.          0.08098028]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2748 #########################################
< action >
[-0.04808373 -0.05      ]
< returned_observation >
[ 0.          0.03098028]
< reward >
2.6999999999999993
< running_reward >
0.8099999999999997
< done >
False
######################################### STEP 2749 #########################################
< action >
[-0.04768117 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
True
##################### episode 118 infomation #####################
{'nb_episode_steps': 20, 'min_reward': -12.3, 'episode_reward': -92.5, 'ave_reward': -4.625, 'nb_steps': 2750, 'max_reward': 3.6999999999999993}
######################################### STEP 2750 #########################################
< action >
[-0.05       -0.04987338]
< returned_observation >
[ 0.48950482  0.57643598]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2751 #########################################
< action >
[-0.05       -0.04957128]
< returned_observation >
[ 0.43950482  0.5268647 ]
< reward >
0.6000000000000014
< running_reward >
0.1800000000000004
< done >
False
######################################### STEP 2752 #########################################
< action >
[-0.05      -0.0483186]
< returned_observation >
[ 0.38950482  0.4785461 ]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2753 #########################################
< action >
[-0.05      -0.0476162]
< returned_observation >
[ 0.33950482  0.4309299 ]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2754 #########################################
< action >
[-0.05       -0.04765569]
< returned_observation >
[ 0.28950482  0.38327421]
< reward >
-10.899999999999999
< running_reward >
-3.2699999999999996
< done >
False
######################################### STEP 2755 #########################################
< action >
[-0.05       -0.04699113]
< returned_observation >
[ 0.23950482  0.33628308]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2756 #########################################
< action >
[-0.05       -0.04764756]
< returned_observation >
[ 0.18950482  0.28863552]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2757 #########################################
< action >
[-0.05       -0.04689819]
< returned_observation >
[ 0.13950482  0.24173734]
< reward >
-12.2
< running_reward >
-3.6599999999999997
< done >
False
######################################### STEP 2758 #########################################
< action >
[-0.05       -0.04764449]
< returned_observation >
[ 0.08950482  0.19409284]
< reward >
3.8000000000000007
< running_reward >
1.1400000000000001
< done >
False
######################################### STEP 2759 #########################################
< action >
[-0.05      -0.0468284]
< returned_observation >
[ 0.03950482  0.14726444]
< reward >
2.3999999999999986
< running_reward >
0.7199999999999995
< done >
False
######################################### STEP 2760 #########################################
< action >
[-0.05       -0.04625276]
< returned_observation >
[ 0.          0.10101169]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2761 #########################################
< action >
[-0.05       -0.04788984]
< returned_observation >
[ 0.          0.05312184]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2762 #########################################
< action >
[-0.05       -0.04843009]
< returned_observation >
[ 0.          0.00469175]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2763 #########################################
< action >
[-0.05       -0.04875476]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 119 infomation #####################
{'nb_episode_steps': 14, 'min_reward': -12.2, 'episode_reward': -75.6, 'ave_reward': -5.3999999999999995, 'nb_steps': 2764, 'max_reward': 3.8000000000000007}
######################################### STEP 2764 #########################################
< action >
[-0.00429482 -0.05      ]
< returned_observation >
[ 0.00125058  0.43490944]
< reward >
3.5
< running_reward >
1.05
< done >
False
######################################### STEP 2765 #########################################
< action >
[ 0.00254492 -0.05      ]
< returned_observation >
[ 0.00379551  0.38490944]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2766 #########################################
< action >
[ 0.00629503 -0.04955178]
< returned_observation >
[ 0.01009053  0.33535766]
< reward >
2.8000000000000007
< running_reward >
0.8400000000000002
< done >
False
######################################### STEP 2767 #########################################
< action >
[-0.01306348 -0.04914218]
< returned_observation >
[ 0.          0.28621549]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2768 #########################################
< action >
[-0.03928113 -0.05      ]
< returned_observation >
[ 0.          0.23621549]
< reward >
3.6000000000000014
< running_reward >
1.0800000000000003
< done >
False
######################################### STEP 2769 #########################################
< action >
[-0.05       -0.04852986]
< returned_observation >
[ 0.          0.18768562]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2770 #########################################
< action >
[-0.05       -0.04855581]
< returned_observation >
[ 0.          0.13912981]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2771 #########################################
< action >
[-0.05       -0.04870694]
< returned_observation >
[ 0.          0.09042287]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2772 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.          0.04042287]
< reward >
-11.7
< running_reward >
-3.51
< done >
False
######################################### STEP 2773 #########################################
< action >
[-0.05       -0.04981585]
< returned_observation >
[ 0.  0.]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
True
##################### episode 120 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -12.100000000000001, 'episode_reward': -70.9, 'ave_reward': -7.090000000000001, 'nb_steps': 2774, 'max_reward': 3.6000000000000014}
######################################### STEP 2774 #########################################
< action >
[-0.05        0.04906836]
< returned_observation >
[ 0.93832853  0.42425389]
< reward >
1.1999999999999993
< running_reward >
0.35999999999999976
< done >
False
######################################### STEP 2775 #########################################
< action >
[-0.05        0.04810716]
< returned_observation >
[ 0.88832853  0.47236105]
< reward >
-11.5
< running_reward >
-3.4499999999999997
< done >
False
######################################### STEP 2776 #########################################
< action >
[-0.04951957  0.04914798]
< returned_observation >
[ 0.83880897  0.52150902]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2777 #########################################
< action >
[-0.05  0.05]
< returned_observation >
[ 0.78880897  0.57150902]
< reward >
-0.10000000000000142
< running_reward >
-0.030000000000000426
< done >
False
######################################### STEP 2778 #########################################
< action >
[-0.04973011  0.04800753]
< returned_observation >
[ 0.73907885  0.61951655]
< reward >
0.6999999999999993
< running_reward >
0.20999999999999977
< done >
False
######################################### STEP 2779 #########################################
< action >
[-0.05        0.00027134]
< returned_observation >
[ 0.68907885  0.61978789]
< reward >
2.6000000000000014
< running_reward >
0.7800000000000004
< done >
False
######################################### STEP 2780 #########################################
< action >
[-0.05       -0.03388464]
< returned_observation >
[ 0.63907885  0.58590326]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2781 #########################################
< action >
[-0.05       -0.03843914]
< returned_observation >
[ 0.58907885  0.54746411]
< reward >
-13.100000000000001
< running_reward >
-3.93
< done >
False
######################################### STEP 2782 #########################################
< action >
[-0.05       -0.03984947]
< returned_observation >
[ 0.53907885  0.50761464]
< reward >
2.1999999999999993
< running_reward >
0.6599999999999998
< done >
False
######################################### STEP 2783 #########################################
< action >
[-0.05       -0.04072075]
< returned_observation >
[ 0.48907885  0.46689389]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2784 #########################################
< action >
[-0.05       -0.04249511]
< returned_observation >
[ 0.43907885  0.42439879]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2785 #########################################
< action >
[-0.05       -0.04432996]
< returned_observation >
[ 0.38907885  0.38006882]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2786 #########################################
< action >
[-0.05       -0.04433193]
< returned_observation >
[ 0.33907885  0.3357369 ]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2787 #########################################
< action >
[-0.05       -0.04973145]
< returned_observation >
[ 0.28907885  0.28600545]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2788 #########################################
< action >
[-0.05 -0.05]
< returned_observation >
[ 0.23907885  0.23600545]
< reward >
-12.5
< running_reward >
-3.75
< done >
False
######################################### STEP 2789 #########################################
< action >
[-0.05       -0.04920433]
< returned_observation >
[ 0.18907885  0.18680112]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2790 #########################################
< action >
[-0.05       -0.04760235]
< returned_observation >
[ 0.13907885  0.13919877]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2791 #########################################
< action >
[-0.05       -0.04739188]
< returned_observation >
[ 0.08907885  0.09180689]
< reward >
3.6999999999999993
< running_reward >
1.1099999999999997
< done >
False
######################################### STEP 2792 #########################################
< action >
[-0.05       -0.04599054]
< returned_observation >
[ 0.03907885  0.04581636]
< reward >
-11.0
< running_reward >
-3.3
< done >
False
######################################### STEP 2793 #########################################
< action >
[-0.05       -0.04401839]
< returned_observation >
[ 0.          0.00179797]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2794 #########################################
< action >
[-0.05       -0.04305886]
< returned_observation >
[ 0.  0.]
< reward >
-11.2
< running_reward >
-3.36
< done >
True
##################### episode 121 infomation #####################
{'nb_episode_steps': 21, 'min_reward': -13.100000000000001, 'episode_reward': -162.29999999999998, 'ave_reward': -7.728571428571428, 'nb_steps': 2795, 'max_reward': 3.6999999999999993}
######################################### STEP 2795 #########################################
< action >
[-0.03069526 -0.05      ]
< returned_observation >
[ 0.0663429   0.41190876]
< reward >
2.3000000000000007
< running_reward >
0.6900000000000002
< done >
False
######################################### STEP 2796 #########################################
< action >
[-0.00976642 -0.04988279]
< returned_observation >
[ 0.05657648  0.36202597]
< reward >
-11.2
< running_reward >
-3.36
< done >
False
######################################### STEP 2797 #########################################
< action >
[-0.00574394 -0.05      ]
< returned_observation >
[ 0.05083255  0.31202597]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2798 #########################################
< action >
[-0.02649581 -0.04973728]
< returned_observation >
[ 0.02433673  0.26228869]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2799 #########################################
< action >
[-0.03858471 -0.04991052]
< returned_observation >
[ 0.          0.21237816]
< reward >
-11.899999999999999
< running_reward >
-3.5699999999999994
< done >
False
######################################### STEP 2800 #########################################
< action >
[-0.0465001 -0.05     ]
< returned_observation >
[ 0.          0.16237816]
< reward >
-11.8
< running_reward >
-3.54
< done >
False
######################################### STEP 2801 #########################################
< action >
[-0.04833917 -0.05      ]
< returned_observation >
[ 0.          0.11237816]
< reward >
-11.100000000000001
< running_reward >
-3.3300000000000005
< done >
False
######################################### STEP 2802 #########################################
< action >
[-0.0473022 -0.05     ]
< returned_observation >
[ 0.          0.06237816]
< reward >
3.1000000000000014
< running_reward >
0.9300000000000004
< done >
False
######################################### STEP 2803 #########################################
< action >
[-0.04636674 -0.05      ]
< returned_observation >
[ 0.          0.01237816]
< reward >
-11.399999999999999
< running_reward >
-3.4199999999999995
< done >
False
######################################### STEP 2804 #########################################
< action >
[-0.04629018 -0.05      ]
< returned_observation >
[ 0.  0.]
< reward >
-11.3
< running_reward >
-3.39
< done >
True
##################### episode 122 infomation #####################
{'nb_episode_steps': 10, 'min_reward': -11.899999999999999, 'episode_reward': -86.0, 'ave_reward': -8.6, 'nb_steps': 2805, 'max_reward': 3.1000000000000014}
######################################### STEP 2805 #########################################
< action >
[-0.04931756  0.05      ]
< returned_observation >
[ 0.91368691  0.39183061]
< reward >
-11.3
< running_reward >
-3.39
< done >
False
######################################### STEP 2806 #########################################
< action >
[-0.05        0.04996756]
< returned_observation >
[ 0.86368691  0.44179817]
< reward >
0.3999999999999986
< running_reward >
0.11999999999999957
< done >
False
######################################### STEP 2807 #########################################
< action >
[-0.05        0.04927951]
< returned_observation >
[ 0.81368691  0.49107768]
< reward >
-13.7
< running_reward >
-4.109999999999999
< done >
False
######################################### STEP 2808 #########################################
< action >
[-0.05        0.04582106]
< returned_observation >
[ 0.76368691  0.53689874]
< reward >
-12.100000000000001
< running_reward >
-3.6300000000000003
< done >
False
######################################### STEP 2809 #########################################
< action >
[-0.05        0.01315481]
< returned_observation >
[ 0.71368691  0.55005355]
< reward >
-12.600000000000001
< running_reward >
-3.7800000000000002
< done >
False
######################################### STEP 2810 #########################################
< action >
[-0.05       -0.02960204]
< returned_observation >
[ 0.66368691  0.52045151]
< reward >
1.1000000000000014
< running_reward >
0.3300000000000004
< done >
False
######################################### STEP 2811 #########################################
< action >
[-0.05       -0.03750694]
< returned_observation >
[ 0.61368691  0.48294457]
< reward >
0.0
< running_reward >
0.0
< done >
False
